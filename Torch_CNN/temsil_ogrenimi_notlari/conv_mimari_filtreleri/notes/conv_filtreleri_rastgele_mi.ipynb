{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d1cc358",
   "metadata": {},
   "source": [
    "\n",
    "# Bu soruya cevap arıyoruz: CNN’deki conv filtreleri “rastgele” mi? Filtre sırasını biz belirleyebilir miyiz? “Kenardan başlamak” mantıklı mı?\n",
    "\n",
    "Bu notebook şu soruları teknik olarak netleştirir:\n",
    "\n",
    "1) Convolution katmanları **rastgele filtre mi uygular**, yoksa filtreler **öğrenilir** mi?  \n",
    "2) Conv katmanındaki filtrelerin **sırası** diye bir şey var mı? Biz bunu belirleyebilir miyiz?  \n",
    "3) “En iyi çözüm kenardan başlamaktır” fikri nereden geliyor? CNN’ler zaten **kenar** mı öğreniyor?  \n",
    "4) Eğer “kenar” gibi ön-bilgi eklemek istersek, bunu **hangi yöntemlerle** yapabiliriz?\n",
    "\n",
    "> Not: Burada “filtre sırası” derken genelde iki şey kastedilir:\n",
    "> - (A) Aynı katmandaki farklı kernel’lerin **hangi sırada/indekste** durduğu  \n",
    "> - (B) Katmanların **hangi tip filtreleri önce-sonra** öğreneceği (düşük seviye → yüksek seviye)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed55794",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 1) Kısa cevap\n",
    "\n",
    "- Conv filtreleri **rastgele uygulanmaz**.  \n",
    "  Eğitim başında ağırlıklar **rastgele başlatılır**, ama sonra **geri yayılım (backprop)** ile veri üzerinden öğrenilir.\n",
    "\n",
    "- Aynı katmandaki filtrelerin **sırası** genelde anlamlı değildir.  \n",
    "  Çünkü ağda “kanal permütasyon simetrisi” vardır: filtreleri permüte edebilirsin, sonraki katmanın ağırlıklarını da aynı şekilde permüte edersen ağın çıktısı değişmez.\n",
    "\n",
    "- “Kenardan başlamak” sezgisi **doğru bir induktif bias**:  \n",
    "  Erken katmanlar gerçekten de sıklıkla **Gabor/edge benzeri** filtreler öğrenir.  \n",
    "  Ama bunu *elle zorunlu kılmak* yerine ağın bunu öğrenmesine izin vermek çoğu zaman daha etkilidir.\n",
    "\n",
    "Şimdi bunu temelden ispat/intuition ile açıyoruz.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df27b42",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 2) Conv filtreleri neden “rastgele” gibi görünür?\n",
    "\n",
    "### 2.1) Başlangıçta rastgele (initialization)\n",
    "\n",
    "Eğitim başlamadan önce conv ağırlıkları genelde:\n",
    "- He/Kaiming init (ReLU/SiLU için)\n",
    "- Xavier init (tanh vb. için)\n",
    "\n",
    "gibi dağılımlardan **rastgele** örneklenir.\n",
    "\n",
    "Ama bu “model rastgele filtre uygular” demek değildir.  \n",
    "Bu sadece başlangıç noktasını belirler.\n",
    "\n",
    "### 2.2) Eğitimde öğrenme (learning)\n",
    "\n",
    "Eğitim sırasında hedef fonksiyon minimize edilir:\n",
    "\n",
    "\\[\n",
    "W \\leftarrow W - \\eta \\nabla_W \\mathcal{L}\n",
    "\\]\n",
    "\n",
    "Bu gradyan, filtrelerin “hangi örüntüyü yakalaması gerektiği” bilgisini taşır.\n",
    "Dolayısıyla filtreler zamanla veri istatistiklerine göre şekillenir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e67e44b",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 3) “Filtre sırası” diye bir şey var mı?\n",
    "\n",
    "### 3.1) Aynı katmandaki filtrelerin indeksi (kanal sırası) **anlamlı değil**\n",
    "\n",
    "Bir conv katmanı \\(C_{out}\\) tane filtre üretir.\n",
    "Bu filtrelerin “1. filtre”, “2. filtre” diye bir sırası vardır ama bu sıra **semantik** değildir.\n",
    "\n",
    "Neden? Çünkü şu simetri vardır:\n",
    "\n",
    "- Bir katmanın çıktı kanallarını herhangi bir permütasyonla yeniden sıralarsan,\n",
    "- Sonraki katmanın giriş kanallarını aynı permütasyonla uyumlu şekilde yeniden sıralarsan,\n",
    "- Ağın çıktısı **değişmez**.\n",
    "\n",
    "Bu yüzden “filtrelerin sırası” modele bir şey katmaz; sadece bir indekslemedir.\n",
    "\n",
    "### 3.2) Peki “katmanlar arası sıra” (low-level → high-level) var mı?\n",
    "\n",
    "Evet, bu farklı bir şey:\n",
    "- İlk katmanlar genelde kenar/texture (low-level)\n",
    "- Orta katmanlar parça/şekil (mid-level)\n",
    "- Derin katmanlar semantik (high-level)\n",
    "\n",
    "Bu sıra, “indeks sırası” değil; **derinlik boyunca temsil hiyerarşisi**dir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ec0628f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maks |y - y2|: 1.1920928955078125e-07\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Kanal permütasyon sezgisi: \n",
    "# Aynı katmandaki filtreleri yeniden sıralamak tek başına anlamlı değildir.\n",
    "# (Matematiksel fikir: sonraki katman bu permütasyonu telafi edebilir.)\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Basit iki katmanlı conv blok (1x1 conv ile kanallar arası karışım kolay gösterilir)\n",
    "conv1 = torch.nn.Conv2d(3, 8, kernel_size=3, padding=1, bias=False)\n",
    "conv2 = torch.nn.Conv2d(8, 4, kernel_size=1, padding=0, bias=False)\n",
    "\n",
    "x = torch.randn(2, 3, 16, 16)\n",
    "\n",
    "y = conv2(conv1(x))\n",
    "\n",
    "# Şimdi conv1'in çıkış kanallarını permüte edelim\n",
    "perm = torch.randperm(8)\n",
    "\n",
    "# conv1 ağırlıklarını permüte: out_channels yeniden sıralansın\n",
    "conv1_perm = torch.nn.Conv2d(3, 8, kernel_size=3, padding=1, bias=False)\n",
    "conv1_perm.weight.data = conv1.weight.data[perm].clone()\n",
    "\n",
    "# conv2 giriş kanallarını aynı perm ile telafi edelim: conv2.weight: [out, in, 1,1]\n",
    "conv2_perm = torch.nn.Conv2d(8, 4, kernel_size=1, padding=0, bias=False)\n",
    "conv2_perm.weight.data = conv2.weight.data[:, perm].clone()\n",
    "\n",
    "y2 = conv2_perm(conv1_perm(x))\n",
    "\n",
    "print(\"Maks |y - y2|:\", (y - y2).abs().max().item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8917dc5a",
   "metadata": {},
   "source": [
    "\n",
    "✅ Çıktı çok küçük (sayısal hata seviyesinde) ise şu demektir:  \n",
    "**Aynı katmandaki filtrelerin sırası/indeksi semantik değil**; sonraki katman bu permütasyonu telafi edebilir.\n",
    "\n",
    "Dolayısıyla:\n",
    "- “Filtrelerin sırasını belirleyeyim” fikri çoğu zaman anlamsızdır.\n",
    "- Önemli olan: filtrelerin **hangi özellikleri** öğrenebildiği ve katmanların **hiyerarşik** düzenidir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91adbc9",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 4) “Kenardan başlamak” fikri doğru mu?\n",
    "\n",
    "### 4.1) Evet: erken katmanlar genelde edge/texture öğrenir\n",
    "\n",
    "Doğal görüntülerde en güçlü istatistiklerden biri:\n",
    "- yoğunluk değişimleri (gradient)  \n",
    "- kenarlar (edges)  \n",
    "- basit yönlü örüntüler (Gabor benzeri)\n",
    "\n",
    "Bu yüzden CNN’lerin ilk katmanları sıkça:\n",
    "- yatay/dikey kenar\n",
    "- diyagonal kenar\n",
    "- blob/spot\n",
    "- düşük frekans (blur)  \n",
    "benzeri filtreler öğrenir.\n",
    "\n",
    "### 4.2) Ama “elle zorlamak” her zaman iyi değil\n",
    "\n",
    "Eğer ilk katmanı “sadece edge filtreleri” yaparsan:\n",
    "- modeli bazı veri türlerinde kısıtlarsın  \n",
    "  (ör. medikal, SAR, multispectral, düşük ışık, stylized data)\n",
    "- öğrenmesi gereken farklı low-level ipuçlarını kaçırabilirsin\n",
    "\n",
    "Modern yaklaşım:\n",
    "- doğru inductive bias’ı **tasarımla** ver (stride planı, norm seçimi, augmentation)\n",
    "- filtrelerin detayını **öğrenmeye bırak**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4867390b",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 5) Peki “kenarı” modele bilerek nasıl eklersin? (mantıklı yöntemler)\n",
    "\n",
    "Bu işin 4 seviyesi var:\n",
    "\n",
    "### 5.1) Sabit (hand-crafted) filtre katmanı\n",
    "- Sobel/Scharr/Laplacian gibi kernel’leri sabit tut\n",
    "- İlk katmana “ek kanal” olarak ekle (RGB + edge map)\n",
    "\n",
    "✅ Avantaj: güçlü ön-bilgi  \n",
    "❌ Dezavantaj: esneklik azalır\n",
    "\n",
    "### 5.2) Başlangıçta edge’e benzetip sonra serbest bırakma\n",
    "- İlk conv kernel’lerini Gabor benzeri başlat\n",
    "- Eğitimle güncellenmesine izin ver\n",
    "\n",
    "✅ Avantaj: iyi başlangıç  \n",
    "❌ Dezavantaj: her probleme uygun değil\n",
    "\n",
    "### 5.3) Kayıp fonksiyonuna yardımcı görev (edge supervision)\n",
    "- Ek bir head ile edge map tahmini\n",
    "- Multi-task learning\n",
    "\n",
    "✅ Avantaj: representation güçlenir  \n",
    "❌ Dezavantaj: ek karmaşıklık\n",
    "\n",
    "### 5.4) Frequency-aware / anti-aliasing yaklaşımlar\n",
    "- Downsample öncesi low-pass (BlurPool vb.)\n",
    "- Daha sağlam sinyal işleme\n",
    "\n",
    "✅ Avantaj: stride kaynaklı aliasing azalır  \n",
    "❌ Dezavantaj: maliyet/latency etkisi olabilir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cfb9dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB: torch.Size([2, 3, 32, 32]) RGB+edge: torch.Size([2, 4, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Mini demo: Sobel edge çıkarıp RGB'ye ek kanal olarak birleştirme (PyTorch ile)\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def sobel_edges(gray):\n",
    "    # gray: (N,1,H,W)\n",
    "    kx = torch.tensor([[-1,0,1],[-2,0,2],[-1,0,1]], dtype=gray.dtype, device=gray.device).view(1,1,3,3)\n",
    "    ky = torch.tensor([[-1,-2,-1],[0,0,0],[1,2,1]], dtype=gray.dtype, device=gray.device).view(1,1,3,3)\n",
    "    gx = F.conv2d(gray, kx, padding=1)\n",
    "    gy = F.conv2d(gray, ky, padding=1)\n",
    "    mag = torch.sqrt(gx**2 + gy**2 + 1e-6)\n",
    "    return mag\n",
    "\n",
    "x = torch.randn(2, 3, 32, 32)\n",
    "gray = x.mean(dim=1, keepdim=True)\n",
    "edge = sobel_edges(gray)\n",
    "\n",
    "x_plus = torch.cat([x, edge], dim=1)  # (N,4,H,W)\n",
    "print(\"RGB:\", x.shape, \"RGB+edge:\", x_plus.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195ee81a",
   "metadata": {},
   "source": [
    "\n",
    "Bu, “kenar bilgisini” modele **ekstra kanal** olarak vermenin en basit yolu.\n",
    "\n",
    "Ama tekrar: bu bir “her zaman en iyi” değil; dataset’e göre değişir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5087d6",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 6) Sık yapılan yanlış anlama: “Filtrelerin sırasını belirleyebilirim” ≠ “Ne öğreneceğini belirlerim”\n",
    "\n",
    "- Filtre indeksini sıralamak kolay (permütasyon)\n",
    "- Ama “bu filtre kesin kenar, bu filtre kesin texture” diye zorlamak:\n",
    "  - ya sabit filtre gerektirir\n",
    "  - ya da ek kısıt/regularization gerektirir\n",
    "  - genelde optimuma giden yolu daraltır\n",
    "\n",
    "CNN’lerin gücü:\n",
    "> Feature’ların hangi kombinasyonla faydalı olacağını veriden öğrenmesidir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cca374",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 7) Kapanış: Net cevap\n",
    "\n",
    "- Conv mimarileri “rastgele filtre uygular” gibi başlar çünkü **ağırlıklar rastgele başlatılır**.  \n",
    "  Ama eğitimle filtreler **öğrenilir**.\n",
    "\n",
    "- Aynı katmandaki filtrelerin “sırası” semantik değildir.  \n",
    "  Kanal permütasyonları sonraki katman tarafından telafi edilebilir.\n",
    "\n",
    "- “Kenardan başlamak” fikri, doğal görüntü istatistikleri yüzünden sezgisel olarak doğrudur;  \n",
    "  erken katmanlar çoğu zaman edge/texture öğrenir.  \n",
    "  Ama bunu “kural” gibi dayatmak yerine:\n",
    "  - doğru stride/augmentation/norm seçimi\n",
    "  - gerekiyorsa edge bilgisini yardımcı sinyal olarak verme\n",
    "  gibi yöntemler daha güvenli.\n",
    "\n",
    "İstersen bir sonraki adımda:\n",
    "- Senin YOLO/backbone tasarımında “edge bias” eklemek mantıklı mı,  \n",
    "datasetine göre nasıl karar veririz (small object/blur/noise) onu da çıkarırız.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
