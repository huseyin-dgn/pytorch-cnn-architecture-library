## MBConv (Inverted Bottleneck)

MBConvâ€™un olayÄ±: **kanalÄ± Ã¶nce ÅŸiÅŸir (expand), uzamsal iÅŸlemi depthwise ile ucuza yap, sonra tekrar sÄ±kÄ±ÅŸtÄ±r (project).**  
Bu yapÄ± MobileNetV2/EfficientNet Ã§izgisinin temel taÅŸÄ±dÄ±r. âš™ï¸ğŸ“±

### Blok yapÄ±sÄ± (sÄ±ra net)

1. **1Ã—1 Expand**  
   `C_in -> C_exp = C_in * expansion_factor`  
   AmaÃ§: kapasiteyi artÄ±rÄ±p featureâ€™larÄ± zenginleÅŸtirmek.

2. **3Ã—3 Depthwise (stride burada)**  
   `groups = C_exp` olduÄŸu iÃ§in her kanal ayrÄ± filtre â†’ ucuz spatial iÅŸlem.

3. **1Ã—1 Project (Linear Bottleneck)**  
   `C_exp -> C_out`  
   Burada aktivasyon yok (linear), Ã§Ã¼nkÃ¼ dar boÄŸazda nonlinearity bilgi kaybÄ±nÄ± artÄ±rabiliyor.

4. **Residual (opsiyonel)**  
   Sadece `stride=1` ve `C_in == C_out` ise eklenir.  
   Downsample veya kanal deÄŸiÅŸimi varsa residual yok.

### Bu kodda neler var?

- Aktivasyon olarak **SiLU** kullanÄ±lmÄ±ÅŸ (MobileNet/EfficientNet tarzÄ±).
- Residual ÅŸartÄ± doÄŸru: `(stride == 1 and c_in == c_out)` âœ…

### Model akÄ±ÅŸÄ± (`MBConvNetSmall`)

- Stem: 3â†’16
- Stage1: 16â†’16 (2 MBConv, boyut sabit)
- Stage2: stride=2 ile 32â†’16 Ã§Ã¶zÃ¼nÃ¼rlÃ¼k + 16â†’24 kanal
- Stage3: stride=2 ile 16â†’8 Ã§Ã¶zÃ¼nÃ¼rlÃ¼k + 24â†’40 kanal
- GAP + FC

### Neden iyi?

- Normal convâ€™a gÃ¶re **daha dÃ¼ÅŸÃ¼k FLOPs** hedefler (depthwise sayesinde)
- Expand sayesinde kapasiteyi korur/artar
- Residual ile optimizasyonu kolaylaÅŸtÄ±rÄ±r âœ…

### Dikkat

- `expansion_factor` Ã§ok bÃ¼yÃ¼rse compute artar; Ã§ok kÃ¼Ã§Ã¼lÃ¼rse kapasite dÃ¼ÅŸer.
- Pratikte EfficientNetâ€™te buna ek olarak SE (Squeeze-Excite) ve drop connect de sÄ±k gÃ¶rÃ¼lÃ¼r.
