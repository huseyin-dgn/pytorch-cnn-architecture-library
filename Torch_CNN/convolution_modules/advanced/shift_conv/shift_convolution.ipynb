{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd59dea6",
   "metadata": {},
   "source": [
    "# Shift Convolution (Shift-Conv)\n",
    "\n",
    "Bu notebook, **Shift Convolution (Shift-Conv)** yöntemini en temelden başlayarak; **neden ortaya çıktığını**, **tam olarak ne yaptığını**, **hangi bloklarla birlikte kullanıldığını** ve **PyTorch ile nasıl uygulanacağını** detaylı şekilde anlatır.\n",
    "\n",
    "## Hedef\n",
    "- Shift işleminin (kanal bazlı kaydırma) tanımını görmek\n",
    "- Konvolüsyonun uzamsal karıştırmasını nasıl “ucuz” şekilde sağladığını anlamak\n",
    "- **Shift + 1×1 Conv** kombinasyonunun neden kritik olduğunu kavramak\n",
    "- Parametre/FLOP karşılaştırması yapmak\n",
    "- PyTorch ile **tam çalışan** örnek kodlar görmek\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967bc692",
   "metadata": {},
   "source": [
    "## 1) Motivasyon: Neden Shift-Conv?\n",
    "\n",
    "Mobil/edge (telefon, Jetson, gömülü) ağlarda hedef şudur:\n",
    "\n",
    "- **FLOP** (hesap yükü) azalt\n",
    "- **Parametre** azalt\n",
    "- Yine de uzamsal (spatial) özellikleri iyi yakala\n",
    "\n",
    "Klasik **K×K** konvolüsyonun maliyeti yüksektir.\n",
    "\n",
    "### Klasik Conv2d maliyeti (yaklaşık)\n",
    "- Parametre: `C_in * C_out * K * K`\n",
    "- FLOP (yaklaşık): `H * W * C_in * C_out * K * K`\n",
    "\n",
    "### Shift fikri\n",
    "**K×K konvolüsyonun yaptığı uzamsal karıştırmayı** (komşu piksellere bakma) parametresiz bir operasyonla yap:\n",
    "\n",
    "- Kanalların bir kısmını **sağa/sola/yukarı/aşağı** kaydır\n",
    "- Sonra **1×1 Conv** ile kanalları karıştır (learnable mixing)\n",
    "\n",
    "Bu yaklaşım, K×K conv yerine:\n",
    "\n",
    "1) `shift` (parametresiz, FLOP çok düşük)\n",
    "2) `1×1 conv` (öğrenilebilir ama K×K değil, daha ucuz)\n",
    "\n",
    "kombinasyonunu kullanır.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f105dc14",
   "metadata": {},
   "source": [
    "## 2) Shift İşlemi Nedir?\n",
    "\n",
    "Shift işlemi, her kanalı (veya kanal gruplarını) belirli bir yönde kaydırır.\n",
    "\n",
    "Örnek: 3×3 komşuluk yönleri\n",
    "\n",
    "- yukarı (0, -1)\n",
    "- aşağı (0, +1)\n",
    "- sol (-1, 0)\n",
    "- sağ (+1, 0)\n",
    "- (opsiyonel) çaprazlar ve merkez (0,0)\n",
    "\n",
    "### En kritik nokta\n",
    "Shift operasyonu **öğrenilebilir ağırlık içermez**.\n",
    "\n",
    "- Parametre sayısı: **0**\n",
    "- Ama uzamsal bilgi taşır: komşu pikselleri kanallara dağıtır\n",
    "\n",
    "Bu yüzden Shift, tek başına konvolüsyonun yerini tam alamaz.\n",
    "Çünkü konvolüsyonun “öğrenme” kısmı ağırlıklardadır.\n",
    "\n",
    "Shift-Conv yaklaşımında öğrenme çoğunlukla **1×1 conv** ile yapılır:\n",
    "\n",
    "> `Shift (spatial mixing) + 1×1 Conv (channel mixing)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee99403f",
   "metadata": {},
   "source": [
    "## 3) Shift-Conv Bloğu: Neden 1×1 Conv ile birlikte?\n",
    "\n",
    "Shift şunu yapar:\n",
    "- Kanalların bazılarını sağa/sola/yukarı/aşağı kaydırır\n",
    "- Böylece farklı uzamsal konumlardan bilgi gelir\n",
    "\n",
    "Ama shift:\n",
    "- Kanallar arasında **öğrenilebilir bir karışım** yapmaz\n",
    "- Sadece yeniden düzenler\n",
    "\n",
    "**1×1 Conv** şunu yapar:\n",
    "- Kanallar arasında öğrenilebilir mixing sağlar\n",
    "- Parametre: `C_in * C_out`\n",
    "- FLOP: `H * W * C_in * C_out`\n",
    "\n",
    "Bu yüzden Shift-Conv genelde şu bloktur:\n",
    "\n",
    "```\n",
    "x → Shift → 1×1 Conv → (BN) → (Activation)\n",
    "```\n",
    "\n",
    "Bu, **Depthwise Separable Conv** ile zihinsel olarak benzer bir ayrıştırmadır:\n",
    "- Depthwise: spatial mixing (kanal başına)\n",
    "- Pointwise: channel mixing\n",
    "\n",
    "Shift: spatial mixing’i daha da ucuz (parametresiz) hale getirir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e98de20",
   "metadata": {},
   "source": [
    "## 4) Shift Nasıl Tasarlanır? (Kanal Dağıtımı)\n",
    "\n",
    "Pratikte kanalları yönlere bölüştürürsün.\n",
    "\n",
    "Örneğin `C` kanalın olsun ve 5 yön kullan:\n",
    "- (0,0) merkez (shift yok)\n",
    "- (1,0) sağ\n",
    "- (-1,0) sol\n",
    "- (0,1) aşağı\n",
    "- (0,-1) yukarı\n",
    "\n",
    "Kanalların yaklaşık `C/5`’i her yöne atanır.\n",
    "\n",
    "Not:\n",
    "- Sınırda taşan değerler genelde **zero padding** ile doldurulur.\n",
    "- Alternatif: `padding_mode='replicate'` gibi seçenekler (ama shift basit olsun diye çoğu implementasyon zero kullanır).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb66bbb",
   "metadata": {},
   "source": [
    "## 5) PyTorch ile Shift Implementasyonu (Tam Çalışan)\n",
    "\n",
    "Aşağıdaki implementasyon:\n",
    "- `x` tensorunu (B, C, H, W) alır\n",
    "- Kanalları gruplara böler\n",
    "- Her grubu farklı yöne **torch.roll** ile kaydırır\n",
    "- Sınırdaki wrap-around etkisini engellemek için sıfırlama uygular (zero padding benzeri)\n",
    "\n",
    "Bu sayede shift işlemi **deterministik ve parametresiz** olur.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d5a5cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([2, 10, 8, 8]) y: torch.Size([2, 10, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def shift2d(x: torch.Tensor, directions=None) -> torch.Tensor:\n",
    "    \"\"\"Parametresiz shift işlemi.\n",
    "\n",
    "    Args:\n",
    "        x: (B, C, H, W)\n",
    "        directions: kanal gruplarına atanacak (dx, dy) listesi.\n",
    "            Varsayılan: merkez + 4 yön (5 grup)\n",
    "\n",
    "    Not:\n",
    "        torch.roll wrap-around yapar. Biz wrap-around bölgelerini sıfırlayarak\n",
    "        zero-padding etkisi oluşturuyoruz.\n",
    "    \"\"\"\n",
    "    if directions is None:\n",
    "        directions = [(0, 0), (1, 0), (-1, 0), (0, 1), (0, -1)]  # center, right, left, down, up\n",
    "\n",
    "    B, C, H, W = x.shape\n",
    "    G = len(directions)\n",
    "\n",
    "    base = C // G\n",
    "    sizes = [base] * (G - 1) + [C - base * (G - 1)]\n",
    "    xs = torch.split(x, sizes, dim=1)\n",
    "\n",
    "    out_chunks = []\n",
    "    for chunk, (dx, dy) in zip(xs, directions):\n",
    "        if dx == 0 and dy == 0:\n",
    "            out_chunks.append(chunk)\n",
    "            continue\n",
    "\n",
    "        rolled = torch.roll(chunk, shifts=(dy, dx), dims=(-2, -1))\n",
    "\n",
    "        # wrap-around sıfırlama\n",
    "        if dy > 0:\n",
    "            rolled[..., :dy, :] = 0\n",
    "        elif dy < 0:\n",
    "            rolled[..., dy:, :] = 0\n",
    "\n",
    "        if dx > 0:\n",
    "            rolled[..., :, :dx] = 0\n",
    "        elif dx < 0:\n",
    "            rolled[..., :, dx:] = 0\n",
    "\n",
    "        out_chunks.append(rolled)\n",
    "\n",
    "    return torch.cat(out_chunks, dim=1)\n",
    "\n",
    "\n",
    "# Hızlı test\n",
    "x = torch.randn(2, 10, 8, 8)\n",
    "y = shift2d(x)\n",
    "print('x:', x.shape, 'y:', y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13217ea",
   "metadata": {},
   "source": [
    "## 6) Shift-Conv Blok: Shift + 1×1 Conv\n",
    "\n",
    "Şimdi shift fonksiyonunu bir modüle sarıyoruz ve arkasına `1×1 Conv` ekliyoruz.\n",
    "\n",
    "Bu blok, pratikte K×K conv yerine kullanılabilir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f9ee11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp: torch.Size([4, 32, 64, 64]) out: torch.Size([4, 64, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "class ShiftConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, directions=None, bias=False):\n",
    "        super().__init__()\n",
    "        self.directions = directions\n",
    "        self.pw = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=bias)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.act = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = shift2d(x, self.directions)\n",
    "        x = self.pw(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "\n",
    "# Test\n",
    "model = ShiftConvBlock(32, 64)\n",
    "inp = torch.randn(4, 32, 64, 64)\n",
    "out = model(inp)\n",
    "print('inp:', inp.shape, 'out:', out.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3406569",
   "metadata": {},
   "source": [
    "## 7) Parametre ve FLOP Karşılaştırması (Hızlı Hesap)\n",
    "\n",
    "Bir katman karşılaştırması yapalım:\n",
    "\n",
    "- Klasik `3×3 Conv`: Param = `C_in*C_out*9`\n",
    "- Shift-Conv: Param = `C_in*C_out` (sadece 1×1)\n",
    "\n",
    "Bu, özellikle `K=3` için teorik olarak ~9× parametre farkı demek.\n",
    "\n",
    "Şimdi sayısal görelim.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3f98b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3x3 Conv params: 73728\n",
      "Shift+1x1 params: 8192\n",
      "Param ratio (Conv / Shift): 9.0\n"
     ]
    }
   ],
   "source": [
    "def params_conv2d(cin, cout, k):\n",
    "    return cin * cout * k * k\n",
    "\n",
    "def params_shift_conv(cin, cout):\n",
    "    return cin * cout  # shift parametresiz\n",
    "\n",
    "cin, cout, k = 64, 128, 3\n",
    "p_conv = params_conv2d(cin, cout, k)\n",
    "p_shift = params_shift_conv(cin, cout)\n",
    "print('3x3 Conv params:', p_conv)\n",
    "print('Shift+1x1 params:', p_shift)\n",
    "print('Param ratio (Conv / Shift):', p_conv / p_shift)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99334a58",
   "metadata": {},
   "source": [
    "## 8) Nerede Kullanılır? (Pratik Tasarım)\n",
    "\n",
    "Shift-Conv özellikle:\n",
    "- Mobil backbone bloklarında\n",
    "- 3×3 conv’un çok maliyetli olduğu yerlerde\n",
    "\n",
    "Şu şablonlarla kullanılır:\n",
    "\n",
    "### Şablon A: Conv yerine Shift-Conv\n",
    "```\n",
    "3×3 Conv yerine:\n",
    "Shift → 1×1 Conv\n",
    "```\n",
    "\n",
    "### Şablon B: Bottleneck benzeri\n",
    "```\n",
    "1×1 (expand) → Shift → 1×1 (project)\n",
    "```\n",
    "\n",
    "Bu yaklaşım, Inverted Bottleneck mantığına benzer şekilde kanal genişletme/sıkıştırma ile çalışır.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3481de7",
   "metadata": {},
   "source": [
    "## 9) Mini Model Örneği: Shift-Conv Kullanan CNN\n",
    "\n",
    "Aşağıdaki model:\n",
    "- Basit bir stem conv\n",
    "- Ardından 2 adet ShiftConvBlock\n",
    "- Global average pooling + classification head\n",
    "\n",
    "Bu, Shift-Conv’un gerçek kullanımını görmen için minimal bir örnek.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cf64d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: torch.Size([8, 10])\n"
     ]
    }
   ],
   "source": [
    "class SmallShiftCNN(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.block1 = ShiftConvBlock(32, 64)\n",
    "        self.block2 = ShiftConvBlock(64, 128)\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "# Test\n",
    "m = SmallShiftCNN(in_channels=3, num_classes=10)\n",
    "dummy = torch.randn(8, 3, 64, 64)\n",
    "pred = m(dummy)\n",
    "print('pred:', pred.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b034311",
   "metadata": {},
   "source": [
    "## 10) Sık Yapılan Hatalar ve İpuçları\n",
    "\n",
    "1. **torch.roll wrap-around yapar**\n",
    "   - Biz wrap-around bölgelerini sıfırladık.\n",
    "   - Aksi halde sağa kaydırınca soldan değer taşar (sahte bilgi).\n",
    "\n",
    "2. Shift tek başına yeterli değil\n",
    "   - Öğrenme `1×1 conv` ile olur.\n",
    "\n",
    "3. Kanal sayısı küçükse grup dağılımı dengesiz olabilir\n",
    "   - Çok küçük C’de bazı yönlere çok az kanal düşer.\n",
    "   - Bu durumda yön sayısını azaltabilir veya farklı dağıtım yapabilirsin.\n",
    "\n",
    "4. Performans notu\n",
    "   - Shift teorik olarak ucuzdur.\n",
    "   - Ancak PyTorch’ta `roll + slice` bazı ortamlarda bellek hareketi yaratabilir.\n",
    "   - Mobil inference için özel optimize edilmiş implementasyonlar daha hızlı olabilir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc89c2e",
   "metadata": {},
   "source": [
    "## 11) Özet\n",
    "\n",
    "- Shift-Conv, K×K konvolüsyonun uzamsal etkisini **parametresiz bir kaydırma** ile taklit eder.\n",
    "- Öğrenilebilir kısım çoğunlukla **1×1 conv** ile sağlanır.\n",
    "- Amaç: **parametre ve FLOP azaltmak** (özellikle mobil ağlar için).\n",
    "- Tipik blok: `Shift → 1×1 Conv → BN → Activation`\n",
    "\n",
    "Bu noktadan sonra istersen:\n",
    "- Shift-Conv’u kendi CNN bloğuna (ör. Hyso) entegre edelim\n",
    "- Aynı sahnede 3×3 conv vs shift+1×1 çıktıları görselleştirelim\n",
    "- FLOP hesaplarını daha detaylı (gerçek H×W ile) çıkaralım\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
