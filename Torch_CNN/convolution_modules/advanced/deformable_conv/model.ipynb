{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8e412d8",
   "metadata": {},
   "source": [
    "### 1. Temel Deformable Conv Bloğu (Offset + DeformConv2d)\n",
    "\n",
    "Burada yapıyı şöyle düşün:\n",
    "\n",
    "* offset_conv: Giriş feature map’ten offset üretiyor.\n",
    "\n",
    "* dcn: DeformConv2d (torchvision.ops’ta var; yoksa mmcv benzeri kütüphaneden gelir.)\n",
    "\n",
    "* Sonra normal Conv bloğu gibi BatchNorm + aktivasyon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db712049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: torch.Size([1, 64, 128, 128])\n",
      "Output: torch.Size([1, 128, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "try:\n",
    "    from torchvision.ops import DeformConv2d\n",
    "except ImportError:\n",
    "    DeformConv2d = None\n",
    "\n",
    "class DeformableConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels,\n",
    "                 kernel_size=3, stride=1, padding=1, bias=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "        # 1) Offset üreten konvolüsyon\n",
    "        # Her konumda K*K tane grid noktası var,\n",
    "        # her nokta için (dx, dy) → 2 * K * K kanal\n",
    "        self.offset_conv = nn.Conv2d(\n",
    "            in_channels,\n",
    "            2 * kernel_size * kernel_size,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            bias=True,  # offset için bias genelde açık\n",
    "        )\n",
    "\n",
    "        if DeformConv2d is None:\n",
    "            raise RuntimeError(\n",
    "                \"DeformConv2d bulunamadı. torchvision.ops veya DCN implementasyonu kurman gerekiyor.\"\n",
    "            )\n",
    "\n",
    "        # 2) Asıl deformable convolution\n",
    "        self.dcn = DeformConv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            bias=bias,\n",
    "        )\n",
    "\n",
    "        # 3) Normalleştirme + aktivasyon\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.act = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C_in, H, W)\n",
    "\n",
    "        # 1) Offset haritasını üret\n",
    "        offset = self.offset_conv(x)\n",
    "        # offset shape: (B, 2*K*K, H_out, W_out)\n",
    "\n",
    "        # 2) Deformable Conv uygula\n",
    "        out = self.dcn(x, offset)\n",
    "        # out: (B, C_out, H_out, W_out)\n",
    "\n",
    "        # 3) BN + ReLU\n",
    "        out = self.bn(out)\n",
    "        out = self.act(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    x = torch.randn(1, 64, 128, 128)\n",
    "    block = DeformableConvBlock(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "    y = block(x)\n",
    "    print(\"Input:\", x.shape)\n",
    "    print(\"Output:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9880db",
   "metadata": {},
   "source": [
    "### Bu yapıda ne oluyor?\n",
    "\n",
    "**offset_conv:**\n",
    "\n",
    "* Input: (B, C_in, H, W)\n",
    "\n",
    "* Output: (B, 2*K*K, H_out, W_out) → her spatial konumda grid’in nereye kayacağı çıkıyor.\n",
    "\n",
    "**dcn(x, offset):**\n",
    "\n",
    "### DCN içerde şunu yapıyor:\n",
    "\n",
    "* Her konum için sabit grid + offset → yeni koordinatlar\n",
    "\n",
    "* Bilinear interpolasyon ile bu koordinatlardan değer çekiyor\n",
    "\n",
    "* Ağırlıklarla çarpıp topluyor (normal conv gibi)\n",
    "\n",
    "**Senin için kritik olan:**\n",
    "\n",
    ">Değişen tek şey, örnekleme noktalarının koordinatları; geri kalan mantık Conv ile aynı."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792abc32",
   "metadata": {},
   "source": [
    "----\n",
    "----\n",
    "## 2. Modulated DCN (DCNv2 Mantığı)\n",
    "\n",
    "* Burada offset + bir de modulation mask var. Maske her grid noktasının önemini ayarlıyor.\n",
    "\n",
    "* Ek olarak mask_conv var.\n",
    "\n",
    "* Mask kanal sayısı = K*K (her grid noktası için 1 skaler ağırlık)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d590ab33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModulatedDeformableConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels,\n",
    "                 kernel_size=3, stride=1, padding=1, bias=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "        # Offset: 2 * K * K\n",
    "        self.offset_conv = nn.Conv2d(\n",
    "            in_channels,\n",
    "            2 * kernel_size * kernel_size,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "        )\n",
    "\n",
    "        # Mask: K * K\n",
    "        self.mask_conv = nn.Conv2d(\n",
    "            in_channels,\n",
    "            kernel_size * kernel_size,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "        )\n",
    "\n",
    "        if DeformConv2d is None:\n",
    "            raise RuntimeError(\"DeformConv2d bulunamadı.\")\n",
    "\n",
    "        # torchvision.ops.DeformConv2d modülasyon maskesini doğrudan desteklemiyor olabilir.\n",
    "        # DCNv2 implementasyonlarında genelde farklı bir sınıf var (ModulatedDeformConv2d).\n",
    "        # Burada konsepti göstermek için mask'i dışarıdan uygular gibi düşüneceğiz.\n",
    "        self.dcn = DeformConv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            bias=bias,\n",
    "        )\n",
    "\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.act = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1) Offset ve mask üret\n",
    "        offset = self.offset_conv(x)                       # (B, 2*K*K, H, W)\n",
    "        mask = self.mask_conv(x)                          # (B, K*K, H, W)\n",
    "        mask = torch.sigmoid(mask)                        # [0,1] aralığına sık\n",
    "\n",
    "        # 2) DCN çağrısında bazı implementasyonlar mask'i ayrıca alır:\n",
    "        # out = self.dcn(x, offset, mask)\n",
    "        # Fakat torchvision.ops.DeformConv2d bunu desteklemiyorsa,\n",
    "        # DCNv2 için özel implementasyon kullanmak gerekir.\n",
    "        # Burada sadece kavramsal gösteriyoruz.\n",
    "        out = self.dcn(x, offset)  # mask'siz basit kullanım\n",
    "\n",
    "        # 3) Aktivasyon katmanları\n",
    "        out = self.bn(out)\n",
    "        out = self.act(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e54cb0",
   "metadata": {},
   "source": [
    "## 3. İç Mantığı Anlamak İçin: grid_sample ile Basit DCN Simülasyonu\n",
    "\n",
    "* Gerçekte DeformConv2d içinde olan şeyin bir benzerini, F.grid_sample ile kendimiz yazabiliriz.\n",
    "* Bu hem offset fikrini hem de koordinat sistemini çok netleştirir.\n",
    "\n",
    "Burada:\n",
    "\n",
    "* Giriş: (B, C, H, W)\n",
    "\n",
    "* Base grid: her piksel için normal (sabit) koordinat\n",
    "\n",
    "* Offset: bu grid’e eklenen kayma\n",
    "\n",
    "- grid_sample: mis gibi deformable sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41236750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: torch.Size([1, 3, 32, 32])\n",
      "Output: torch.Size([1, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ToyDeformableSampler(nn.Module):\n",
    "    \"\"\"\n",
    "    Bu sınıf tam DCN değil, sadece 'offset + sampling' mantığını anlamak için.\n",
    "    Fikir:\n",
    "      - Bir offset haritası var: (B, H, W, 2) → (dx, dy)\n",
    "      - Bu offset'i normal bir grid'e ekleyip F.grid_sample ile örnekliyoruz.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x, offset):\n",
    "        \"\"\"\n",
    "        x:      (B, C, H, W)\n",
    "        offset: (B, H, W, 2)  # her piksel için (dx, dy)\n",
    "        \"\"\"\n",
    "        B, C, H, W = x.shape\n",
    "\n",
    "        # 1) Normalized base grid oluştur: [-1,1] aralığında\n",
    "        #    grid_x: soldan sağa -1 → 1\n",
    "        #    grid_y: yukarıdan aşağı -1 → 1\n",
    "        grid_y, grid_x = torch.meshgrid(\n",
    "            torch.linspace(-1, 1, H, device=x.device),\n",
    "            torch.linspace(-1, 1, W, device=x.device),\n",
    "            indexing=\"ij\"\n",
    "        )\n",
    "        base_grid = torch.stack((grid_x, grid_y), dim=-1)  # (H, W, 2)\n",
    "        base_grid = base_grid.unsqueeze(0).repeat(B, 1, 1, 1)  # (B, H, W, 2)\n",
    "\n",
    "        # 2) Offsetleri bu base_grid'e ekle\n",
    "        #    offset de normalized koordinat sisteminde olmalı\n",
    "        #    (gerçekte DCN integer piksel düzleminde çalışıyor; burada görselleştirme için normalleştiriyoruz.)\n",
    "        deformed_grid = base_grid + offset  # (B, H, W, 2)\n",
    "\n",
    "        # 3) grid_sample ile yeni grid'e göre x'ten değer çek\n",
    "        # mode='bilinear', padding_mode='zeros' vs. ayarlanabilir.\n",
    "        sampled = F.grid_sample(\n",
    "            x,\n",
    "            deformed_grid,\n",
    "            mode=\"bilinear\",\n",
    "            padding_mode=\"border\",\n",
    "            align_corners=True,\n",
    "        )\n",
    "        # sampled: (B, C, H, W)\n",
    "\n",
    "        return sampled\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    B, C, H, W = 1, 3, 32, 32\n",
    "    x = torch.randn(B, C, H, W)\n",
    "\n",
    "    # Basit bir offset haritası üretelim: tüm görüntüyü hafif sağa kaydırıyoruz\n",
    "    offset = torch.zeros(B, H, W, 2)\n",
    "    offset[..., 0] = 0.1  # x yönünde kayma\n",
    "    offset[..., 1] = 0.0  # y yönü sabit\n",
    "\n",
    "    sampler = ToyDeformableSampler()\n",
    "    y = sampler(x, offset)\n",
    "    print(\"Input:\", x.shape)\n",
    "    print(\"Output:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e617507c",
   "metadata": {},
   "source": [
    "## 4. Backbone’a Entegre Ederken Kod Yapısı Nasıl Olur?\n",
    "\n",
    "* Mesela diyelim ki, kendi CNN’inde şöyle bir blok var:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7073f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm2d(out_channels)\n",
    "        self.act   = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.act(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += identity\n",
    "        out = self.act(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7e0f57",
   "metadata": {},
   "source": [
    "**Bunu DCN’le değiştirmek istersek:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2106751",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeformableBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = DeformableConvBlock(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "        )  # DCN blok\n",
    "        self.conv2 = DeformableConvBlock(\n",
    "            out_channels,\n",
    "            out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "        )\n",
    "\n",
    "        self.proj = None\n",
    "        if in_channels != out_channels:\n",
    "            # Kanal sayısı uymazsa, identity'yi projeksiyonla çevir.\n",
    "            self.proj = nn.Conv2d(in_channels, out_channels, 1, bias=False)\n",
    "\n",
    "        self.act = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x if self.proj is None else self.proj(x)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        out = out + identity\n",
    "        out = self.act(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ecadc7",
   "metadata": {},
   "source": [
    "Burada çok net:\n",
    "\n",
    "* Sadece nn.Conv2d yerine DeformableConvBlock koyuyoruz.\n",
    "\n",
    "* Geri kalanı birebir residual block mantığı."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797c7319",
   "metadata": {},
   "source": [
    "---\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a26abf",
   "metadata": {},
   "source": [
    "#  Neden 2 * kernel_size * kernel_size yazdık?\n",
    "\n",
    "Çünkü deformable conv, her kernel örnekleme noktası için 2 tane offset ister:\n",
    "\n",
    "* Δx (sağa-sola kayma)\n",
    "\n",
    "* Δy (yukarı-aşağı kayma)\n",
    "\n",
    "* Kernel boyutu K×K ise toplam K*K adet örnekleme noktası vardır.\n",
    "\n",
    "Her nokta için 2 değer (dx, dy) gerektiği için:\n",
    "\n",
    "offset kanal sayısı =  2 × (K×K)\n",
    "\n",
    "Örnekler:\n",
    "\n",
    "* K=3 → K*K = 9 nokta var\n",
    "\n",
    "  → 2*9 = 18 kanal offset çıkar.\n",
    "\n",
    "* K=5 → 25 nokta\n",
    "\n",
    "→ 2*25 = 50 kanal offset çıkar.\n",
    "\n",
    "### Bu kanallar neyi temsil ediyor?\n",
    "\n",
    "Offset conv’un çıktısı şu şekildedir:\n",
    "```python\n",
    "offset.shape = (B, 2*K*K, H_out, W_out)\n",
    "```\n",
    "\n",
    "Bu 2*K*K kanal aslında şunun gibi düşün:\n",
    "\n",
    "* İlk K*K kanal: tüm noktaların Δx değerleri\n",
    "\n",
    "* Son K*K kanal: tüm noktaların Δy değerleri\n",
    "\n",
    "Yani her konum (i,j) için model şunu öğreniyor:\n",
    "\n",
    "* “3×3 kernelin 9 noktasını, bu konumda şu kadar sağa-sola ve yukarı-aşağı kaydır.”\n",
    "\n",
    "Bu yüzden 2*kernel*kernel zorunlu. Başka sayı verirsen DCN katmanı offset’i doğru okuyamaz.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f736257",
   "metadata": {},
   "source": [
    "----\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
