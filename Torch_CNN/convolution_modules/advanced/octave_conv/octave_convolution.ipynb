{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f01c578",
   "metadata": {},
   "source": [
    "# Octave Convolution (OctConv)\n",
    "\n",
    "Bu notebook’ta **Octave Convolution (OctConv)** kavramını sıfırdan, **neden ortaya çıktığını**, **nasıl çalıştığını**, **hangi hiperparametrelerle kontrol edildiğini** ve **PyTorch ile nasıl uygulanacağını** adım adım inceleyeceğiz.\n",
    "\n",
    "## Hedefler\n",
    "- Feature map’lerdeki **yüksek frekans / düşük frekans** bilgisini anlamak\n",
    "- OctConv’un **kanalları iki bantta (High/Low)** temsil etme fikrini kavramak\n",
    "- `alpha` (α) parametresinin ne olduğunu ve pratik etkisini görmek\n",
    "- OctConv’un içindeki dört yolu (H→H, H→L, L→H, L→L) netleştirmek\n",
    "- PyTorch implementasyonu ile **çalışan** örnek kodlar elde etmek\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172251a9",
   "metadata": {},
   "source": [
    "## 1) Motivasyon: Neden OctConv?\n",
    "\n",
    "Klasik konvolüsyonlarda giriş feature map’inin tamamı **aynı uzamsal çözünürlükte (H×W)** işlenir.\n",
    "\n",
    "Fakat CNN feature map’leri şunu gösterir:\n",
    "- Bazı kanallar **detay/kenar/tekstür** taşır → **yüksek frekans** (High-Freq)\n",
    "- Bazı kanallar **genel şekil, geniş alan bağlamı** taşır → **düşük frekans** (Low-Freq)\n",
    "\n",
    "Low-freq bilgi genellikle **daha düşük uzamsal çözünürlükte** saklanabilir.\n",
    "\n",
    "OctConv fikri:\n",
    "> Kanalları iki gruba ayır: **High (H)** ve **Low (L)**.\n",
    ">\n",
    "> Low kanalları **daha düşük çözünürlükte** tut (örn. H/2 × W/2).\n",
    ">\n",
    "> Böylece hesap yükü (FLOP) ve bellek hareketi azalır.\n",
    "\n",
    "Bu fikir özellikle büyük backbone’larda FLOP düşürmek için değerlidir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be285d80",
   "metadata": {},
   "source": [
    "## 2) Frekans Mantığı: High vs Low\n",
    "\n",
    "Frekans burada sinyal işleme anlamında sezgisel kullanılır:\n",
    "\n",
    "- **High-Frequency (yüksek frekans):**\n",
    "  - Keskin değişimler, kenarlar, ince detaylar\n",
    "  - Uzamsal çözünürlüğe ihtiyaç duyar (H×W)\n",
    "\n",
    "- **Low-Frequency (düşük frekans):**\n",
    "  - Yavaş değişim, geniş bağlam, global şekil\n",
    "  - Daha düşük çözünürlükte temsil edilebilir (H/2×W/2)\n",
    "\n",
    "OctConv, bu ayrımı **kanal düzeyinde** yapar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f2d138",
   "metadata": {},
   "source": [
    "## 3) OctConv’un Ana Parametresi: α (alpha)\n",
    "\n",
    "OctConv’da kanalların ne kadarı Low band’a gidecek bunu **α** belirler.\n",
    "\n",
    "- Giriş kanalı sayısı: `C_in`\n",
    "- Çıkış kanalı sayısı: `C_out`\n",
    "\n",
    "Low bant kanal sayıları:\n",
    "- `C_in_L = α_in * C_in`\n",
    "- `C_out_L = α_out * C_out`\n",
    "\n",
    "High bant kanal sayıları:\n",
    "- `C_in_H = C_in - C_in_L`\n",
    "- `C_out_H = C_out - C_out_L`\n",
    "\n",
    "Tipik kullanım:\n",
    "- `α` genelde 0.25 veya 0.5 gibi seçilir.\n",
    "\n",
    "**α arttıkça:**\n",
    "- Low frekans kanalları artar → daha çok hesap düşük çözünürlükte yapılır\n",
    "- FLOP azalabilir ama detay taşıyan kapasite düşebilir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3efbcb4",
   "metadata": {},
   "source": [
    "## 4) OctConv İç Yapısı: 4 Akış (H→H, H→L, L→H, L→L)\n",
    "\n",
    "OctConv, girişte iki bant alır: `(X_H, X_L)`.\n",
    "Çıkışta da iki bant üretir: `(Y_H, Y_L)`.\n",
    "\n",
    "### 4 yol\n",
    "1. **H → H:** High’tan High’a normal conv (aynı çözünürlük)\n",
    "2. **H → L:** High’tan Low’a bilgi aktarımı\n",
    "   - Önce downsample (örn. avgpool), sonra conv\n",
    "3. **L → H:** Low’tan High’a bilgi aktarımı\n",
    "   - Conv, sonra upsample (örn. nearest/bilinear)\n",
    "4. **L → L:** Low’tan Low’a conv (düşük çözünürlükte)\n",
    "\n",
    "Sezgisel formül:\n",
    "\n",
    "$Y_H = f_{H\\to H}(X_H) + \\mathrm{Up}(f_{L\\to H}(X_L))$\n",
    "\n",
    "$Y_L = f_{L\\to L}(X_L) + f_{H\\to L}(\\mathrm{Down}(X_H))$\n",
    "\n",
    "Burada `f`'ler konvolüsyon işlemleridir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bb960d",
   "metadata": {},
   "source": [
    "## 5) Pratikte OctConv Nasıl Kullanılır?\n",
    "\n",
    "OctConv genelde 3 senaryoda kullanılır:\n",
    "\n",
    "### A) İlk OctConv (girişte tek bant var)\n",
    "- Giriş sadece High’tır: `X_L` yok.\n",
    "- `X_H`'ın bir kısmı downsample edilerek Low bant oluşturulur.\n",
    "\n",
    "### B) Ara OctConv (girişte iki bant var)\n",
    "- Giriş `(X_H, X_L)` olarak gelir.\n",
    "- Çıkış yine `(Y_H, Y_L)` üretir.\n",
    "\n",
    "### C) Son OctConv (çıkışta tek bant istersin)\n",
    "- Çıkışta Low bantı High’a upsample edip birleştirirsin.\n",
    "- Böylece klasik katmanlara geri dönersin.\n",
    "\n",
    "Bu notebook’ta, en anlaşılır olan **Ara OctConv** yapısını kodlayacağız.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3346a0c8",
   "metadata": {},
   "source": [
    "## 6) PyTorch: OctConv Implementasyonu (Çalışan)\n",
    "\n",
    "Aşağıdaki sınıf:\n",
    "- Girdi: `(x_h, x_l)` (Low yoksa `x_l=None` verilebilir)\n",
    "- Çıktı: `(y_h, y_l)`\n",
    "\n",
    "Basit ve öğretici olması için:\n",
    "- Downsample: `AvgPool2d(2)`\n",
    "- Upsample: `F.interpolate(scale_factor=2, mode='nearest')`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15200b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_h: torch.Size([2, 32, 32, 32]) x_l: torch.Size([2, 32, 16, 16])\n",
      "y_h: torch.Size([2, 64, 32, 32]) y_l: torch.Size([2, 64, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class OctaveConv2d(nn.Module):\n",
    "    def __init__(self, cin, cout, kernel_size=3, stride=1, padding=1,\n",
    "                 alpha_in=0.5, alpha_out=0.5, bias=False):\n",
    "        super().__init__()\n",
    "\n",
    "        assert 0.0 <= alpha_in <= 1.0\n",
    "        assert 0.0 <= alpha_out <= 1.0\n",
    "\n",
    "        self.alpha_in = alpha_in\n",
    "        self.alpha_out = alpha_out\n",
    "        self.stride = stride\n",
    "\n",
    "        cin_l = int(round(cin * alpha_in))\n",
    "        cin_h = cin - cin_l\n",
    "\n",
    "        cout_l = int(round(cout * alpha_out))\n",
    "        cout_h = cout - cout_l\n",
    "\n",
    "        self.cin_h, self.cin_l = cin_h, cin_l\n",
    "        self.cout_h, self.cout_l = cout_h, cout_l\n",
    "\n",
    "        self.down = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.hh = nn.Conv2d(cin_h, cout_h, kernel_size, stride=stride, padding=padding, bias=bias) if (cin_h > 0 and cout_h > 0) else None\n",
    "        self.hl = nn.Conv2d(cin_h, cout_l, kernel_size, stride=stride, padding=padding, bias=bias) if (cin_h > 0 and cout_l > 0) else None\n",
    "        self.lh = nn.Conv2d(cin_l, cout_h, kernel_size, stride=stride, padding=padding, bias=bias) if (cin_l > 0 and cout_h > 0) else None\n",
    "        self.ll = nn.Conv2d(cin_l, cout_l, kernel_size, stride=stride, padding=padding, bias=bias) if (cin_l > 0 and cout_l > 0) else None\n",
    "\n",
    "    def forward(self, x_h, x_l=None):\n",
    "        y_h = 0\n",
    "        y_l = 0\n",
    "\n",
    "        if self.hh is not None and x_h is not None:\n",
    "            y_h = y_h + self.hh(x_h)\n",
    "\n",
    "        if self.hl is not None and x_h is not None:\n",
    "            x_h_down = self.down(x_h)\n",
    "            y_l = y_l + self.hl(x_h_down)\n",
    "\n",
    "        if self.ll is not None and x_l is not None:\n",
    "            y_l = y_l + self.ll(x_l)\n",
    "\n",
    "        if self.lh is not None and x_l is not None:\n",
    "            y_lh = self.lh(x_l)\n",
    "            y_lh_up = F.interpolate(y_lh, scale_factor=2, mode='nearest')\n",
    "            y_h = y_h + y_lh_up\n",
    "\n",
    "        if isinstance(y_h, int):\n",
    "            y_h = None\n",
    "        if isinstance(y_l, int):\n",
    "            y_l = None\n",
    "\n",
    "        return y_h, y_l\n",
    "\n",
    "\n",
    "# Hızlı test\n",
    "B = 2\n",
    "cin, cout = 64, 128\n",
    "alpha = 0.5\n",
    "cin_l = int(round(cin * alpha))\n",
    "cin_h = cin - cin_l\n",
    "\n",
    "x_h = torch.randn(B, cin_h, 32, 32)\n",
    "x_l = torch.randn(B, cin_l, 16, 16)\n",
    "\n",
    "oct = OctaveConv2d(cin, cout, alpha_in=alpha, alpha_out=alpha)\n",
    "y_h, y_l = oct(x_h, x_l)\n",
    "print('x_h:', x_h.shape, 'x_l:', x_l.shape)\n",
    "print('y_h:', None if y_h is None else y_h.shape, 'y_l:', None if y_l is None else y_l.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d75823",
   "metadata": {},
   "source": [
    "## 7) OctConv Bloğu: OctConv + BN + Activation\n",
    "\n",
    "Backbone’da kullanmak için genelde BN/Activation eklenir.\n",
    "Aşağıdaki blok, High ve Low bantlara ayrı BN uygular.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8710c8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block y_h: torch.Size([2, 64, 32, 32])\n",
      "block y_l: torch.Size([2, 64, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "class OctaveConvBlock(nn.Module):\n",
    "    def __init__(self, cin, cout, alpha_in=0.5, alpha_out=0.5,\n",
    "                 kernel_size=3, stride=1, padding=1):\n",
    "        super().__init__()\n",
    "        self.oct = OctaveConv2d(cin, cout, kernel_size, stride, padding, alpha_in, alpha_out, bias=False)\n",
    "\n",
    "        self.bn_h = nn.BatchNorm2d(self.oct.cout_h) if self.oct.cout_h > 0 else None\n",
    "        self.bn_l = nn.BatchNorm2d(self.oct.cout_l) if self.oct.cout_l > 0 else None\n",
    "        self.act = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x_h, x_l=None):\n",
    "        y_h, y_l = self.oct(x_h, x_l)\n",
    "        if y_h is not None and self.bn_h is not None:\n",
    "            y_h = self.act(self.bn_h(y_h))\n",
    "        if y_l is not None and self.bn_l is not None:\n",
    "            y_l = self.act(self.bn_l(y_l))\n",
    "        return y_h, y_l\n",
    "\n",
    "\n",
    "# Test\n",
    "block = OctaveConvBlock(64, 128, alpha_in=0.5, alpha_out=0.5)\n",
    "y_h, y_l = block(x_h, x_l)\n",
    "print('block y_h:', y_h.shape if y_h is not None else None)\n",
    "print('block y_l:', y_l.shape if y_l is not None else None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06936b8",
   "metadata": {},
   "source": [
    "## 8) Mini Model Örneği: OctConv Kullanan Basit CNN\n",
    "\n",
    "Bu model:\n",
    "- Stem ile 64 kanal üretir\n",
    "- High/Low bantlara split eder\n",
    "- 2 OctConv blok uygular\n",
    "- Low’u upsample edip High ile birleştirir\n",
    "- GlobalAvgPool + Linear ile sınıflandırır\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba40a1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out: torch.Size([4, 10])\n"
     ]
    }
   ],
   "source": [
    "class MiniOctNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=10, alpha=0.5):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.b1 = OctaveConvBlock(64, 128, alpha_in=alpha, alpha_out=alpha)\n",
    "        self.b2 = OctaveConvBlock(128, 128, alpha_in=alpha, alpha_out=alpha)\n",
    "\n",
    "        self.down = nn.AvgPool2d(2)\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def split_hl(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        c_l = int(round(C * self.alpha))\n",
    "        c_h = C - c_l\n",
    "        x_h = x[:, :c_h]\n",
    "        x_l = self.down(x[:, c_h:]) if c_l > 0 else None\n",
    "        return x_h, x_l\n",
    "\n",
    "    def merge_hl(self, x_h, x_l):\n",
    "        if x_l is None:\n",
    "            return x_h\n",
    "        x_l_up = F.interpolate(x_l, scale_factor=2, mode='nearest')\n",
    "        return torch.cat([x_h, x_l_up], dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x_h, x_l = self.split_hl(x)\n",
    "        x_h, x_l = self.b1(x_h, x_l)\n",
    "        x_h, x_l = self.b2(x_h, x_l)\n",
    "        x = self.merge_hl(x_h, x_l)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "# Test\n",
    "m = MiniOctNet(in_channels=3, num_classes=10, alpha=0.5)\n",
    "dummy = torch.randn(4, 3, 32, 32)\n",
    "out = m(dummy)\n",
    "print('out:', out.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f692cff0",
   "metadata": {},
   "source": [
    "## 9) Parametre Karşılaştırması (Basit)\n",
    "\n",
    "OctConv’un parametreleri dört yolun toplamıdır.\n",
    "Bu toplam çoğu zaman klasik conv ile aynı mertebededir.\n",
    "\n",
    "Asıl avantaj **FLOP** tarafında gelir çünkü Low bant konvolüsyonları daha düşük çözünürlükte çalışır.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23d4ed8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv params: 73728\n",
      "OctConv params: 73728\n"
     ]
    }
   ],
   "source": [
    "def conv_params(cin, cout, k):\n",
    "    return cin * cout * k * k\n",
    "\n",
    "def octconv_params(cin, cout, k, alpha_in=0.5, alpha_out=0.5):\n",
    "    cin_l = int(round(cin * alpha_in)); cin_h = cin - cin_l\n",
    "    cout_l = int(round(cout * alpha_out)); cout_h = cout - cout_l\n",
    "    return (cin_h*cout_h + cin_h*cout_l + cin_l*cout_h + cin_l*cout_l) * k*k\n",
    "\n",
    "cin, cout, k, alpha = 64, 128, 3, 0.5\n",
    "print('Conv params:', conv_params(cin, cout, k))\n",
    "print('OctConv params:', octconv_params(cin, cout, k, alpha, alpha))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af7f122",
   "metadata": {},
   "source": [
    "## 10) Ne Zaman Mantıklı?\n",
    "\n",
    "- Erken/orta aşamada çözünürlük yüksekken (H×W büyük) FLOP düşürmek için iyi olabilir.\n",
    "- Çok büyük α seçmek detay kaybı riskini artırır.\n",
    "- İki bant yönetimi kod karmaşıklığını artırır.\n",
    "\n",
    "Yine de OctConv, **\"feature map’in her kanalı aynı çözünürlükte tutulmak zorunda değil\"** fikrini öğretmesi açısından çok değerlidir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c1c9c3",
   "metadata": {},
   "source": [
    "## 11) Özet\n",
    "\n",
    "- OctConv, kanalları **High/Low** frekans olarak ayırır.\n",
    "- Low bant düşük çözünürlükte işlenir → **FLOP azalır**.\n",
    "- 4 akış: H→H, H→L, L→H, L→L.\n",
    "- `α` low kanal oranını belirler.\n",
    "- Pratikte girişte split, ortada OctConv, çıkışta merge yapılır.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
