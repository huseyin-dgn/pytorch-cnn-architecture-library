{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4c3c50b",
   "metadata": {},
   "source": [
    "# Octave Convolution Kod İncelemesi + Örnek Model (OctNet)\n",
    "\n",
    "Bu notebook’ta iki şeyi birlikte yapacağız:\n",
    "\n",
    "1) **Octave Convolution (OctConv)** kod yapısını *satır satır mantığıyla* inceleyeceğiz.\n",
    "2) OctConv kullanan **tam bir mini model** (backbone + head) yazacağız ve çalıştıracağız.\n",
    "\n",
    "Notebook içinde:\n",
    "- OctConv’un 4 yolunu (H→H, H→L, L→H, L→L) kodda nerede yaptığımızı net göstereceğim.\n",
    "- `alpha` (α) kanal bölme mantığını kod üzerinde takip edeceğiz.\n",
    "- Forward sırasında **tensor şekillerini** (shape) print ederek akışı gözleyeceğiz.\n",
    "\n",
    "Not: Bu notebook eğitim amaçlıdır; performans optimizasyonu değil, **anlaşılır tasarım** önceliklidir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7630d3e0",
   "metadata": {},
   "source": [
    "## 1) OctConv’un Temel Fikri (1 paragraf)\n",
    "\n",
    "Feature map kanallarının bir kısmı **High** bantta (tam çözünürlük H×W), bir kısmı **Low** bantta (genelde H/2×W/2) tutulur.\n",
    "OctConv, girişte `(x_h, x_l)` alıp çıkışta `(y_h, y_l)` üretir.\n",
    "İçeride 4 akış vardır:\n",
    "\n",
    "- **H→H**: High’dan High’a (aynı çözünürlük)\n",
    "- **H→L**: High’dan Low’a (downsample + conv)\n",
    "- **L→L**: Low’dan Low’a (düşük çözünürlükte conv)\n",
    "- **L→H**: Low’dan High’a (conv + upsample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4aafaa",
   "metadata": {},
   "source": [
    "## 2) Kullanacağımız Yardımcı Operasyonlar\n",
    "\n",
    "OctConv’u basitçe kurmak için:\n",
    "- **Downsample:** `AvgPool2d(2)`\n",
    "- **Upsample:** `F.interpolate(scale_factor=2, mode='nearest')`\n",
    "\n",
    "Bu iki operasyon, High ve Low bantlar arasında geçişi sağlar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aff771d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x214add9abb0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08cde14",
   "metadata": {},
   "source": [
    "## 3) OctaveConv2d (Çekirdek Katman) — Kod İncelemesi\n",
    "\n",
    "Bu sınıf OctConv’un tam kendisi.\n",
    "\n",
    "### 3.1) `__init__` içinde yapılanlar\n",
    "\n",
    "1) `alpha_in`, `alpha_out` ile kanal bölme (High/Low) miktarı belirlenir.\n",
    "2) `cin_h, cin_l, cout_h, cout_l` hesaplanır.\n",
    "3) 4 akış için conv tanımlanır:\n",
    "   - `hh`: H→H\n",
    "   - `hl`: H→L\n",
    "   - `ll`: L→L\n",
    "   - `lh`: L→H\n",
    "\n",
    "### 3.2) `forward` içinde yapılanlar\n",
    "\n",
    "Her akışın çıktısı toplanarak `y_h` ve `y_l` oluşturulur.\n",
    "Yani kodun mantığı şu iki satıra indirgenir:\n",
    "\n",
    "- `y_h = HH(x_h) + Up(LH(x_l))`\n",
    "- `y_l = LL(x_l) + HL(Down(x_h))`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc95196f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OctaveConv2d(nn.Module):\n",
    "    \"\"\"Octave Convolution (Ara katman versiyonu)\n",
    "\n",
    "    Girdi:\n",
    "        x_h: (B, C_h, H, W)\n",
    "        x_l: (B, C_l, H/2, W/2) veya None\n",
    "\n",
    "    Çıktı:\n",
    "        y_h: (B, C_out_h, H_out, W_out) veya None\n",
    "        y_l: (B, C_out_l, H_out/2, W_out/2) veya None\n",
    "\n",
    "    Not:\n",
    "        Bu implementasyon eğitim amaçlı: down=AvgPool2d, up=nearest.\n",
    "    \"\"\"\n",
    "    def __init__(self, cin, cout, kernel_size=3, stride=1, padding=1,\n",
    "                 alpha_in=0.5, alpha_out=0.5, bias=False):\n",
    "        super().__init__()\n",
    "\n",
    "        assert 0.0 <= alpha_in <= 1.0\n",
    "        assert 0.0 <= alpha_out <= 1.0\n",
    "\n",
    "        self.alpha_in = alpha_in\n",
    "        self.alpha_out = alpha_out\n",
    "        self.stride = stride\n",
    "\n",
    "        # 1) Kanal bölme\n",
    "        cin_l = int(round(cin * alpha_in))\n",
    "        cin_h = cin - cin_l\n",
    "        cout_l = int(round(cout * alpha_out))\n",
    "        cout_h = cout - cout_l\n",
    "\n",
    "        self.cin_h, self.cin_l = cin_h, cin_l\n",
    "        self.cout_h, self.cout_l = cout_h, cout_l\n",
    "\n",
    "        # 2) Bant geçişleri için downsample\n",
    "        self.down = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # 3) 4 akış için conv'lar\n",
    "        # Kanal sayısı 0 ise ilgili yol kullanılmaz (None)\n",
    "        self.hh = nn.Conv2d(cin_h, cout_h, kernel_size, stride=stride, padding=padding, bias=bias) if (cin_h > 0 and cout_h > 0) else None\n",
    "        self.hl = nn.Conv2d(cin_h, cout_l, kernel_size, stride=stride, padding=padding, bias=bias) if (cin_h > 0 and cout_l > 0) else None\n",
    "        self.ll = nn.Conv2d(cin_l, cout_l, kernel_size, stride=stride, padding=padding, bias=bias) if (cin_l > 0 and cout_l > 0) else None\n",
    "        self.lh = nn.Conv2d(cin_l, cout_h, kernel_size, stride=stride, padding=padding, bias=bias) if (cin_l > 0 and cout_h > 0) else None\n",
    "\n",
    "    def forward(self, x_h, x_l=None):\n",
    "        # y_h ve y_l'yi toplama değişkeni olarak başlatıyoruz.\n",
    "        # int başlatıp en sonda None'a çevirmemizin sebebi: bazı yollarda kanal=0 olabilir.\n",
    "        y_h = 0\n",
    "        y_l = 0\n",
    "\n",
    "        # --- H -> H ---\n",
    "        if self.hh is not None and x_h is not None:\n",
    "            y_h = y_h + self.hh(x_h)\n",
    "\n",
    "        # --- H -> L --- (downsample + conv)\n",
    "        if self.hl is not None and x_h is not None:\n",
    "            x_h_down = self.down(x_h)          # (B, C_h, H/2, W/2)\n",
    "            y_l = y_l + self.hl(x_h_down)\n",
    "\n",
    "        # --- L -> L ---\n",
    "        if self.ll is not None and x_l is not None:\n",
    "            y_l = y_l + self.ll(x_l)\n",
    "\n",
    "        # --- L -> H --- (conv + upsample)\n",
    "        if self.lh is not None and x_l is not None:\n",
    "            y_lh = self.lh(x_l)                # (B, C_out_h, H/2, W/2)\n",
    "            y_lh_up = F.interpolate(y_lh, scale_factor=2, mode='nearest')  # (B, C_out_h, H, W)\n",
    "            y_h = y_h + y_lh_up\n",
    "\n",
    "        # Eğer ilgili bant yoksa (0 kanal seçildiyse), y_* int kalır → None yap.\n",
    "        if isinstance(y_h, int):\n",
    "            y_h = None\n",
    "        if isinstance(y_l, int):\n",
    "            y_l = None\n",
    "\n",
    "        return y_h, y_l\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfd32ca",
   "metadata": {},
   "source": [
    "## 4) OctaveConvBlock — OctConv + BN + ReLU\n",
    "\n",
    "Backbone’da pratik kullanım için OctConv’un çıkışlarına BN + aktivasyon ekleriz.\n",
    "High ve Low bantların kanal sayıları farklı olacağı için BN’leri ayrı tutuyoruz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04b53d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OctaveConvBlock(nn.Module):\n",
    "    def __init__(self, cin, cout, alpha_in=0.5, alpha_out=0.5,\n",
    "                 kernel_size=3, stride=1, padding=1):\n",
    "        super().__init__()\n",
    "        self.oct = OctaveConv2d(cin, cout, kernel_size, stride, padding, alpha_in, alpha_out, bias=False)\n",
    "\n",
    "        self.bn_h = nn.BatchNorm2d(self.oct.cout_h) if self.oct.cout_h > 0 else None\n",
    "        self.bn_l = nn.BatchNorm2d(self.oct.cout_l) if self.oct.cout_l > 0 else None\n",
    "        self.act = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x_h, x_l=None):\n",
    "        y_h, y_l = self.oct(x_h, x_l)\n",
    "        if y_h is not None and self.bn_h is not None:\n",
    "            y_h = self.act(self.bn_h(y_h))\n",
    "        if y_l is not None and self.bn_l is not None:\n",
    "            y_l = self.act(self.bn_l(y_l))\n",
    "        return y_h, y_l\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461b7638",
   "metadata": {},
   "source": [
    "## 5) Split / Merge Fonksiyonları (Tek Bant ↔ Çift Bant)\n",
    "\n",
    "OctConv kullanırken tipik akış:\n",
    "\n",
    "1) Stem ile tek bant feature üretirsin: `x` (B, C, H, W)\n",
    "2) Bunu `(x_h, x_l)` diye iki banda ayırırsın (split)\n",
    "3) Birkaç OctConv blok uygularsın\n",
    "4) Çıkışta low bandı upsample edip high ile concat yaparsın (merge)\n",
    "\n",
    "Aşağıdaki iki fonksiyon bu işi yapar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62ee8c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitMergeHL(nn.Module):\n",
    "    def __init__(self, alpha=0.5):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.down = nn.AvgPool2d(2)\n",
    "\n",
    "    def split(self, x):\n",
    "        \"\"\"x: (B, C, H, W) -> (x_h, x_l)\"\"\"\n",
    "        B, C, H, W = x.shape\n",
    "        c_l = int(round(C * self.alpha))\n",
    "        c_h = C - c_l\n",
    "        x_h = x[:, :c_h]\n",
    "        x_l = self.down(x[:, c_h:]) if c_l > 0 else None\n",
    "        return x_h, x_l\n",
    "\n",
    "    def merge(self, x_h, x_l):\n",
    "        \"\"\"(x_h, x_l) -> (B, C, H, W)\"\"\"\n",
    "        if x_l is None:\n",
    "            return x_h\n",
    "        x_l_up = F.interpolate(x_l, scale_factor=2, mode='nearest')\n",
    "        return torch.cat([x_h, x_l_up], dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df042a8e",
   "metadata": {},
   "source": [
    "## 6) OctConv Kullanan Tam Model: `OctNetMini`\n",
    "\n",
    "Bu modelin mimarisi:\n",
    "\n",
    "1) **Stem:** `Conv(3→64)` + BN + ReLU\n",
    "2) **Split:** 64 kanalı (α ile) High/Low’a ayır\n",
    "3) **Backbone:** 2 adet `OctaveConvBlock`\n",
    "4) **Merge:** Low’u upsample edip High ile concat → tek tensöre dön\n",
    "5) **Head:** GlobalAvgPool + Linear\n",
    "\n",
    "Bu mimari “OctConv’u modele nasıl entegre ederim?” sorusunun minimal ama doğru cevabıdır.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88731bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OctNetMini(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=10, alpha=0.5):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.sm = SplitMergeHL(alpha=alpha)\n",
    "\n",
    "        # 1) Stem\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # 2) OctConv backbone\n",
    "        self.b1 = OctaveConvBlock(64, 128, alpha_in=alpha, alpha_out=alpha)\n",
    "        self.b2 = OctaveConvBlock(128, 128, alpha_in=alpha, alpha_out=alpha)\n",
    "\n",
    "        # 3) Head\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x, verbose=False):\n",
    "        x = self.stem(x)  # (B,64,H,W)\n",
    "        if verbose:\n",
    "            print('Stem out:', x.shape)\n",
    "\n",
    "        x_h, x_l = self.sm.split(x)\n",
    "        if verbose:\n",
    "            print('Split x_h:', None if x_h is None else x_h.shape)\n",
    "            print('Split x_l:', None if x_l is None else x_l.shape)\n",
    "\n",
    "        x_h, x_l = self.b1(x_h, x_l)\n",
    "        if verbose:\n",
    "            print('After b1 x_h:', None if x_h is None else x_h.shape)\n",
    "            print('After b1 x_l:', None if x_l is None else x_l.shape)\n",
    "\n",
    "        x_h, x_l = self.b2(x_h, x_l)\n",
    "        if verbose:\n",
    "            print('After b2 x_h:', None if x_h is None else x_h.shape)\n",
    "            print('After b2 x_l:', None if x_l is None else x_l.shape)\n",
    "\n",
    "        x = self.sm.merge(x_h, x_l)\n",
    "        if verbose:\n",
    "            print('Merged x:', x.shape)\n",
    "\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        logits = self.fc(x)\n",
    "        if verbose:\n",
    "            print('Logits:', logits.shape)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5616365d",
   "metadata": {},
   "source": [
    "## 7) Modeli Çalıştır: Shape Takibi\n",
    "\n",
    "Aşağıdaki hücrede `verbose=True` verip forward akışında tüm shape’leri göreceğiz.\n",
    "Bu, kod incelemesinin en net kısmı: **H/Low bantların nasıl aktığını gözle görmek.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d83b9ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stem out: torch.Size([2, 64, 32, 32])\n",
      "Split x_h: torch.Size([2, 32, 32, 32])\n",
      "Split x_l: torch.Size([2, 32, 16, 16])\n",
      "After b1 x_h: torch.Size([2, 64, 32, 32])\n",
      "After b1 x_l: torch.Size([2, 64, 16, 16])\n",
      "After b2 x_h: torch.Size([2, 64, 32, 32])\n",
      "After b2 x_l: torch.Size([2, 64, 16, 16])\n",
      "Merged x: torch.Size([2, 128, 32, 32])\n",
      "Logits: torch.Size([2, 10])\n",
      "\n",
      "Final output: torch.Size([2, 10])\n"
     ]
    }
   ],
   "source": [
    "model = OctNetMini(in_channels=3, num_classes=10, alpha=0.5)\n",
    "x = torch.randn(2, 3, 32, 32)\n",
    "out = model(x, verbose=True)\n",
    "\n",
    "print('\\nFinal output:', out.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9260a72",
   "metadata": {},
   "source": [
    "## 8) Parametre Sayımı (Opsiyonel Kontrol)\n",
    "\n",
    "OctConv’un asıl kazancı FLOP tarafındadır; ama yine de toplam parametreyi görmek faydalıdır.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac5d8c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 224842\n"
     ]
    }
   ],
   "source": [
    "def count_params(m: nn.Module):\n",
    "    return sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
    "\n",
    "print('Trainable params:', count_params(model))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeef47d4",
   "metadata": {},
   "source": [
    "## 9) Kod İnceleme Notları (Kritik Noktalar)\n",
    "\n",
    "1) **`alpha` kanal bölme yapar**\n",
    "- Stem çıkışı 64 kanal.\n",
    "- `alpha=0.5` ise: Low ≈ 32 kanal, High ≈ 32 kanal.\n",
    "- Low bant ayrıca `AvgPool2d(2)` ile **H/2×W/2** çözünürlüğe iner.\n",
    "\n",
    "2) **H→L yolu neden downsample ister?**\n",
    "- Low bant zaten düşük çözünürlükte tutuluyor.\n",
    "- High’tan Low’a bilgi aktarırken çözünürlüğü eşitlemek zorundasın.\n",
    "\n",
    "3) **L→H yolu neden upsample ister?**\n",
    "- Low’tan High’a aktarırken High çözünürlüğe geri çıkmalısın.\n",
    "\n",
    "4) **Toplama (fusion) nerede oluyor?**\n",
    "- High çıkış: `y_h = HH(x_h) + Up(LH(x_l))`\n",
    "- Low çıkış: `y_l = LL(x_l) + HL(Down(x_h))`\n",
    "\n",
    "5) **Merge neden concat?**\n",
    "- En sonda klasik katmanlara dönmek için tek tensör gerekir.\n",
    "- High (H×W) ile upsample edilmiş Low (H×W) kanalda birleştirilir.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
