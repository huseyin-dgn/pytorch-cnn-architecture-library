{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45a537fb",
   "metadata": {},
   "source": [
    "# Ghost Convolution (Ghost Module) — Teori ve Uygulama\n",
    "\n",
    "Bu defterde **Ghost Convolution / Ghost Module** yapısını ayrıntılı şekilde inceleyeceksin:\n",
    "\n",
    "- Ghost Convolution nedir, hangi problemden doğmuştur?\n",
    "- \"Feature redundancy\" (özellik fazlalığı) fikri nedir?\n",
    "- Ghost Module nasıl çalışır: primary features + cheap operations\n",
    "- Normal Conv ile parametre ve FLOPs sezgisel karşılaştırma\n",
    "- PyTorch ile basit bir `GhostConv` implementasyonu\n",
    "- Normal 1×1 Conv ile GhostConv çıktılarının ve parametrelerinin karşılaştırılması\n",
    "\n",
    "Hedef, GhostConv'u sadece \"yeni bir conv tipi\" gibi değil,\n",
    "**neden var, hangi tasarım kararıyla geldi, nasıl optimize ediyor** seviyesinde anlamaktır.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fa0b0f",
   "metadata": {},
   "source": [
    "## 1. Motivasyon: Neden Ghost Convolution?\n",
    "\n",
    "Klasik bir konvolüsyon düşünelim:\n",
    "\n",
    "- Girdi: `(N, C_in, H, W)`\n",
    "- Çıktı: `(N, C_out, H, W)`\n",
    "- Parametre: `k × k × C_in × C_out`\n",
    "\n",
    "Özellikle `C_out` büyük olduğunda hem **parametre sayısı** hem **FLOPs** maliyeti artar.\n",
    "\n",
    "### Gözlem (GhostNet Makalesi):\n",
    "\n",
    "- Konvolüsyon çıktısındaki feature map'lere bakıldığında,\n",
    "- Birçok kanal **yüksek derecede benzer** (redundant),\n",
    "- Yani \"hem pahalı hem çok sayıda\" feature üretmek gereksiz olabilir.\n",
    "\n",
    "Bu gözleme dayanarak soru şudur:\n",
    "\n",
    "> Tüm `C_out` feature map'lerini pahalı konvolüsyonla üretmek zorunda mıyım?\n",
    "> Yoksa az sayıda \"gerçek\" feature üretip,\n",
    "> geri kalanını ucuz işlemlerle türetebilir miyim?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600bbd30",
   "metadata": {},
   "source": [
    "## 2. Ghost Module Temel Fikri\n",
    "\n",
    "Ghost Module, `C_in → C_out` dönüşümünü iki aşamada yapar:\n",
    "\n",
    "1. **Primary Convolution (Gerçek feature'lar)**  \n",
    "   - Girdi: `(N, C_in, H, W)`  \n",
    "   - Çıkış: `(N, C_int, H, W)`  \n",
    "   - Burada `C_int < C_out`. Örneğin `C_int = C_out / ratio`.  \n",
    "   - Bu kısım klasik konvolüsyondur (pahalı kısım).\n",
    "\n",
    "2. **Cheap Operations (Ghost feature'lar)**  \n",
    "   - Girdi: `(N, C_int, H, W)`  \n",
    "   - Ucuz işlemlerle yeni feature map'ler türetilir: `(N, C_ghost, H, W)`  \n",
    "   - Örnek ucuz işlemler:\n",
    "     - Depthwise 3×3 conv\n",
    "     - Pixel shift\n",
    "     - Küçük kernel conv\n",
    "   - Amaç: feature'ların geri kalanını çok düşük maliyetle üretmek.\n",
    "\n",
    "3. **Concat + Slice**  \n",
    "   - `[primary_features, ghost_features]` birleştirilir:  \n",
    "     `(N, C_int + C_ghost, H, W)`  \n",
    "   - Gerekirse `C_out` kanal sayısına kırpılarak son çıktı elde edilir.\n",
    "\n",
    "Bu sayede:\n",
    "\n",
    "- Pahalı konvolüsyon **daha az kanala** uygulanır,\n",
    "- Çıktının geri kalanı \"ghost\" (ucuzdan üretilmiş) feature'lardır.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7756c6e",
   "metadata": {},
   "source": [
    "## 3. Parametre / FLOPs Açısından Sezgi\n",
    "\n",
    "Klasik 1×1 Conv için parametre sayısı:\n",
    "\n",
    "\\[\n",
    "\\text{Param}_{1x1} = C_{in} \\times C_{out}\n",
    "\\]\n",
    "\n",
    "GhostConv için ise:\n",
    "\n",
    "- Primary Conv (1×1):  \n",
    "  \\( C_{in} \\times C_{int} \\)\n",
    "\n",
    "- Cheap Ops (örneğin depthwise 3×3):  \n",
    "  \\( k \\times k \\times C_{int} \\)  (k=3 için `9 × C_int`)\n",
    "\n",
    "Toplam yaklaşık:\n",
    "\n",
    "\\[\n",
    "\\text{Param}_{Ghost} \\approx C_{in} C_{int} + 9 C_{int}\n",
    "\\]\n",
    "\n",
    "Eğer `C_int = C_out / r` seçilirse (örneğin r = 2):\n",
    "\n",
    "- `C_int = C_out / 2`  \n",
    "- Pahalı kısım artık `C_in × (C_out/2)` kadar.\n",
    "- Kalan feature'lar ucuz depthwise'tan gelir.\n",
    "\n",
    "Sonuç:\n",
    "\n",
    "- \\( C_{in} C_{out} \\) yerine yaklaşık \\( C_{in} C_{out} / r \\) civarı maliyet,\n",
    "- Özellikle `C_out` büyük olduğunda fark oldukça anlamlıdır.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4afdfe39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Girdi şekli : torch.Size([1, 32, 32, 32])\n",
      "GhostConv çıkışı: torch.Size([1, 64, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GhostConv(nn.Module):\n",
    "    \"\"\"\n",
    "    Basit Ghost Convolution implementasyonu.\n",
    "\n",
    "    Adımlar:\n",
    "    - Primary conv: C_in -> C_int  (daha az kanal, pahalı kısım)\n",
    "    - Cheap operation (depthwise conv): C_int -> C_ghost\n",
    "    - Concat primary ve ghost, sonra C_out'e kırp\n",
    "    \"\"\"\n",
    "    def __init__(self, c_in, c_out, kernel_size=1, ratio=2, dw_kernel_size=3,\n",
    "                 stride=1, padding=0):\n",
    "        super().__init__()\n",
    "        self.c_out = c_out\n",
    "        self.ratio = ratio\n",
    "\n",
    "        # Dahili kanal sayısı: kaç tane \"gerçek\" feature üreteceğiz?\n",
    "        c_int = int(round(c_out / ratio))\n",
    "        self.c_int = c_int\n",
    "        c_ghost = c_out - c_int\n",
    "\n",
    "        # 1) Primary conv (pahalı kısım)\n",
    "        self.primary_conv = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=c_in,\n",
    "                out_channels=c_int,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=padding,\n",
    "                bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(c_int),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # 2) Cheap operation (ghost feature üretimi) - depthwise conv\n",
    "        if c_ghost > 0:\n",
    "            self.cheap_conv = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels=c_int,\n",
    "                    out_channels=c_ghost,\n",
    "                    kernel_size=dw_kernel_size,\n",
    "                    stride=1,\n",
    "                    padding=dw_kernel_size // 2,\n",
    "                    groups=c_int,   # depthwise\n",
    "                    bias=False\n",
    "                ),\n",
    "                nn.BatchNorm2d(c_ghost),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "        else:\n",
    "            self.cheap_conv = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1) Temel feature'ları üret\n",
    "        x_primary = self.primary_conv(x)   # (N, c_int, H, W)\n",
    "\n",
    "        # 2) Ghost feature'ları üret\n",
    "        if self.cheap_conv is not None:\n",
    "            x_ghost = self.cheap_conv(x_primary)  # (N, c_ghost, H, W)\n",
    "            out = torch.cat([x_primary, x_ghost], dim=1)  # (N, c_int + c_ghost, H, W)\n",
    "        else:\n",
    "            out = x_primary\n",
    "\n",
    "        # 3) Fazla kanal varsa kırp (güvenlik için)\n",
    "        if out.size(1) > self.c_out:\n",
    "            out = out[:, :self.c_out, :, :]\n",
    "\n",
    "        return out\n",
    "\n",
    "# Küçük bir şekil testi\n",
    "x = torch.randn(1, 32, 32, 32)\n",
    "ghost = GhostConv(c_in=32, c_out=64, kernel_size=1, ratio=2, dw_kernel_size=3)\n",
    "\n",
    "y = ghost(x)\n",
    "print(\"Girdi şekli :\", x.shape)\n",
    "print(\"GhostConv çıkışı:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a38d549",
   "metadata": {},
   "source": [
    "## 4. Normal 1×1 Conv ile GhostConv Karşılaştırması\n",
    "\n",
    "Şimdi aynı giriş/çıkış kanal sayıları için:\n",
    "\n",
    "- Normal 1×1 Conv\n",
    "- GhostConv\n",
    "\n",
    "arasındaki parametre sayısını karşılaştıralım.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80217316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal 1x1 Conv parametre sayısı: 2048\n",
      "GhostConv parametre sayısı      : 1440\n",
      "Normal Conv çıktı şekli         : torch.Size([1, 64, 32, 32])\n",
      "GhostConv çıktı şekli           : torch.Size([1, 64, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "def count_params(m):\n",
    "    return sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
    "\n",
    "C_in, C_out = 32, 64\n",
    "x = torch.randn(1, C_in, 32, 32)\n",
    "\n",
    "std_conv = nn.Conv2d(C_in, C_out, kernel_size=1, bias=False)\n",
    "ghost_conv = GhostConv(C_in, C_out, kernel_size=1, ratio=2, dw_kernel_size=3)\n",
    "\n",
    "y_std = std_conv(x)\n",
    "y_ghost = ghost_conv(x)\n",
    "\n",
    "print(\"Normal 1x1 Conv parametre sayısı:\", count_params(std_conv))\n",
    "print(\"GhostConv parametre sayısı      :\", count_params(ghost_conv))\n",
    "print(\"Normal Conv çıktı şekli         :\", y_std.shape)\n",
    "print(\"GhostConv çıktı şekli           :\", y_ghost.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911873bc",
   "metadata": {},
   "source": [
    "## 5. GhostConv Nerede Kullanılır?\n",
    "\n",
    "Ghost Module, özellikle şu senaryolarda tercih edilir:\n",
    "\n",
    "- **GhostNet** gibi hafif (lightweight) mimarilerde,\n",
    "- Mobil / edge cihazlarda,\n",
    "- Yüksek kanal sayılı katmanlarda:\n",
    "  - Normal conv ile parametre ve FLOPs çok yüksek,\n",
    "  - GhostConv ile benzer temsil gücü daha ucuza elde edilebilir.\n",
    "\n",
    "Genel olarak GhostConv, klasik conv'un doğrudan yerine geçecek bir yapı değildir;\n",
    "özellikle performans / maliyet optimizasyonu hedeflendiğinde anlamlı hale gelir.\n",
    "\n",
    "**Özellikle:**\n",
    "- 1×1 Conv yerine GhostConv kullanmak,\n",
    "- Bazı 3×3 Conv katmanlarını GhostConv ile değiştirmek,\n",
    "büyük mimarilerde ciddi parametre tasarrufu sağlar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad69362",
   "metadata": {},
   "source": [
    "## 6. Kısa Özet\n",
    "\n",
    "- GhostConvolution, feature map'lerin önemli bir kısmının **redundant** olduğu fikrinden doğmuştur.\n",
    "- Fikir: \n",
    "  - Az sayıda \"gerçek\" feature'ı pahalı bir conv ile üret,\n",
    "  - Geri kalan feature'ları bu temel feature'lardan **ucuz işlemlerle** türet.\n",
    "- Yapı:\n",
    "  - Primary Conv: `C_in → C_int`\n",
    "  - Cheap Ops (depthwise conv vb.): `C_int → C_ghost`\n",
    "  - Concat + slice: `C_int + C_ghost → C_out`\n",
    "- Sonuç:\n",
    "  - Normal Conv'e göre daha az parametre ve FLOPs,\n",
    "  - Benzer (veya yeterli) temsil gücü.\n",
    "- PyTorch'ta GhostConv yazmak için temel kalıp bu defterde verilmiştir;\n",
    "  bunu kendi backbone'larına entegre ederek pratikte deneyebilirsin.\n",
    "\n",
    "Bu noktadan sonra,\n",
    "aynı fikri tam bir CNN modeli üzerinde kullanmak (örneğin bazı 1x1 conv katmanlarını GhostConv ile değiştirmek),\n",
    "Ghost Module'ü gerçekten içselleştirmenin bir sonraki adımı olacaktır.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
