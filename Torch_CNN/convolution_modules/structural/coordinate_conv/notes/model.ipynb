{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe7b2575",
   "metadata": {},
   "source": [
    "# 1) Geliştirme: CoordConv’u sadece kritik yerlere koyalım\n",
    "\n",
    "CoordConv’u her katmana koymak çoğu zaman gereksiz. En iyi kullanım:\n",
    "\n",
    "* Stem (erken konum bilgisi)\n",
    "\n",
    "* veya Head (koordinat regresyon/heatmap üretimi)\n",
    "\n",
    "Aşağıdaki model: stem’de CoordConv, sonra residual bloklarla devam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00b7ed37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in  : torch.Size([2, 3, 64, 64])\n",
      "stem: torch.Size([2, 32, 32, 32])\n",
      "s1  : torch.Size([2, 64, 16, 16])\n",
      "s2  : torch.Size([2, 128, 8, 8])\n",
      "s3  : torch.Size([2, 256, 4, 4])\n",
      "out : torch.Size([2, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def make_coord_channels(B, H, W, device, dtype, with_r=False):\n",
    "    y = torch.linspace(-1.0, 1.0, steps=H, device=device, dtype=dtype)\n",
    "    x = torch.linspace(-1.0, 1.0, steps=W, device=device, dtype=dtype)\n",
    "    yy, xx = torch.meshgrid(y, x, indexing='ij')\n",
    "    xx = xx[None, None].repeat(B, 1, 1, 1)\n",
    "    yy = yy[None, None].repeat(B, 1, 1, 1)\n",
    "    if with_r:\n",
    "        rr = torch.sqrt(xx**2 + yy**2)\n",
    "        return torch.cat([xx, yy, rr], dim=1)\n",
    "    return torch.cat([xx, yy], dim=1)\n",
    "\n",
    "class CoordConv2d(nn.Module):\n",
    "    def __init__(self, cin, cout, k=3, stride=1, padding=1, with_r=False, bias=False):\n",
    "        super().__init__()\n",
    "        self.with_r = with_r\n",
    "        extra = 3 if with_r else 2\n",
    "        self.conv = nn.Conv2d(cin + extra, cout, k, stride=stride, padding=padding, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        coords = make_coord_channels(B, H, W, device=x.device, dtype=x.dtype, with_r=self.with_r)\n",
    "        return self.conv(torch.cat([x, coords], dim=1))\n",
    "\n",
    "class ConvBNAct(nn.Module):\n",
    "    def __init__(self, cin, cout, k=3, stride=1, padding=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(cin, cout, k, stride=stride, padding=padding, bias=False),\n",
    "            nn.BatchNorm2d(cout),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class BasicResBlock(nn.Module):\n",
    "    def __init__(self, cin, cout, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = ConvBNAct(cin, cout, 3, stride=stride, padding=1)\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(cout, cout, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(cout),\n",
    "        )\n",
    "        self.skip = nn.Identity() if (cin == cout and stride == 1) else nn.Sequential(\n",
    "            nn.Conv2d(cin, cout, 1, stride=stride, bias=False),\n",
    "            nn.BatchNorm2d(cout),\n",
    "        )\n",
    "        self.act = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.conv1(x)\n",
    "        y = self.conv2(y)\n",
    "        y = y + self.skip(x)\n",
    "        return self.act(y)\n",
    "\n",
    "class CoordResNetTiny(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=10, with_r=True):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            CoordConv2d(in_channels, 32, k=3, stride=1, padding=1, with_r=with_r, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.stage1 = BasicResBlock(32, 64, stride=2)\n",
    "        self.stage2 = BasicResBlock(64, 128, stride=2)\n",
    "        self.stage3 = BasicResBlock(128, 256, stride=2)\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x, verbose=False):\n",
    "        if verbose:\n",
    "            print(\"in  :\", x.shape)\n",
    "\n",
    "        x = self.stem(x)\n",
    "        if verbose:\n",
    "            print(\"stem:\", x.shape)\n",
    "\n",
    "        x = self.stage1(x)\n",
    "        if verbose:\n",
    "            print(\"s1  :\", x.shape)\n",
    "\n",
    "        x = self.stage2(x)\n",
    "        if verbose:\n",
    "            print(\"s2  :\", x.shape)\n",
    "\n",
    "        x = self.stage3(x)\n",
    "        if verbose:\n",
    "            print(\"s3  :\", x.shape)\n",
    "\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        out = self.fc(x)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"out :\", out.shape)\n",
    "\n",
    "        return out\n",
    "\n",
    "# test\n",
    "if __name__ == \"__main__\":\n",
    "    m = CoordResNetTiny(with_r=True)\n",
    "    y = m(torch.randn(2,3,64,64), verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc50978",
   "metadata": {},
   "source": [
    "# 2) Geliştirme: CoordConv’u “head”e koyup koordinat regresyonu yaptıralım (CoordConv’un asıl olayı)\n",
    "\n",
    "Eğer hedefimiz “konum çıkarmak” ise (x,y), sınıflandırma yerine bu daha doğru:\n",
    "\n",
    "* Backbone feature çıkarır\n",
    "\n",
    "* Head CoordConv ile (x,y) üretir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0770772c",
   "metadata": {},
   "source": [
    "### Dikkat edilmesi gerekenler\n",
    "\n",
    "* Çıkış: xy ∈ [-1, 1] aralığında 2 değer (x, y)\n",
    "\n",
    "* Eğitimde GT (ground-truth) da aynı aralıkta olmalı.\n",
    "\n",
    "* Loss: SmoothL1Loss (regresyon için sağlam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcd71c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def create_coord_maps(batch_size, height, width, device, dtype, add_radius=False):\n",
    "    y_lin = torch.linspace(-1.0, 1.0, steps=height, device=device, dtype=dtype)\n",
    "    x_lin = torch.linspace(-1.0, 1.0, steps=width,  device=device, dtype=dtype)\n",
    "\n",
    "    yy, xx = torch.meshgrid(y_lin, x_lin, indexing='ij')  # (H,W)\n",
    "\n",
    "    xx = xx[None, None].repeat(batch_size, 1, 1, 1)  # (B,1,H,W)\n",
    "    yy = yy[None, None].repeat(batch_size, 1, 1, 1)  # (B,1,H,W)\n",
    "\n",
    "    if add_radius:\n",
    "        rr = torch.sqrt(xx**2 + yy**2)\n",
    "        return torch.cat([xx, yy, rr], dim=1)  # (B,3,H,W)\n",
    "\n",
    "    return torch.cat([xx, yy], dim=1)          # (B,2,H,W)\n",
    "\n",
    "\n",
    "class CoordConvLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, add_radius=False, bias=False):\n",
    "        super().__init__()\n",
    "        self.add_radius = add_radius\n",
    "        extra = 3 if add_radius else 2\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels + extra,\n",
    "            out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            bias=bias\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        coords = create_coord_maps(\n",
    "            batch_size=b,\n",
    "            height=h,\n",
    "            width=w,\n",
    "            device=x.device,\n",
    "            dtype=x.dtype,\n",
    "            add_radius=self.add_radius\n",
    "        )\n",
    "        x = torch.cat([x, coords], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class ConvBNReLU(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class CoordXYRegressor(nn.Module):\n",
    "    def __init__(self, in_channels=3, add_radius=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = nn.Sequential(\n",
    "            ConvBNReLU(in_channels, 32, 3, 1, 1),\n",
    "            nn.MaxPool2d(2),\n",
    "            ConvBNReLU(32, 64, 3, 2, 1),\n",
    "            ConvBNReLU(64, 128, 3, 2, 1),\n",
    "        )\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            CoordConvLayer(128, 128, kernel_size=3, stride=1, padding=1, add_radius=add_radius, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x, verbose=False):\n",
    "        if verbose: print(\"in      :\", x.shape)\n",
    "\n",
    "        feats = self.backbone(x)\n",
    "        if verbose: print(\"features :\", feats.shape)\n",
    "\n",
    "        h = self.head(feats)\n",
    "        if verbose: print(\"head     :\", h.shape)\n",
    "\n",
    "        h = torch.flatten(h, 1)\n",
    "        xy = torch.tanh(self.fc(h))  # (B,2) in [-1,1]\n",
    "\n",
    "        if verbose: print(\"xy       :\", xy.shape)\n",
    "        return xy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15c30e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in      : torch.Size([8, 3, 64, 64])\n",
      "features : torch.Size([8, 128, 8, 8])\n",
      "head     : torch.Size([8, 128, 1, 1])\n",
      "xy       : torch.Size([8, 2])\n",
      "loss: 0.23944737017154694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hdgn5\\AppData\\Local\\Temp\\ipykernel_16808\\3125360906.py:15: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\autograd\\generated\\python_variable_methods.cpp:837.)\n",
      "  print(\"loss:\", float(loss))\n"
     ]
    }
   ],
   "source": [
    "model = CoordXYRegressor(in_channels=3, add_radius=True)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.SmoothL1Loss()\n",
    "\n",
    "x = torch.randn(8, 3, 64, 64)\n",
    "gt_xy = torch.empty(8, 2).uniform_(-1, 1)  # sahte ground-truth\n",
    "\n",
    "pred_xy = model(x, verbose=True)\n",
    "loss = loss_fn(pred_xy, gt_xy)\n",
    "\n",
    "opt.zero_grad()\n",
    "loss.backward()\n",
    "opt.step()\n",
    "\n",
    "print(\"loss:\", float(loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538b0c5d",
   "metadata": {},
   "source": [
    "# 3) Geliştirme\n",
    "\n",
    "* CoordConv + Attention (SE/CBAM) kombinasyonu.\n",
    "\n",
    "Mantık çok basit ve net:\n",
    " \n",
    "* CoordConv modele mutlak konumu verir (x/y ve opsiyonel r kanalları).\n",
    "\n",
    "* Attention (SE veya CBAM) ise bu yeni gelen bilgiyle birlikte hangi kanal / hangi özellik önemliyse onu yükseltir, gereksizleri bastırır.\n",
    "\n",
    "Yani ikisi beraber:\n",
    "\n",
    "* “Konumu gör” + “doğru özelliğe odaklan”\n",
    "\n",
    "* Özellikle localization / regression işlerinde head kısmında faydalı olur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "403d0ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SeBlock(nn.Module):\n",
    "    def __init__(self, channels, reductions=8):\n",
    "        super().__init__()\n",
    "        hidden = max(1, channels // reductions)\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc1 = nn.Conv2d(channels, hidden, kernel_size=1)\n",
    "        self.fc2 = nn.Conv2d(hidden, channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        s = self.pool(x)\n",
    "        s = F.relu(self.fc1(s), inplace=True)\n",
    "        s = torch.sigmoid(self.fc2(s))\n",
    "        return x * s\n",
    "\n",
    "def cords(B, H, W, device, dtype, add_rad=False):\n",
    "    y = torch.linspace(-1.0, 1.0, steps=H, device=device, dtype=dtype)\n",
    "    x = torch.linspace(-1.0, 1.0, steps=W, device=device, dtype=dtype)\n",
    "\n",
    "    yy, xx = torch.meshgrid(y, x, indexing=\"ij\")  # (H,W)\n",
    "\n",
    "    xx = xx[None, None].repeat(B, 1, 1, 1)  # (B,1,H,W)\n",
    "    yy = yy[None, None].repeat(B, 1, 1, 1)  # (B,1,H,W)\n",
    "\n",
    "    if add_rad:\n",
    "        rr = torch.sqrt(xx**2 + yy**2)\n",
    "        return torch.cat([xx, yy, rr], dim=1)  # (B,3,H,W)\n",
    "    return torch.cat([xx, yy], dim=1)          # (B,2,H,W)\n",
    "\n",
    "class CordConv(nn.Module):\n",
    "    def __init__(self, cin, cout, k=3, stride=1, padding=1, add_rad=False, bias=False):\n",
    "        super().__init__()\n",
    "        self.add_rad = add_rad\n",
    "        extras = 3 if add_rad else 2\n",
    "        self.conv_1 = nn.Conv2d(cin + extras, cout, kernel_size=k, stride=stride, padding=padding, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        coords = cords(b, h, w, device=x.device, dtype=x.dtype, add_rad=self.add_rad)\n",
    "        x = torch.cat([x, coords], dim=1)\n",
    "        return self.conv_1(x)\n",
    "\n",
    "class ConvBNReLU(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class CoordXYRegr(nn.Module):\n",
    "    def __init__(self, in_channels=3, add_rad=True, se_reduction=10):\n",
    "        super().__init__()\n",
    "        self.backbone = nn.Sequential(\n",
    "            ConvBNReLU(in_channels, 32, 3, 1, 1),\n",
    "            nn.MaxPool2d(2),\n",
    "            ConvBNReLU(32, 64, 3, 2, 1),\n",
    "            ConvBNReLU(64, 128, 3, 2, 1),\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            CordConv(128, 128, k=3, stride=1, padding=1, add_rad=add_rad, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            SeBlock(128, reductions=se_reduction),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "        )\n",
    "        self.fc = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x, verbose=False):\n",
    "        if verbose: print(\"in      :\", x.shape)\n",
    "        feats = self.backbone(x)\n",
    "        if verbose: print(\"features :\", feats.shape)\n",
    "        h = self.head(feats)\n",
    "        if verbose: print(\"head     :\", h.shape)\n",
    "        h = torch.flatten(h, 1)\n",
    "        xy = torch.tanh(self.fc(h))\n",
    "        if verbose: print(\"xy       :\", xy.shape)\n",
    "        return xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f4faf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in      : torch.Size([8, 3, 64, 64])\n",
      "features : torch.Size([8, 128, 8, 8])\n",
      "head     : torch.Size([8, 128, 1, 1])\n",
      "xy       : torch.Size([8, 2])\n",
      "torch.Size([8, 2])\n"
     ]
    }
   ],
   "source": [
    "m = CoordXYRegr(in_channels=3, add_rad=True)\n",
    "x = torch.randn(8, 3, 64, 64)\n",
    "y = m(x, verbose=True)\n",
    "print(y.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
