{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4b4151b",
   "metadata": {},
   "source": [
    "# RepVGG — Eğitimde Çok Dal, Inference’ta Tek 3×3 (Re-parameterization)\n",
    "\n",
    "Bu notebook’ta **RepVGG** fikrini sıfırdan ve uygulamalı öğreneceğiz.\n",
    "\n",
    "## Bu notebook sonunda şunları net bileceksin\n",
    "1) RepVGG bir \"conv türü\" değil, bir **mimari/deploy fikri**\n",
    "2) Training-time block (3×3 + 1×1 + identity) nasıl çalışır?\n",
    "3) BatchNorm (BN) folding nedir?\n",
    "4) Multi-branch → **tek 3×3 Conv** dönüşümü (re-parameterization)\n",
    "5) Dönüşümün doğrulanması (çıktılar neredeyse aynı mı?)\n",
    "6) RepVGG kullanan mini model\n",
    "\n",
    "Not: RepVGG’in olayı \"eğitimde kolay öğren, inference’ta hızlı koş\" yaklaşımıdır.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d431db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.9.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(0)\n",
    "print('torch:', torch.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef94599c",
   "metadata": {},
   "source": [
    "---\n",
    "## 1) RepVGG Nedir?\n",
    "\n",
    "RepVGG’in ana fikri:\n",
    "- **Training zamanında** bir blok içinde birden fazla dal (branch) kullan.\n",
    "- **Inference zamanında** bu dalları matematiksel olarak birleştir ve tek bir 3×3 conv’a indir.\n",
    "\n",
    "### Neden?\n",
    "- Training’de multi-branch yapı + BN genelde öğrenmeyi kolaylaştırır.\n",
    "- Inference’ta branch’lar ve BN operasyonları hız/latency için kötüdür.\n",
    "\n",
    "RepVGG: \"Training’i rahatlat, deploy’u hızlandır\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad20631",
   "metadata": {},
   "source": [
    "---\n",
    "## 2) Training-time RepVGG Block Yapısı\n",
    "\n",
    "Tipik RepVGG bloğu (stride=1 ise):\n",
    "\n",
    "```bash\n",
    "             ┌─ Conv3×3 + BN ─┐\n",
    "x ───────────┼─ Conv1×1 + BN ─┼─ (+) ─ ReLU\n",
    "             └─ Identity + BN ─┘\n",
    "```\n",
    "\n",
    "stride=2 olursa identity dalı yoktur (shape uymadığı için).\n",
    "\n",
    "Bu dalların hepsi **lineer** işlemlerdir (Conv ve BN lineer),\n",
    "bu yüzden **tek bir Conv** altında birleştirilebilir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71dd7f6",
   "metadata": {},
   "source": [
    "---\n",
    "## 3) BatchNorm Folding (BN’yi Conv’a Katlamak)\n",
    "\n",
    "BN inference formu:\n",
    "\n",
    "$y = \\gamma \\cdot \\frac{x - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}} + \\beta$\n",
    "\n",
    "Eğer $x = Conv(z, W) + b$ ise, BN ile birleşip yeni conv üretir:\n",
    "\n",
    "$W' = W \\cdot \\frac{\\gamma}{\\sqrt{\\sigma^2 + \\epsilon}}$\n",
    "\n",
    "$b' = (b - \\mu) \\cdot \\frac{\\gamma}{\\sqrt{\\sigma^2 + \\epsilon}} + \\beta$\n",
    "\n",
    "Bu sayede BN inference’ta kaldırılır.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7496ff1f",
   "metadata": {},
   "source": [
    "---\n",
    "## 4) 1×1 Conv’u 3×3’e Dönüştürme (Padding)\n",
    "\n",
    "1×1 kernel’i 3×3’ün merkezine koyup diğer yerleri 0 yaparız.\n",
    "Bu sayede 1×1 branch de 3×3 kernel gibi temsil edilir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cab7d52",
   "metadata": {},
   "source": [
    "---\n",
    "## 5) Identity Dalını 3×3 Conv Gibi Yazma\n",
    "\n",
    "Identity (stride=1, cin=cout) özel bir 3×3 kernel ile ifade edilir:\n",
    "- Sadece diagonal kanal eşleşmeleri\n",
    "- Merkez (1,1) = 1\n",
    "- Diğer her yer 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5ac384",
   "metadata": {},
   "source": [
    "---\n",
    "## 6) Kod: BN Folding ve Kernel Birleştirme Yardımcıları\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "088ae893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_conv_bn(conv: nn.Conv2d, bn: nn.BatchNorm2d):\n",
    "    \"\"\"Conv + BN -> (W_fused, b_fused). conv.bias=None varsayar.\"\"\"\n",
    "    assert conv.bias is None\n",
    "    W = conv.weight\n",
    "    gamma = bn.weight\n",
    "    beta = bn.bias\n",
    "    mean = bn.running_mean\n",
    "    var = bn.running_var\n",
    "    eps = bn.eps\n",
    "\n",
    "    scale = gamma / torch.sqrt(var + eps)\n",
    "    W_fused = W * scale.reshape(-1, 1, 1, 1)\n",
    "    b_fused = beta - mean * scale\n",
    "    return W_fused, b_fused\n",
    "\n",
    "\n",
    "def pad_1x1_to_3x3(W_1x1: torch.Tensor):\n",
    "    \"\"\"(C_out,C_in,1,1) -> (C_out,C_in,3,3)\"\"\"\n",
    "    if W_1x1.size(-1) == 3:\n",
    "        return W_1x1\n",
    "    assert W_1x1.size(-1) == 1\n",
    "    W_3x3 = torch.zeros((W_1x1.size(0), W_1x1.size(1), 3, 3), device=W_1x1.device, dtype=W_1x1.dtype)\n",
    "    W_3x3[:, :, 1:2, 1:2] = W_1x1\n",
    "    return W_3x3\n",
    "\n",
    "\n",
    "def fuse_identity_bn(num_channels: int, bn: nn.BatchNorm2d, device=None, dtype=None):\n",
    "    \"\"\"Identity + BN -> (W_fused, b_fused) şeklinde 3x3 conv kernel üret.\"\"\"\n",
    "    if device is None:\n",
    "        device = bn.weight.device\n",
    "    if dtype is None:\n",
    "        dtype = bn.weight.dtype\n",
    "\n",
    "    W = torch.zeros((num_channels, num_channels, 3, 3), device=device, dtype=dtype)\n",
    "    for i in range(num_channels):\n",
    "        W[i, i, 1, 1] = 1.0\n",
    "\n",
    "    gamma = bn.weight\n",
    "    beta = bn.bias\n",
    "    mean = bn.running_mean\n",
    "    var = bn.running_var\n",
    "    eps = bn.eps\n",
    "\n",
    "    scale = gamma / torch.sqrt(var + eps)\n",
    "    W_fused = W * scale.reshape(-1, 1, 1, 1)\n",
    "    b_fused = beta - mean * scale\n",
    "    return W_fused, b_fused\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b5c27f",
   "metadata": {},
   "source": [
    "---\n",
    "## 7) RepVGGBlock (Training-time) + Deploy’a Dönüşüm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afa9f7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RepVGGBlock(nn.Module):\n",
    "    def __init__(self, cin, cout, stride=1, deploy=False):\n",
    "        super().__init__()\n",
    "        self.cin = cin\n",
    "        self.cout = cout\n",
    "        self.stride = stride\n",
    "        self.deploy = deploy\n",
    "        self.act = nn.ReLU(inplace=True)\n",
    "\n",
    "        if deploy:\n",
    "            self.rbr_reparam = nn.Conv2d(cin, cout, 3, stride=stride, padding=1, bias=True)\n",
    "        else:\n",
    "            self.rbr_3x3 = nn.Sequential(\n",
    "                nn.Conv2d(cin, cout, 3, stride=stride, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(cout)\n",
    "            )\n",
    "            self.rbr_1x1 = nn.Sequential(\n",
    "                nn.Conv2d(cin, cout, 1, stride=stride, padding=0, bias=False),\n",
    "                nn.BatchNorm2d(cout)\n",
    "            )\n",
    "            if cout == cin and stride == 1:\n",
    "                self.rbr_identity = nn.BatchNorm2d(cout)\n",
    "            else:\n",
    "                self.rbr_identity = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.deploy:\n",
    "            return self.act(self.rbr_reparam(x))\n",
    "\n",
    "        out = self.rbr_3x3(x) + self.rbr_1x1(x)\n",
    "        if self.rbr_identity is not None:\n",
    "            out = out + self.rbr_identity(x)\n",
    "        return self.act(out)\n",
    "\n",
    "    def get_equivalent_kernel_bias(self):\n",
    "        conv3, bn3 = self.rbr_3x3[0], self.rbr_3x3[1]\n",
    "        W3, b3 = fuse_conv_bn(conv3, bn3)\n",
    "\n",
    "        conv1, bn1 = self.rbr_1x1[0], self.rbr_1x1[1]\n",
    "        W1, b1 = fuse_conv_bn(conv1, bn1)\n",
    "        W1 = pad_1x1_to_3x3(W1)\n",
    "\n",
    "        if self.rbr_identity is not None:\n",
    "            Wid, bid = fuse_identity_bn(self.cout, self.rbr_identity, device=W3.device, dtype=W3.dtype)\n",
    "        else:\n",
    "            Wid = torch.zeros_like(W3)\n",
    "            bid = torch.zeros_like(b3)\n",
    "\n",
    "        W_eq = W3 + W1 + Wid\n",
    "        b_eq = b3 + b1 + bid\n",
    "        return W_eq, b_eq\n",
    "\n",
    "    def switch_to_deploy(self):\n",
    "        if self.deploy:\n",
    "            return\n",
    "        W, b = self.get_equivalent_kernel_bias()\n",
    "        self.rbr_reparam = nn.Conv2d(self.cin, self.cout, 3, stride=self.stride, padding=1, bias=True)\n",
    "        self.rbr_reparam.weight.data = W\n",
    "        self.rbr_reparam.bias.data = b\n",
    "\n",
    "        del self.rbr_3x3\n",
    "        del self.rbr_1x1\n",
    "        if hasattr(self, 'rbr_identity'):\n",
    "            del self.rbr_identity\n",
    "        self.deploy = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bc15a7",
   "metadata": {},
   "source": [
    "---\n",
    "## 8) Dönüşümü Doğrulama (Training vs Deploy çıktısı)\n",
    "\n",
    "Önemli: BN folding doğrulaması için `eval()` gerekir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68be57f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max abs diff: 3.337860107421875e-06\n",
      "shapes: torch.Size([2, 16, 32, 32]) torch.Size([2, 16, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "blk = RepVGGBlock(cin=16, cout=16, stride=1, deploy=False)\n",
    "blk.eval()\n",
    "\n",
    "x = torch.randn(2, 16, 32, 32)\n",
    "with torch.no_grad():\n",
    "    y_train = blk(x)\n",
    "\n",
    "blk.switch_to_deploy()\n",
    "blk.eval()\n",
    "with torch.no_grad():\n",
    "    y_deploy = blk(x)\n",
    "\n",
    "print('max abs diff:', (y_train - y_deploy).abs().max().item())\n",
    "print('shapes:', y_train.shape, y_deploy.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa95d785",
   "metadata": {},
   "source": [
    "---\n",
    "## 9) Mini RepVGG Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6b52441",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniRepVGG(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=10, deploy=False):\n",
    "        super().__init__()\n",
    "        self.deploy = deploy\n",
    "\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.stage1 = nn.Sequential(\n",
    "            RepVGGBlock(32, 64, stride=2, deploy=deploy),\n",
    "            RepVGGBlock(64, 64, stride=1, deploy=deploy),\n",
    "        )\n",
    "        self.stage2 = nn.Sequential(\n",
    "            RepVGGBlock(64, 128, stride=2, deploy=deploy),\n",
    "            RepVGGBlock(128, 128, stride=1, deploy=deploy),\n",
    "        )\n",
    "        self.stage3 = nn.Sequential(\n",
    "            RepVGGBlock(128, 256, stride=2, deploy=deploy),\n",
    "            RepVGGBlock(256, 256, stride=1, deploy=deploy),\n",
    "        )\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x, verbose=False):\n",
    "        if verbose: print('input:', x.shape)\n",
    "        x = self.stem(x)\n",
    "        if verbose: print('stem :', x.shape)\n",
    "        x = self.stage1(x)\n",
    "        if verbose: print('s1   :', x.shape)\n",
    "        x = self.stage2(x)\n",
    "        if verbose: print('s2   :', x.shape)\n",
    "        x = self.stage3(x)\n",
    "        if verbose: print('s3   :', x.shape)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        out = self.fc(x)\n",
    "        if verbose: print('out  :', out.shape)\n",
    "        return out\n",
    "\n",
    "    def switch_to_deploy(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, RepVGGBlock):\n",
    "                m.switch_to_deploy()\n",
    "        self.deploy = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6ca1d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: torch.Size([2, 3, 64, 64])\n",
      "stem : torch.Size([2, 32, 64, 64])\n",
      "s1   : torch.Size([2, 64, 32, 32])\n",
      "s2   : torch.Size([2, 128, 16, 16])\n",
      "s3   : torch.Size([2, 256, 8, 8])\n",
      "out  : torch.Size([2, 10])\n",
      "input: torch.Size([2, 3, 64, 64])\n",
      "stem : torch.Size([2, 32, 64, 64])\n",
      "s1   : torch.Size([2, 64, 32, 32])\n",
      "s2   : torch.Size([2, 128, 16, 16])\n",
      "s3   : torch.Size([2, 256, 8, 8])\n",
      "out  : torch.Size([2, 10])\n",
      "\n",
      "max abs diff (model): 2.9802322387695312e-08\n"
     ]
    }
   ],
   "source": [
    "model = MiniRepVGG(in_channels=3, num_classes=10, deploy=False)\n",
    "x = torch.randn(2, 3, 64, 64)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y1 = model(x, verbose=True)\n",
    "\n",
    "model.switch_to_deploy()\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y2 = model(x, verbose=True)\n",
    "\n",
    "print('\\nmax abs diff (model):', (y1 - y2).abs().max().item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526549fc",
   "metadata": {},
   "source": [
    "---\n",
    "## 10) Ne Zaman RepVGG Mantıklı?\n",
    "\n",
    "**Mantıklı:** deploy/latency kritik, hızlı backbone isteniyor.\n",
    "\n",
    "**Dikkat:** training tarafında branch maliyeti var; ama inference’ta tek conv’a iner.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
