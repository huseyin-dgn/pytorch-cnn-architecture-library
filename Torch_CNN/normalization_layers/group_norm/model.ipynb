{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Group Normalization (GN) — Gelişmiş ve Kontrolü Kolay Kullanım (CNN odaklı)\n",
        "\n",
        "Bu defterde:\n",
        "\n",
        "1) **Önce kod**: Projelerin çoğunda kullanılabilecek, kontrollü ve güvenli bir **GroupNorm yardımcı modülü** veriliyor.  \n",
        "2) **Sonra açıklama**: Kodda geçen tüm mekanizmalar tek tek anlatılıyor:\n",
        "   - `num_groups` nasıl seçilir?\n",
        "   - `eps`, `affine`, `channels_last` ne işe yarar?\n",
        "   - GN’nin LN/IN ile ilişkisi\n",
        "   - CNN bloklarında GN’yi doğru bağlama pratikleri\n",
        "   - Diğer opsiyonlar: SyncBN, FrozenBN, Weight Standardization, vb.\n",
        "\n",
        "> Not: Burada bir “tam model” kurmuyoruz. Ama GN’nin **projeye tak-çalıştır** şekilde kullanılması için gereken mekanizmaları kuruyoruz.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# 1) KOD (ÖNCE)\n",
        "\n",
        "Aşağıdaki kod parçası:\n",
        "- GN’yi **NCHW (channels-first)** CNN akışında sorunsuz kullanır.\n",
        "- İstersen **NHWC (channels-last)** tensorlerle de kullanabilir.\n",
        "- `num_groups` için **otomatik seçim** (C % G == 0) yapar.\n",
        "- İstersen GN’yi **LN-benzeri (G=1)** veya **IN-benzeri (G=C)** moda alabilir.\n",
        "- Yanlış ayarları erken yakalamak için **doğrulama (validation)** içerir.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# ----------------------------\n",
        "# 1) Yardımcı: group seçimi\n",
        "# ----------------------------\n",
        "def choose_gn_groups(C: int, preferred=(32, 16, 8, 4, 2, 1)) -> int:\n",
        "    ## “Eğer mümkünse GN’yi 32 grup yap, olmazsa 16, olmazsa 8… en son 1’e düş\n",
        "    ## Çünkü CNN/detection pratiklerinde “GroupNorm(32)” yıllardır default gibi kullanılıyor\n",
        "            ## C=24 → 32 gelmez, 16 gelmez, 8 gelir \n",
        "            ## C=96 → 32 gelir, 16 da gelir, 8 de gelir\n",
        "            ## Bazı C’lerde birden fazla seçenek mümkün.\n",
        "    for g in preferred:\n",
        "        if g <= C and (C % g == 0):\n",
        "            return g\n",
        "    return 1\n",
        "\n",
        "# ----------------------------\n",
        "# 2) GN yapılandırması (kontrol kolay)\n",
        "# ----------------------------\n",
        "class GNConfig:\n",
        "    def __init__(\n",
        "        self,\n",
        "        groups=\"auto\",               # \"auto\" veya int\n",
        "        eps: float = 1e-5,\n",
        "        affine: bool = True,\n",
        "        preferred_groups=(32, 16, 8, 4, 2, 1),\n",
        "        mode: str = \"gn\"             # \"gn\" | \"ln_like\" | \"in_like\"\n",
        "    ):\n",
        "        assert mode in {\"gn\", \"ln_like\", \"in_like\"}\n",
        "        self.groups = groups\n",
        "        self.eps = eps\n",
        "        self.affine = affine\n",
        "        self.preferred_groups = preferred_groups\n",
        "        self.mode = mode\n",
        "\n",
        "# ----------------------------\n",
        "# 3) Gelişmiş GN modülü (channels_first / channels_last destekli)\n",
        "# ----------------------------\n",
        "class GroupNormFlex(nn.Module):\n",
        "    \"\"\"Projelerde tekrar kullanılabilir GN wrapper.\n",
        "\n",
        "    Özellikler:\n",
        "    - channels_first (NCHW / NCDHW) veya channels_last (NHWC / NDHWC) ile çalışabilir\n",
        "    - groups='auto' ile C'ye göre mantıklı group seçer\n",
        "    - mode:\n",
        "        - 'gn'      : normal GN (G=auto veya int)\n",
        "        - 'ln_like' : GN(1) -> LN benzeri\n",
        "        - 'in_like' : GN(C) -> IN benzeri\n",
        "    \"\"\"\n",
        "    def __init__(self, num_channels: int, config: GNConfig | None = None, *, channels_last: bool = False):\n",
        "        super().__init__()\n",
        "        if config is None:\n",
        "            config = GNConfig()\n",
        "        self.num_channels = int(num_channels)\n",
        "        self.channels_last = bool(channels_last)\n",
        "        self.config = config\n",
        "\n",
        "        # --- groups belirle ---\n",
        "        if config.mode == \"ln_like\":\n",
        "            groups = 1\n",
        "        elif config.mode == \"in_like\":\n",
        "            groups = self.num_channels\n",
        "        else:\n",
        "            if config.groups == \"auto\":\n",
        "                groups = choose_gn_groups(self.num_channels, config.preferred_groups)\n",
        "            else:\n",
        "                # config.groups \"auto\" değilse, kullanıcı GN’nin grup sayısını manuel vermek istiyor demektir.\n",
        "                groups = int(config.groups)\n",
        "\n",
        "        # --- doğrulama ---\n",
        "        if groups < 1:\n",
        "            raise ValueError(\"num_groups >= 1 olmalı\")\n",
        "        if self.num_channels % groups != 0:\n",
        "            raise ValueError(f\"C % G == 0 olmalı. C={self.num_channels}, G={groups}\")\n",
        "        self.groups = groups\n",
        "\n",
        "        self.gn = nn.GroupNorm(\n",
        "            num_groups=self.groups,\n",
        "            num_channels=self.num_channels,\n",
        "            eps=float(config.eps),\n",
        "            affine=bool(config.affine)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        ## NHWC yalnızca GN’nin anlayacağı formata (NCHW) geçici olarak çevrilir,\n",
        "        ## GN uygulanır ve pipeline bozulmasın diye tekrar eski formata döndürülür.\n",
        "        ## NCHW kullanıyorsan bu adımların hiçbiri çalışmaz bile.\n",
        "\n",
        "        if self.channels_last: #  Bu şunu soruyor: “Bu katmana gelen tensor NHWC mi, yoksa NCHW mi?”\n",
        "            # channels_last=False :: NCHW geliyor :: Direkt nn.GroupNorm uygula \n",
        "            # channels_last=True :: Tensor NHWC geliyor :: GN uygulayabilmek için geçici olarak NCHW’ye çevir\n",
        "            \n",
        "            # 2D: NHWC -> NCHW -> GN -> NHWC\n",
        "                ## GPU (özellikle Tensor Core) bazı durumlarda NHWC ile daha hızlı\n",
        "\n",
        "            if x.ndim == 4: \n",
        "                # Biz NHWC gelirse ne yapıyoruz, onu konuşuyoruz.\n",
        "                # NHWC → NCHW  çeviriyoruz \n",
        "                x = x.permute(0, 3, 1, 2).contiguous() # Bu sadece ekseni yer değiştirir, veri değişmez.\n",
        "                ## .contiguous() neden? :: permute sadece view döndürür, memory sıralı değildir. :: Bunu bellekte düzgün sıraya koy\n",
        "                x = self.gn(x) ## Şimdi GN uygulanabilir :: GN kanalları gruplara bölüyor :: H, W ile birlikte\n",
        "\n",
        "                return x.permute(0, 2, 3, 1).contiguous() ## Ama neden tekrar NHWC’ye dönüyoruz? \n",
        "                ## Bu katmandan önceki katmanlar NHWC idi.Sonraki katmanlar da NHWC bekliyor\n",
        "\n",
        "            # 3D: NDHWC -> NCDHW -> GN -> NDHWC\n",
        "            if x.ndim == 5:\n",
        "                x = x.permute(0, 4, 1, 2, 3).contiguous()\n",
        "                x = self.gn(x)\n",
        "                return x.permute(0, 2, 3, 4, 1).contiguous()\n",
        "\n",
        "            raise ValueError(\"channels_last=True için x.ndim 4 veya 5 olmalı (NHWC/NDHWC).\")\n",
        "\n",
        "        ## Peki NCHW ise :: O zaman bu karmaşaya HİÇ girmiyoruz:\n",
        "        return self.gn(x)\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# 4) (Opsiyonel) Conv -> GN -> Act bloğu (GN entegrasyon örneği)\n",
        "# ----------------------------\n",
        "class ConvGNAct(nn.Module):\n",
        "    def __init__(self, in_ch: int, out_ch: int, k: int = 3, s: int = 1, p=None, act: str = \"silu\", gn_config: GNConfig | None = None):\n",
        "        super().__init__()\n",
        "        if p is None:\n",
        "            p = k // 2\n",
        "        self.conv = nn.Conv2d(in_ch, out_ch, kernel_size=k, stride=s, padding=p, bias=False)\n",
        "        self.norm = GroupNormFlex(out_ch, gn_config, channels_last=False)\n",
        "\n",
        "        if act == \"relu\":\n",
        "            self.act = nn.ReLU(inplace=True)\n",
        "        elif act == \"silu\":\n",
        "            self.act = nn.SiLU(inplace=True)\n",
        "        elif act == \"gelu\":\n",
        "            self.act = nn.GELU()\n",
        "        elif act in (\"none\", None):\n",
        "            self.act = nn.Identity()\n",
        "        else:\n",
        "            raise ValueError(\"act: 'relu' | 'silu' | 'gelu' | 'none'\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.act(self.norm(self.conv(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NCHW: torch.Size([2, 64, 32, 32]) -> torch.Size([2, 64, 32, 32]) | groups: 32\n",
            "LN-like groups: 1\n",
            "IN-like groups: 64\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(2, 64, 32, 32)\n",
        "cfg = GNConfig(groups='auto', mode='gn')\n",
        "gn = GroupNormFlex(64, cfg)\n",
        "\n",
        "y = gn(x)\n",
        "print('NCHW:', x.shape, '->', y.shape, '| groups:', gn.groups)\n",
        "\n",
        "# LN-benzeri: GN(1)\n",
        "gn_ln = GroupNormFlex(64, GNConfig(mode='ln_like'))\n",
        "y2 = gn_ln(x)\n",
        "print('LN-like groups:', gn_ln.groups)\n",
        "\n",
        "# IN-benzeri: GN(C)\n",
        "gn_in = GroupNormFlex(64, GNConfig(mode='in_like'))\n",
        "y3 = gn_in(x)\n",
        "print('IN-like groups:', gn_in.groups)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NHWC: torch.Size([2, 32, 32, 64]) -> torch.Size([2, 32, 32, 64]) | groups: 32\n"
          ]
        }
      ],
      "source": [
        "x_nhwc = torch.randn(2, 32, 32, 64)  # (N,H,W,C)\n",
        "gn_cl = GroupNormFlex(64, GNConfig(groups=32), channels_last=True)\n",
        "y_nhwc = gn_cl(x_nhwc)\n",
        "print('NHWC:', x_nhwc.shape, '->', y_nhwc.shape, '| groups:', gn_cl.groups)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# 2) AÇIKLAMA (SONRA)\n",
        "\n",
        "Aşağıda kodun her parçası ve GN mekanizması **tek tek** anlatılıyor.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.1 `choose_gn_groups(C)`: Neden gerekli?\n",
        "\n",
        "GN’de kritik kural:\n",
        "- **C % G == 0** olmalı (kanallar gruplara eşit bölünecek)\n",
        "\n",
        "Projelerde kanal sayıları farklı olabilir (32, 64, 96, 128, 192, ...).  \n",
        "Bu fonksiyon:\n",
        "- önce **32 grup** dener (en yaygın pratik)\n",
        "- olmazsa 16/8/4/2/1 diye iner\n",
        "\n",
        "Böylece “her yerde çalışan” bir GN ayarı sağlar.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.2 `GNConfig`: Neden config objesi?\n",
        "\n",
        "Projelerde norm ayarları sık değişir:\n",
        "- `groups`: 32 mi? auto mu?\n",
        "- `eps`: fp16 için 1e-5 mi 1e-6 mı?\n",
        "- `affine`: açık mı kapalı mı?\n",
        "- “LN-benzeri” mi istiyorum, “IN-benzeri” mi?\n",
        "\n",
        "Bunları her yerde parametre geçirmek yerine `GNConfig` ile:\n",
        "- tek yerden yönetirsin\n",
        "- deney/ablation yaparken kolayca değiştirirsin\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.3 `GroupNormFlex`: Asıl yeniden kullanılabilir GN katmanı\n",
        "\n",
        "Bu sınıfın amacı:\n",
        "- Tek satırla GN oluşturmak\n",
        "- Yanlış ayarı erkenden yakalamak\n",
        "- Channels-last (NHWC) gelirse otomatik dönüştürmek\n",
        "\n",
        "### 2.3.1 `mode` seçenekleri\n",
        "\n",
        "- `mode=\"gn\"`  \n",
        "  Normal GroupNorm: `G=auto` veya manuel `G=int`\n",
        "\n",
        "- `mode=\"ln_like\"`  \n",
        "  **GN(1)**: tüm kanalları tek grup yapar ⇒ LN benzeri davranış\n",
        "\n",
        "- `mode=\"in_like\"`  \n",
        "  **GN(C)**: her kanalı ayrı grup yapar ⇒ IN benzeri davranış\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.4 `channels_last`: NHWC ile GN kullanımı\n",
        "\n",
        "PyTorch `nn.GroupNorm`, varsayılan olarak **channels-first** (NCHW) bekler.\n",
        "\n",
        "Ama bazı projelerde tensor channels-last olabilir (NHWC):\n",
        "- hız optimizasyonu\n",
        "- belirli kernel’ler\n",
        "- bazı custom pipeline’lar\n",
        "\n",
        "`GroupNormFlex(channels_last=True)`:\n",
        "- NHWC -> NCHW permute eder\n",
        "- GN uygular\n",
        "- tekrar NHWC’ye döner\n",
        "\n",
        "> Eğer projen tamamen NCHW ise `channels_last=False` bırak ve maliyet ekleme.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.5 `eps` neden var?\n",
        "\n",
        "GN formülü:\n",
        "\\[\n",
        "\\hat{x} = \\frac{x - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}}\n",
        "\\]\n",
        "\n",
        "`eps`:\n",
        "- sayısal stabilite içindir\n",
        "- `var` çok küçük olursa bölme problemini önler\n",
        "- fp16/mixed-precision eğitimde bazen önem kazanır\n",
        "\n",
        "Pratik:\n",
        "- çoğu zaman `1e-5` iyi default\n",
        "- bazı durumlarda `1e-6` denenebilir\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.6 `affine` (gamma/beta) ne işe yarar?\n",
        "\n",
        "GN normalize ettikten sonra genelde:\n",
        "\\[\n",
        "y = \\gamma \\hat{x} + \\beta\n",
        "\\]\n",
        "\n",
        "- `affine=True`: `gamma` ve `beta` öğrenilir (default)\n",
        "- `affine=False`: sadece normalize eder\n",
        "\n",
        "Pratikte çoğu CNN’de `affine=True` tercih edilir:\n",
        "- ağın ifade gücünü azaltmaz\n",
        "- norm sonrası yeniden ölçekleme esnekliği verir\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.7 CNN’de GN’yi doğru bağlama: `ConvGNAct`\n",
        "\n",
        "CNN pratiğinde yaygın pattern:\n",
        "\n",
        "**Conv2d -> GroupNorm -> Activation**\n",
        "\n",
        "### Bias neden `False`?\n",
        "- GN’nin affine kısmı (beta) zaten shift yapar\n",
        "- Conv bias + GN beta çoğu zaman gereksiz parametre\n",
        "- Bu yüzden pratikte **Conv bias=False** yaygındır\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.8 GN hangi senaryolarda çok iyi çalışır?\n",
        "\n",
        "- **Object detection / segmentation** (batch küçük)\n",
        "- VRAM limitli eğitim (batch 1–4)\n",
        "- Fine-tuning sırasında BN istatistikleri karışıyorsa\n",
        "- Tek GPU / küçük batch ve SyncBN kullanmak istemiyorsan\n",
        "\n",
        "Genel slogan:\n",
        "> “Batch küçükse GN güvenli bir default’tur.”\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.9 Diğer opsiyonlar ve GN ile ilişkileri (kısa)\n",
        "\n",
        "### Sync BatchNorm (SyncBN)\n",
        "- Multi-GPU ile batch istatistiğini GPU’lar arasında senkronlar\n",
        "- Efektif batch büyür\n",
        "- Eğer altyapı uygunsa BN performansına yaklaşır\n",
        "\n",
        "### Frozen BatchNorm\n",
        "- BN running stats güncellenmez (özellikle pretrained backbone fine-tune)\n",
        "- Bazı detection pipeline’larında yaygın\n",
        "\n",
        "### Weight Standardization (WS)\n",
        "- Aktivasyonu değil, **ağırlıkları** normalize eder\n",
        "- GN ile birlikte kullanıldığında bazen stabilite artar (GN+WS)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# 3) Kısa kullanım örnekleri (projeye tak-çalıştır)\n",
        "\n",
        "### 3.1 Sadece GN katmanı\n",
        "```python\n",
        "norm = GroupNormFlex(C, GNConfig(groups='auto'))\n",
        "```\n",
        "\n",
        "### 3.2 LN benzeri (GN(1))\n",
        "```python\n",
        "norm = GroupNormFlex(C, GNConfig(mode='ln_like'))\n",
        "```\n",
        "\n",
        "### 3.3 IN benzeri (GN(C))\n",
        "```python\n",
        "norm = GroupNormFlex(C, GNConfig(mode='in_like'))\n",
        "```\n",
        "\n",
        "### 3.4 CNN bloğu\n",
        "```python\n",
        "block = ConvGNAct(in_ch, out_ch, gn_config=GNConfig(groups='auto'))\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# 4) Özet\n",
        "\n",
        "- GN, kanalları gruplara bölerek normalize eder ve batch’ten bağımsızdır.\n",
        "- Small-batch detection/segmentation için çok uygundur.\n",
        "- `GroupNormFlex` ile:\n",
        "  - `groups=auto` seçimi\n",
        "  - LN-like / IN-like modları\n",
        "  - channels-last desteği\n",
        "  tek yerde yönetilir.\n",
        "- CNN’de tipik bağlanış: **Conv -> GN -> Activation** (Conv bias=False).\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "torch_gpu",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
