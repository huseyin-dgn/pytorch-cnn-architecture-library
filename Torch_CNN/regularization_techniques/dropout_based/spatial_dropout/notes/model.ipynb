{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Spatial Dropout (Channel-wise Dropout) — En Temelden Yazım + Modele Entegrasyon\n",
        "\n",
        "Bu notebook iki şeyi bitirir:\n",
        "1) **Spatial Dropout’u sıfırdan** (mask, broadcast, scaling) yazarız.\n",
        "2) Bunu **CNN / Residual blok** içine doğru yere koyup entegre ederiz.\n",
        "\n",
        "Hedef: PyTorch’ta `nn.Dropout2d` ne yapıyorsa onu *tam anlayıp* kendin yazabilecek seviyeye gelmek.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0) Spatial Dropout tam olarak ne yapıyor?\n",
        "\n",
        "- Girdi tensörü: **x ∈ R[B, C, H, W]**\n",
        "- Her örnek için her kanal ya tutulur ya tamamen sıfırlanır.\n",
        "- **Klasik dropout** element-wise maske üretir: `[B,C,H,W]`\n",
        "- **Spatial dropout** channel-wise maske üretir: `[B,C,1,1]` → H,W’ye broadcast\n",
        "\n",
        "Bu yüzden CNN’de kanal co-adaptation (kanalların birbirine aşırı bağımlılığı) azalır.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) En temel matematik\n",
        "\n",
        "- Drop probability: **p**\n",
        "- Keep probability: **q = 1 - p**\n",
        "\n",
        "Maske:\n",
        "$$m \\sim Bernoulli(q),\\; m \\in \\{0,1\\}^{B\\times C\\times 1\\times 1}$$\n",
        "\n",
        "Uygulama (inverted dropout):\n",
        "$$y = \\frac{x \\odot m}{q}$$\n",
        "\n",
        "İnverted scaling olayı şunu sağlar:\n",
        "- Train sırasında beklenen değer korunur (yaklaşık) → eval’de ek bir ölçekleme gerekmez.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 4, 5, 5])"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "B, C, H, W = 2, 4, 5, 5\n",
        "x = torch.randn(B, C, H, W)\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Spatial Dropout’u sıfırdan yazalım (fonksiyon seviyesi)\n",
        "\n",
        "Aşağıdaki fonksiyon en minimal haliyle şunu yapar:\n",
        "1) `mask` üretir: `[B, C, 1, 1]`\n",
        "2) `x * mask` uygular\n",
        "3) `q` ile böler (inverted dropout)\n",
        "\n",
        "Not: Bu fonksiyon **sadece training modunda** çalıştırılmalı.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 4, 5, 5])"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def spatial_dropout2d(x: torch.Tensor, p: float, training: bool) -> torch.Tensor:\n",
        "    \"\"\"Channel-wise dropout (Spatial Dropout / Dropout2d) from scratch.\n",
        "    x: [B,C,H,W]\n",
        "    p: drop prob\n",
        "    training: if False -> identity\n",
        "    \"\"\"\n",
        "    if not (0.0 <= p < 1.0):\n",
        "        raise ValueError(\"p must be in [0, 1).\")\n",
        "    if (not training) or p == 0.0:\n",
        "        return x\n",
        "\n",
        "    q = 1.0 - p\n",
        "    # mask: [B, C, 1, 1]  (broadcast to H,W)\n",
        "    mask = torch.empty((x.size(0), x.size(1), 1, 1), device=x.device, dtype=x.dtype).bernoulli_(q)\n",
        "    return x * mask / q\n",
        "\n",
        "y = spatial_dropout2d(x, p=0.5, training=True)\n",
        "y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1) Kanalın komple düştüğünü nasıl doğrularız?\n",
        "\n",
        "Bir kanal komple 0’a gittiyse o kanalın `abs().mean()` değeri 0 olur.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1.7126, 0.0000, 0.0000, 1.5186])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "channel_energy = y[0].abs().mean(dim=(1,2))\n",
        "channel_energy  # 0 olan kanal -> komple düştü"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Bunu düzgün bir nn.Module yapalım\n",
        "\n",
        "Bu noktada iki kritik şey var:\n",
        "- `self.training` flag'i doğru çalışmalı (`model.train()` / `model.eval()`)\n",
        "- p=0 ise identity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(True, torch.Size([2, 4, 5, 5]))"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class SpatialDropout2D(nn.Module):\n",
        "    def __init__(self, p: float = 0.1):\n",
        "        super().__init__()\n",
        "        if not (0.0 <= p < 1.0):\n",
        "            raise ValueError(\"p must be in [0, 1).\")\n",
        "        self.p = float(p)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return spatial_dropout2d(x, p=self.p, training=self.training)\n",
        "\n",
        "sd = SpatialDropout2D(p=0.5)\n",
        "sd.train()\n",
        "y_train = sd(x)\n",
        "sd.eval()\n",
        "y_eval = sd(x)\n",
        "\n",
        "torch.allclose(x, y_eval), y_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Pytorch `nn.Dropout2d` ile aynı mı?\n",
        "\n",
        "Tam birebir aynı davranış için bazı PyTorch sürümlerinde `Dropout2d` maskeyi örnek/kanal bazlı uygular.\n",
        "Bizimki de aynı fikri uygular.\n",
        "\n",
        "Aşağıda çıktıların *birebir aynı olması* şart değil (random mask), ama davranışın tipi aynı olmalı:\n",
        "- Bazı kanallar tamamen 0\n",
        "- Eval modunda hiç dokunmuyor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "custom channel energy: tensor([0.0000, 0.0000, 2.0364, 1.5186])\n",
            "builtin channel energy: tensor([0.0000, 0.0000, 0.0000, 1.5186])\n"
          ]
        }
      ],
      "source": [
        "drop2d = nn.Dropout2d(p=0.5)\n",
        "drop2d.train()\n",
        "y_builtin = drop2d(x)\n",
        "\n",
        "print(\"custom channel energy:\", y_train[0].abs().mean(dim=(1,2)))\n",
        "print(\"builtin channel energy:\", y_builtin[0].abs().mean(dim=(1,2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Modele entegrasyon: NEREYE KOYACAĞIZ?\n",
        "\n",
        "En pratik kural:\n",
        "**Conv → Norm → Activation → Spatial Dropout**\n",
        "\n",
        "Neden activation sonrası?\n",
        "- Norm istatistiklerini dropout ile bozmak istemezsin.\n",
        "- Feature üretildikten sonra bazı kanalları kapatıp robustluk kazandırırsın.\n",
        "\n",
        "Örnek blok:\n",
        "- Conv → BN → SiLU → SD\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 16, 32, 32])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class ConvBNActSD(nn.Module):\n",
        "    def __init__(self, cin, cout, k=3, s=1, p=1, act=\"silu\", sd_p=0.1):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(cin, cout, k, stride=s, padding=p, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(cout)\n",
        "        self.act = nn.SiLU(inplace=True) if act == \"silu\" else nn.ReLU(inplace=True)\n",
        "        self.sd = SpatialDropout2D(p=sd_p)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.act(x)\n",
        "        x = self.sd(x)\n",
        "        return x\n",
        "\n",
        "blk = ConvBNActSD(3, 16, sd_p=0.2)\n",
        "blk.train()\n",
        "out = blk(torch.randn(2,3,32,32))\n",
        "out.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Residual blok içine entegrasyon\n",
        "\n",
        "Senin DropPath tarafıyla birlikte düşüneceğin yer burası.\n",
        "\n",
        "Tipik residual:\n",
        "$$y = x + F(x)$$\n",
        "\n",
        "Spatial Dropout’u `F(x)` içinde uygularsın.\n",
        "Genelde:\n",
        "- ikinci conv sonrası\n",
        "- veya attention sonrası\n",
        "- veya blok çıkışına yakın\n",
        "\n",
        "Aşağıda basit bir ResBlock var:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 16, 32, 32])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class BasicResBlockSD(nn.Module):\n",
        "    def __init__(self, c, sd_p=0.1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(c, c, 3, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(c)\n",
        "        self.act = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(c, c, 3, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(c)\n",
        "        self.sd = SpatialDropout2D(p=sd_p)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = self.act(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        # SD'yi branch içinde uygula\n",
        "        out = self.sd(out)\n",
        "        out = out + identity\n",
        "        out = self.act(out)\n",
        "        return out\n",
        "\n",
        "rb = BasicResBlockSD(16, sd_p=0.2)\n",
        "rb.train()\n",
        "z = rb(torch.randn(2,16,32,32))\n",
        "z.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Tam model örneği (küçük ama gerçekçi)\n",
        "\n",
        "Aşağıdaki model:\n",
        "- Stem conv\n",
        "- 2 tane residual blok\n",
        "- Global average pooling\n",
        "- Linear classifier\n",
        "\n",
        "Spatial Dropout’u hem ConvBNAct içinde hem residual içinde kullanıyoruz.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 5])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class TinyCNNWithSpatialDropout(nn.Module):\n",
        "    def __init__(self, num_classes=10, sd_p=0.1):\n",
        "        super().__init__()\n",
        "        self.stem = ConvBNActSD(3, 32, k=3, s=1, p=1, act=\"silu\", sd_p=sd_p)\n",
        "        self.proj = nn.Conv2d(32, 64, 3, stride=2, padding=1, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(64)\n",
        "        self.act = nn.SiLU(inplace=True)\n",
        "        self.block1 = BasicResBlockSD(64, sd_p=sd_p)\n",
        "        self.block2 = BasicResBlockSD(64, sd_p=sd_p)\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        x = self.act(self.bn(self.proj(x)))\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.pool(x).flatten(1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "m = TinyCNNWithSpatialDropout(num_classes=5, sd_p=0.2)\n",
        "m.train()\n",
        "logits = m(torch.randn(2,3,64,64))\n",
        "logits.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) Training loop içine nasıl girer?\n",
        "\n",
        "Spatial Dropout, `model.train()` iken çalışır.\n",
        "Yani entegrasyon ekstra bir şey istemez:\n",
        "- Train: `model.train()`\n",
        "- Eval: `model.eval()`\n",
        "\n",
        "Aşağıda minimal bir eğitim iskeleti var (dummy data ile).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2.439744710922241, 2.304030656814575, 0.125)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def train_step(model, optimizer, x, y):\n",
        "    model.train()\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    logits = model(x)\n",
        "    loss = F.cross_entropy(logits, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss.detach())\n",
        "\n",
        "def eval_step(model, x, y):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(x)\n",
        "        loss = F.cross_entropy(logits, y)\n",
        "        acc = (logits.argmax(dim=1) == y).float().mean()\n",
        "    return float(loss), float(acc)\n",
        "\n",
        "model = TinyCNNWithSpatialDropout(num_classes=10, sd_p=0.2)\n",
        "opt = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-2)\n",
        "\n",
        "x_batch = torch.randn(8,3,64,64)\n",
        "y_batch = torch.randint(0,10,(8,))\n",
        "\n",
        "loss = train_step(model, opt, x_batch, y_batch)\n",
        "val_loss, val_acc = eval_step(model, x_batch, y_batch)\n",
        "loss, val_loss, val_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9) Pratik ayarlar (senin setup için net öneri)\n",
        "\n",
        "- Başlangıç: **p = 0.05 – 0.15**\n",
        "- Overfit görürsen: 0.2\n",
        "- DropPath de kullanıyorsan (sen kullanıyorsun):\n",
        "  - ikisini aynı anda yüksek yapma\n",
        "  - genelde DropPath ana regularizer olur, SD düşük kalır\n",
        "\n",
        "Yerleşim:\n",
        "- Conv-BN-Act sonrası\n",
        "- Attention sonrası\n",
        "- Residual branch içinde (skip yoluna değil)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10) Mini checklist (bunu repo’da yap)\n",
        "\n",
        "- [ ] `SpatialDropout2D` modülünü `regularization/` altına koy\n",
        "- [ ] Basit ablation: p=0.0 / 0.1 / 0.2\n",
        "- [ ] DropPath ile birlikteyken SD’yi 0.05–0.1’e çek\n",
        "- [ ] Eğitim loglarında overfit azaldı mı bak\n",
        "\n",
        "Hazır olduğunda bir sonraki konu: **Stochastic Depth**.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "torch_gpu",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
