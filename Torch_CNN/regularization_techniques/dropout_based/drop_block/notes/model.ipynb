{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46bcd195",
   "metadata": {},
   "source": [
    "# DropBlock: Nedir? Nasıl Tanımlanır? Modele Nasıl Entegre Edilir? (PyTorch)\n",
    "\n",
    "Bu notebook; **DropBlock**’un kısa tanımını, arkasındaki fikri ve **en temelden ileri seviyeye** PyTorch ile nasıl yazılıp **modele adım adım entegre edileceğini** gösterir.\n",
    "\n",
    "> Not: Kodlar `torch>=1.10` ile uyumludur. GPU varsa otomatik kullanır.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f274b04",
   "metadata": {},
   "source": [
    "## 1) DropBlock kısaca nedir?\n",
    "\n",
    "**Dropout** nöronları (tekil aktivasyonları) rastgele sıfırlarken, **DropBlock** özellikle CNN’lerde **özellik haritalarında (feature map)** **bitişik bir blok alanı** rastgele sıfırlar.  \n",
    "Amaç: Modelin **lokal ipuçlarına aşırı bağımlı** olmasını azaltmak, **daha sağlam (robust) ve genelleştirici** temsiller öğrenmesini sağlamak.\n",
    "\n",
    "**Neden CNN’de Dropout zayıf kalabiliyor?**  \n",
    "CNN feature map’lerinde komşu pikseller/aktivasyonlar güçlü korelasyon taşır. Tek tek aktivasyon düşürmek (Dropout) çoğu zaman “yakın komşular” tarafından telafi edilir. DropBlock ise **komşu bir bölgeyi birlikte düşürerek** bu telafiyi zorlaştırır.\n",
    "\n",
    "**Kilit fikir:**  \n",
    "- Dropout: noktasal maskeleme  \n",
    "- DropBlock: **blok (patch) maskeleme** ✅\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a39976c",
   "metadata": {},
   "source": [
    "## 2) Temel kavramlar: `drop_prob`, `block_size`, `gamma`\n",
    "\n",
    "DropBlock’ta iki ana hiperparametre var:\n",
    "\n",
    "- `drop_prob`: “Ne kadar” düşüreyim? (0.0–0.5 arası sık kullanılır)\n",
    "- `block_size`: “Ne büyüklükte blok” düşüreyim? (ör: 3, 5, 7)\n",
    "\n",
    "Uygulamada genelde şu yapılır:\n",
    "\n",
    "1. Önce **blok merkezlerini** Bernoulli ile örnekle (olasılık `gamma`).\n",
    "2. Bu merkezlerden `block_size x block_size` alanı **1→0** olacak şekilde genişlet (max-pool/dilation benzeri).\n",
    "3. Maskeyi uygula ve aktivasyonları **yeniden ölçekle**:  \n",
    "   Beklenen aktivasyon büyüklüğü korunur.\n",
    "\n",
    "> `gamma`, `drop_prob`’dan türetilir. Çünkü merkez sayısı ile blok alanı farklı şeylerdir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c26548",
   "metadata": {},
   "source": [
    "## 3) En temel DropBlock: 2D feature map için (PyTorch)\n",
    "\n",
    "Aşağıda “klasik” yaklaşımı yazacağız:\n",
    "- Sadece **eğitim modunda** çalışır (`self.training`).\n",
    "- `gamma` hesaplar.\n",
    "- Maske üretir.\n",
    "- Bloklara genişletir.\n",
    "- `x * mask * scale` uygular.\n",
    "\n",
    "> Not: Bu implementasyon, pratikte yaygın kullanılan ve anlaşılır bir sürümdür.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4f5ec5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34c3ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropBlock2D(nn.Module):\n",
    "    def __init__(self, drop_prob: float = 0.1, block_size: int = 7):\n",
    "        super().__init__()\n",
    "        self.drop_prob = float(drop_prob)\n",
    "        self.block_size = int(block_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # Eğitim dışındaysa veya drop_prob 0 ise hiçbir şey yapma\n",
    "        if (not self.training) or self.drop_prob <= 0.0:\n",
    "            return x\n",
    "\n",
    "        # x: (N, C, H, W)\n",
    "        if x.dim() != 4:\n",
    "            raise ValueError(f\"DropBlock2D 4D tensor bekler (N,C,H,W). Geldi: {x.shape}\")\n",
    "\n",
    "        n, c, h, w = x.shape\n",
    "        bs = self.block_size\n",
    "\n",
    "        # Block_size, H/W'den büyük olursa pratikte tüm alanı düşürmeye kayar.\n",
    "        # Bu yüzden güvenli tarafta clamp yapıyoruz.\n",
    "        bs = min(bs, h, w)\n",
    "        if bs < 1:\n",
    "            return x\n",
    "\n",
    "        # Gamma: blok merkezlerinin seçilme olasılığı.\n",
    "        # Yaklaşık fikir: hedeflenen toplam düşen alan oranını drop_prob yap.\n",
    "        # (H*W) yerine \"seçilebilir merkez\" alanı (H-bs+1, W-bs+1) üzerinden düzeltme.\n",
    "        valid_h = h - bs + 1\n",
    "        valid_w = w - bs + 1\n",
    "\n",
    "        # block alanı\n",
    "        block_area = bs * bs\n",
    "\n",
    "        # gamma (literatürde yaygın form)\n",
    "        gamma = self.drop_prob * (h * w) / (block_area * valid_h * valid_w)\n",
    "\n",
    "        # 1) Merkez maskesi (N,C,valid_h,valid_w) üzerinde örnekle\n",
    "        # Sonra bunu (N,C,H,W)'ye pad ile yerleştiriyoruz.\n",
    "        center_mask = (torch.rand((n, c, valid_h, valid_w), device=x.device) < gamma).float()\n",
    "\n",
    "        # 2) Merkez maskesini HxW boyuta taşı (pad)\n",
    "        pad_h = (bs - 1) // 2\n",
    "        pad_w = (bs - 1) // 2\n",
    "        center_mask = F.pad(center_mask, (pad_w, pad_w, pad_h, pad_h))\n",
    "\n",
    "        # 3) Bloklara genişlet: max_pool ile \"yakın çevrede merkez varsa 1\" olur\n",
    "        # kernel=bs, stride=1, padding=bs//2 => HxW korunur\n",
    "        block_mask = F.max_pool2d(center_mask, kernel_size=bs, stride=1, padding=bs//2)\n",
    "\n",
    "        # 4) Drop mask = 1 - block_mask (düşürülen yerler 0 olur)\n",
    "        mask = 1.0 - block_mask\n",
    "\n",
    "        # 5) Yeniden ölçekleme: beklenen aktivasyon büyüklüğünü koru\n",
    "        # mask ortalaması ~ keep_prob => scale = 1/keep_prob\n",
    "        keep_prob = mask.mean().clamp(min=1e-6)\n",
    "        x = x * mask / keep_prob\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50a928f",
   "metadata": {},
   "source": [
    "### Hızlı test\n",
    "\n",
    "- Eğitim modunda (`train()`) çıktıda bloklu sıfırlamalar görmelisin.\n",
    "- `eval()` modunda aynı tensor geri dönmeli.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fde5589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train fark (L1): 0.33283552527427673\n",
      "eval fark  (L1): 0.0\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "m = DropBlock2D(drop_prob=0.25, block_size=5).to(device)\n",
    "x = torch.randn(2, 3, 16, 16, device=device)\n",
    "\n",
    "m.train()\n",
    "y_train = m(x)\n",
    "\n",
    "m.eval()\n",
    "y_eval = m(x)\n",
    "\n",
    "# Farklara bak\n",
    "print(\"train fark (L1):\", (y_train - x).abs().mean().item())\n",
    "print(\"eval fark  (L1):\", (y_eval - x).abs().mean().item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1974399d",
   "metadata": {},
   "source": [
    "## 4) DropBlock’u “en temelden ileriye” doğru güçlendirme\n",
    "\n",
    "Aşağıdaki iyileştirmeler pratikte çok işe yarar:\n",
    "\n",
    "1. **Block size otomatik ayarlanabilir**: erken katmanlarda küçük, derin katmanlarda büyük blok.\n",
    "2. **Linear schedule** (drop_prob ramp-up): eğitim başında düşük, sonlara doğru artan drop_prob.\n",
    "3. **Feature map boyutuna duyarlı**: küçük HxW’de agresif drop_prob patlatabilir.\n",
    "4. **Determinism / seed kontrolü**: debug sırasında.\n",
    "\n",
    "Şimdi bunları paketleyelim.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47d51bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropBlock2D_Scheduled(nn.Module):\n",
    "    \"\"\"DropBlock2D + lineer schedule.\n",
    "\n",
    "    Notlar:\n",
    "    - forward'da step alabilir veya dışarıdan set edebilirsin.\n",
    "    - drop_prob, [0, max_drop_prob] aralığında lineer artar.\n",
    "\n",
    "    Args:\n",
    "        max_drop_prob: Eğitim sonunda ulaşılacak drop_prob.\n",
    "        block_size: Sabit blok boyutu.\n",
    "        total_steps: Schedule toplam adım sayısı.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_drop_prob=0.1, block_size=7, total_steps=10_000):\n",
    "        super().__init__()\n",
    "        self.max_drop_prob = float(max_drop_prob)\n",
    "        self.block_size = int(block_size)\n",
    "        self.total_steps = int(total_steps)\n",
    "        self.register_buffer(\"step\", torch.zeros((), dtype=torch.long))\n",
    "\n",
    "    def _current_drop_prob(self):\n",
    "        s = int(self.step.item())\n",
    "        t = min(max(s / max(1, self.total_steps), 0.0), 1.0)\n",
    "        return self.max_drop_prob * t\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if self.training:\n",
    "            self.step += 1\n",
    "\n",
    "        drop_prob = self._current_drop_prob()\n",
    "        # Aynı DropBlock mantığı, sadece drop_prob dinamik\n",
    "        if (not self.training) or drop_prob <= 0.0:\n",
    "            return x\n",
    "\n",
    "        n, c, h, w = x.shape\n",
    "        bs = min(self.block_size, h, w)\n",
    "        valid_h = h - bs + 1\n",
    "        valid_w = w - bs + 1\n",
    "        block_area = bs * bs\n",
    "\n",
    "        gamma = drop_prob * (h * w) / (block_area * valid_h * valid_w)\n",
    "\n",
    "        center_mask = (torch.rand((n, c, valid_h, valid_w), device=x.device) < gamma).float()\n",
    "        pad_h = (bs - 1) // 2\n",
    "        pad_w = (bs - 1) // 2\n",
    "        center_mask = F.pad(center_mask, (pad_w, pad_w, pad_h, pad_h))\n",
    "        block_mask = F.max_pool2d(center_mask, kernel_size=bs, stride=1, padding=bs//2)\n",
    "        mask = 1.0 - block_mask\n",
    "        keep_prob = mask.mean().clamp(min=1e-6)\n",
    "        return x * mask / keep_prob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625753d5",
   "metadata": {},
   "source": [
    "## 5) DropBlock’u modele entegre etme: adım adım\n",
    "\n",
    "Aşağıdaki akış “temiz” entegrasyon yaklaşımıdır:\n",
    "\n",
    "1. **Conv → Norm → Act** bloğunu yaz\n",
    "2. İstediğin yerlerde **DropBlock** ekle\n",
    "3. Modeli oluştur\n",
    "4. Eğitim döngüsünde `model.train()` iken DropBlock aktif olur, `eval()` iken pasif olur\n",
    "\n",
    "Şimdi küçük ama “ciddi” bir CNN yazalım: Residual + DropBlock.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "924c91ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvGNAct(nn.Module):\n",
    "    def __init__(self, cin, cout, k=3, s=1, p=1, groups_gn=8, act=\"silu\"):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(cin, cout, k, stride=s, padding=p, bias=False)\n",
    "        # GroupNorm: batch size küçükken daha stabil\n",
    "        g = min(groups_gn, cout)\n",
    "        # g, cout'u bölmeli; değilse en yakın böleni seç\n",
    "        while cout % g != 0 and g > 1:\n",
    "            g -= 1\n",
    "        self.norm = nn.GroupNorm(g, cout)\n",
    "        if act == \"silu\":\n",
    "            self.act = nn.SiLU(inplace=True)\n",
    "        elif act == \"relu\":\n",
    "            self.act = nn.ReLU(inplace=True)\n",
    "        else:\n",
    "            raise ValueError(\"act 'silu' veya 'relu' olmalı\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.norm(self.conv(x)))\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, cin, cout, stride=1, dropblock: nn.Module | None = None):\n",
    "        super().__init__()\n",
    "        self.dropblock = dropblock\n",
    "\n",
    "        self.conv1 = ConvGNAct(cin, cout, k=3, s=stride, p=1)\n",
    "        self.conv2 = nn.Conv2d(cout, cout, 3, padding=1, bias=False)\n",
    "        g = min(8, cout)\n",
    "        while cout % g != 0 and g > 1:\n",
    "            g -= 1\n",
    "        self.norm2 = nn.GroupNorm(g, cout)\n",
    "\n",
    "        self.skip = None\n",
    "        if stride != 1 or cin != cout:\n",
    "            self.skip = nn.Conv2d(cin, cout, 1, stride=stride, bias=False)\n",
    "\n",
    "        self.act = nn.SiLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x if self.skip is None else self.skip(x)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "\n",
    "        # DropBlock'u genelde conv sonrası feature map üzerinde uygularsın\n",
    "        if self.dropblock is not None:\n",
    "            out = self.dropblock(out)\n",
    "\n",
    "        out = self.norm2(self.conv2(out))\n",
    "        out = out + identity\n",
    "        return self.act(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6407838",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallResNetDropBlock(nn.Module):\n",
    "    def __init__(self, num_classes=10, dropblock_cfg=None):\n",
    "        super().__init__()\n",
    "\n",
    "        # DropBlock'u stage bazlı koymak mantıklı:\n",
    "        # - Çok erken katmanda agresif dropblock bazen performansı düşürür.\n",
    "        # - Orta/derin katmanlar daha iyi aday.\n",
    "        dropblock_cfg = dropblock_cfg or {}\n",
    "        db1 = dropblock_cfg.get(\"stage1\", None)\n",
    "        db2 = dropblock_cfg.get(\"stage2\", None)\n",
    "        db3 = dropblock_cfg.get(\"stage3\", None)\n",
    "\n",
    "        self.stem = ConvGNAct(3, 64, k=3, s=1, p=1)\n",
    "\n",
    "        self.stage1 = nn.Sequential(\n",
    "            ResidualBlock(64, 64, stride=1, dropblock=db1),\n",
    "            ResidualBlock(64, 64, stride=1, dropblock=db1),\n",
    "        )\n",
    "        self.stage2 = nn.Sequential(\n",
    "            ResidualBlock(64, 128, stride=2, dropblock=db2),\n",
    "            ResidualBlock(128, 128, stride=1, dropblock=db2),\n",
    "        )\n",
    "        self.stage3 = nn.Sequential(\n",
    "            ResidualBlock(128, 256, stride=2, dropblock=db3),\n",
    "            ResidualBlock(256, 256, stride=1, dropblock=db3),\n",
    "        )\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.stage1(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.pool(x).flatten(1)\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce819f8d",
   "metadata": {},
   "source": [
    "### 5.1) Modeli DropBlock olmadan / DropBlock ile kur\n",
    "\n",
    "Aşağıda iki model kuruyoruz:\n",
    "- Baseline (DropBlock yok)\n",
    "- DropBlock’lu (stage2+stage3)\n",
    "\n",
    "> İpucu: DropBlock’u çoğunlukla **orta ve derin stage**’lerde başlatmak daha güvenli.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c66d433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2776906, 2776906)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline = SmallResNetDropBlock(num_classes=10, dropblock_cfg={}).to(device)\n",
    "\n",
    "dropblock_cfg = {\n",
    "    \"stage2\": DropBlock2D_Scheduled(max_drop_prob=0.15, block_size=5, total_steps=2000),\n",
    "    \"stage3\": DropBlock2D_Scheduled(max_drop_prob=0.20, block_size=7, total_steps=2000),\n",
    "}\n",
    "model_db = SmallResNetDropBlock(num_classes=10, dropblock_cfg=dropblock_cfg).to(device)\n",
    "\n",
    "sum(p.numel() for p in baseline.parameters()), sum(p.numel() for p in model_db.parameters())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee8da6c",
   "metadata": {},
   "source": [
    "## 6) Mini eğitim döngüsü (dummy data ile)\n",
    "\n",
    "Gerçek veri seti indirmeden “entegrasyon doğru mu?” test etmek için random data ile 5–10 adım koşalım.\n",
    "\n",
    "- `train()` modunda DropBlock aktif ✅\n",
    "- `eval()` modunda pasif ✅\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "347f337d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline train:\n",
      "step 05 | loss=2.2436\n",
      "step 10 | loss=2.3791\n",
      "\n",
      "DropBlock train:\n",
      "step 05 | loss=2.4834\n",
      "step 10 | loss=2.2723\n",
      "\n",
      "DropBlock eval:\n",
      "eval ok\n"
     ]
    }
   ],
   "source": [
    "def train_steps(model, steps=10, bs=32, num_classes=10, lr=1e-3):\n",
    "    model.train()\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    for i in range(steps):\n",
    "        x = torch.randn(bs, 3, 32, 32, device=device)\n",
    "        y = torch.randint(0, num_classes, (bs,), device=device)\n",
    "\n",
    "        logits = model(x)\n",
    "        loss = loss_fn(logits, y)\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        if (i+1) % 5 == 0:\n",
    "            print(f\"step {i+1:02d} | loss={loss.item():.4f}\")\n",
    "\n",
    "def eval_steps(model, steps=3, bs=32, num_classes=10):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(steps):\n",
    "            x = torch.randn(bs, 3, 32, 32, device=device)\n",
    "            logits = model(x)\n",
    "    print(\"eval ok\")\n",
    "\n",
    "print(\"Baseline train:\")\n",
    "train_steps(baseline, steps=10)\n",
    "\n",
    "print(\"\\nDropBlock train:\")\n",
    "train_steps(model_db, steps=10)\n",
    "\n",
    "print(\"\\nDropBlock eval:\")\n",
    "eval_steps(model_db)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e075646c",
   "metadata": {},
   "source": [
    "## 7) İleri seviye pratik notlar (gerçek projede işine yarar)\n",
    "\n",
    "### 7.1 Nerelere koymalısın?\n",
    "- En çok fayda: **orta/derin feature map**’lerde.\n",
    "- Çok erken katmanda (H,W büyükken) agresif DropBlock bazen “çok bilgi siliyor”.\n",
    "\n",
    "**Yaygın yerleşim:**\n",
    "- Residual block içinde: `conv1` sonrası veya `conv2` öncesi\n",
    "- Detection modellerde: backbone’un orta/derin stage’leri\n",
    "\n",
    "### 7.2 Hiperparametre önerileri (başlangıç)\n",
    "- `block_size`: 3 / 5 / 7  \n",
    "- `max_drop_prob`: 0.05 – 0.25  \n",
    "- Schedule: ilk %20–30 eğitimde düşük, sonlara doğru artış\n",
    "\n",
    "### 7.3 Küçük feature map uyarısı\n",
    "H=W=7 gibi küçük haritalarda block_size büyükse agresifleşir.  \n",
    "Bu notebook implementasyonu `block_size`’ı `min(block_size, H, W)` ile sınırlar.\n",
    "\n",
    "### 7.4 BatchNorm vs GroupNorm\n",
    "DropBlock, regularization olduğu için istatistikleri oynatır.  \n",
    "Batch size küçükse **GroupNorm** daha stabil olabilir (biz örnekte GN kullandık).\n",
    "\n",
    "### 7.5 Performans\n",
    "DropBlock bazen:\n",
    "- Top-1’i artırır ✅\n",
    "- Eğitimi yavaşlatır (regularization) ✅\n",
    "- Çok agresif ayarlanırsa underfit yaptırır ❌  \n",
    "Bu yüzden schedule + doğru stage seçimi kritik.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38d0b65",
   "metadata": {},
   "source": [
    "# SON MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14eb1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DropBlock2D(nn.Module):\n",
    "    def __init__(self, drop_prob: float = 0.1, block_size: int = 7):\n",
    "        super().__init__()\n",
    "        # Kullanıcının verdiği \"ne kadar düşüreyim\" oranı\n",
    "        self.drop_prob = float(drop_prob)\n",
    "        # Düşürülecek blok boyutu\n",
    "        self.block_size = int(block_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # 1) Eğitim modunda değilsek (eval) DropBlock kapalı olmalı\n",
    "        #    veya drop_prob 0 ise hiçbir şey yapmayız.\n",
    "        if (not self.training) or self.drop_prob <= 0.0:\n",
    "            return x\n",
    "\n",
    "        # 2) DropBlock2D yalnızca 4 boyutlu CNN feature map bekler: (N, C, H, W)\n",
    "        if x.dim() != 4:\n",
    "            raise ValueError(f\"DropBlock2D 4D tensor bekler (N,C,H,W). Geldi: {x.shape}\")\n",
    "\n",
    "        # 3) Tensor şekillerini al\n",
    "        n, c, h, w = x.shape\n",
    "\n",
    "        # 4) block_size, feature map boyutundan büyük olamaz.\n",
    "        #    Büyükse, pratikte tüm haritayı düşürmeye gider.\n",
    "        #    Bu yüzden güvenli şekilde clamp'liyoruz.\n",
    "        bs = min(self.block_size, h, w)\n",
    "        if bs < 1:\n",
    "            return x\n",
    "\n",
    "        # 5) Blok merkezlerini seçerken \"valid\" bir merkez alanı gerekir.\n",
    "        #    Çünkü blok, sağa-sola genişleyecek.\n",
    "        #    valid_h = H - bs + 1 -> blok tamamen sığacak merkezlerin sayısı\n",
    "        valid_h = h - bs + 1\n",
    "        valid_w = w - bs + 1\n",
    "\n",
    "        # 6) Blok alanı (kaç piksel/aktivasyon düşürülecek)\n",
    "        block_area = bs * bs\n",
    "\n",
    "        # 7) gamma: \"merkezlerin seçilme olasılığı\"\n",
    "        #    drop_prob doğrudan \"piksel düşürme\" değil, \"blok düşürme\" hedefidir.\n",
    "        #    O yüzden gamma'yı, hedeflenen drop oranına göre ölçekliyoruz.\n",
    "        #\n",
    "        #    Bu form pratikte yaygın kullanılır:\n",
    "        #    gamma = drop_prob * (H*W) / (block_area * valid_h * valid_w)\n",
    "        gamma = self.drop_prob * (h * w) / (block_area * valid_h * valid_w)\n",
    "\n",
    "        # 8) Merkez maskesi üret:\n",
    "        #    Şekil: (N, C, valid_h, valid_w)\n",
    "        #    Her (n,c) için olası merkez noktalarında Bernoulli örnekleriz.\n",
    "        #    Seçilen merkez -> 1, seçilmeyen -> 0\n",
    "        center_mask = (torch.rand((n, c, valid_h, valid_w), device=x.device) < gamma).float()\n",
    "\n",
    "        # 9) Merkez maskesini HxW uzayına taşımamız gerekiyor.\n",
    "        #    Çünkü şu an valid alan boyutunda.\n",
    "        #    Bunu padding ile HxW’ye oturtuyoruz.\n",
    "        #\n",
    "        #    pad miktarı yaklaşık bs//2 kadar.\n",
    "        pad_h = (bs - 1) // 2\n",
    "        pad_w = (bs - 1) // 2\n",
    "        center_mask = F.pad(center_mask, (pad_w, pad_w, pad_h, pad_h))\n",
    "\n",
    "        # 10) Merkezleri BLOK'a genişlet:\n",
    "        #     Eğer bir bölgede merkez varsa o bölgeyi 1 yapacağız.\n",
    "        #     Bunu max_pool ile yapıyoruz:\n",
    "        #     - kernel_size = bs -> bs x bs komşuluğa bak\n",
    "        #     - stride = 1 -> her piksel konumunda uygula\n",
    "        #     - padding = bs//2 -> çıktı boyutu HxW kalsın\n",
    "        #\n",
    "        #     Sonuç: block_mask (N,C,H,W) ve \"blok alanı\" 1 olur.\n",
    "        block_mask = F.max_pool2d(center_mask, kernel_size=bs, stride=1, padding=bs // 2)\n",
    "\n",
    "        # 11) Asıl uygulayacağımız maske:\n",
    "        #     Drop edilen yerler 0 olmalı, tutulacak yerler 1 olmalı.\n",
    "        #     block_mask'te drop edilecek blok 1 olduğu için tersliyoruz:\n",
    "        mask = 1.0 - block_mask\n",
    "\n",
    "        # 12) Ölçekleme (çok kritik):\n",
    "        #     Drop sonrası aktivasyonların beklenen büyüklüğü düşer.\n",
    "        #     Dropout mantığında olduğu gibi,\n",
    "        #     \"beklenen değer sabit kalsın\" diye (1/keep_prob) ile ölçekleriz.\n",
    "        keep_prob = mask.mean().clamp(min=1e-6)\n",
    "\n",
    "        # 13) Maskeyi uygula + ölçekle\n",
    "        return x * mask / keep_prob\n",
    "    \n",
    "class DropBlock2D_Scheduled(nn.Module):\n",
    "    \"\"\"\n",
    "    DropBlock'u eğitim boyunca yavaş yavaş artırmak için schedule'lı sürüm.\n",
    "\n",
    "    Neden?\n",
    "    - Eğitimin başında aşırı regularization öğrenmeyi baltalayabilir.\n",
    "    - Sonlara doğru artırmak daha güvenli: model önce temel temsilleri öğrenir,\n",
    "      sonra daha zorlayıcı regularization ile genelleme güçlenir.\n",
    "\n",
    "    Args:\n",
    "        max_drop_prob (float): Eğitim sonunda ulaşılacak drop_prob.\n",
    "        block_size (int): Blok boyutu.\n",
    "        total_steps (int): Kaç adımda max_drop_prob'a ulaşacağız.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_drop_prob=0.1, block_size=7, total_steps=10_000):\n",
    "        super().__init__()\n",
    "        self.max_drop_prob = float(max_drop_prob)\n",
    "        self.block_size = int(block_size)\n",
    "        self.total_steps = int(total_steps)\n",
    "\n",
    "        # Step sayacını buffer olarak tutuyoruz:\n",
    "        # - model.state_dict() içine girer\n",
    "        # - cuda/cpu taşınırken otomatik taşınır\n",
    "        self.register_buffer(\"step\", torch.zeros((), dtype=torch.long))\n",
    "\n",
    "    def _current_drop_prob(self) -> float:\n",
    "        # 1) Mevcut step'i al\n",
    "        s = int(self.step.item())\n",
    "\n",
    "        # 2) [0,1] arası progress oranı\n",
    "        t = min(max(s / max(1, self.total_steps), 0.0), 1.0)\n",
    "\n",
    "        # 3) Lineer artış: 0 -> max_drop_prob\n",
    "        return self.max_drop_prob * t\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # 1) Eğitim modundaysak her forward'da step arttır\n",
    "        #    (istersen bunu dışarıdan da yönetebilirsin ama burada otomatik)\n",
    "        if self.training:\n",
    "            self.step += 1\n",
    "\n",
    "        # 2) O anki drop_prob'u schedule'dan hesapla\n",
    "        drop_prob = self._current_drop_prob()\n",
    "\n",
    "        # 3) Eval modunda veya drop_prob 0 iken pas geç\n",
    "        if (not self.training) or drop_prob <= 0.0:\n",
    "            return x\n",
    "\n",
    "        # 4) Shape kontrolü\n",
    "        if x.dim() != 4:\n",
    "            raise ValueError(f\"DropBlock2D_Scheduled 4D tensor bekler (N,C,H,W). Geldi: {x.shape}\")\n",
    "\n",
    "        # 5) Şekilleri al\n",
    "        n, c, h, w = x.shape\n",
    "\n",
    "        # 6) Block size clamp\n",
    "        bs = min(self.block_size, h, w)\n",
    "        if bs < 1:\n",
    "            return x\n",
    "\n",
    "        # 7) Valid merkez alanı + blok alanı\n",
    "        valid_h = h - bs + 1\n",
    "        valid_w = w - bs + 1\n",
    "        block_area = bs * bs\n",
    "\n",
    "        # 8) gamma'yı drop_prob'a göre ayarla\n",
    "        gamma = drop_prob * (h * w) / (block_area * valid_h * valid_w)\n",
    "\n",
    "        # 9) Merkez maskesi örnekle\n",
    "        center_mask = (torch.rand((n, c, valid_h, valid_w), device=x.device) < gamma).float()\n",
    "\n",
    "        # 10) HxW alanına pad\n",
    "        pad_h = (bs - 1) // 2\n",
    "        pad_w = (bs - 1) // 2\n",
    "        center_mask = F.pad(center_mask, (pad_w, pad_w, pad_h, pad_h))\n",
    "\n",
    "        # 11) Merkezleri bloklara genişlet\n",
    "        block_mask = F.max_pool2d(center_mask, kernel_size=bs, stride=1, padding=bs // 2)\n",
    "\n",
    "        # 12) Drop mask\n",
    "        mask = 1.0 - block_mask\n",
    "\n",
    "        # 13) Ölçekleme\n",
    "        keep_prob = mask.mean().clamp(min=1e-6)\n",
    "\n",
    "        # 14) Uygula\n",
    "        return x * mask / keep_prob\n",
    "\n",
    "class ConvGNAct(nn.Module):\n",
    "    def __init__(self, cin, cout, k=3, s=1, p=1, groups_gn=8, act=\"silu\"):\n",
    "        super().__init__()\n",
    "\n",
    "        # 1) Conv: bias=False çünkü norm katmanı offset öğrenir\n",
    "        self.conv = nn.Conv2d(cin, cout, k, stride=s, padding=p, bias=False)\n",
    "\n",
    "        # 2) Group sayısını cout'a göre ayarla.\n",
    "        #    GN'de groups, channel sayısını bölmeli.\n",
    "        g = min(groups_gn, cout)\n",
    "        while cout % g != 0 and g > 1:\n",
    "            g -= 1\n",
    "\n",
    "        # 3) GroupNorm\n",
    "        self.norm = nn.GroupNorm(g, cout)\n",
    "\n",
    "        # 4) Aktivasyon seçimi\n",
    "        if act == \"silu\":\n",
    "            self.act = nn.SiLU(inplace=True)\n",
    "        elif act == \"relu\":\n",
    "            self.act = nn.ReLU(inplace=True)\n",
    "        else:\n",
    "            raise ValueError(\"act 'silu' veya 'relu' olmalı\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Conv -> Norm -> Act\n",
    "        return self.act(self.norm(self.conv(x)))\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, cin, cout, stride=1, dropblock: nn.Module | None = None):\n",
    "        super().__init__()\n",
    "        self.dropblock = dropblock\n",
    "        self.conv1 = ConvGNAct(cin, cout, k=3, s=stride, p=1)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(cout, cout, 3, padding=1, bias=False)\n",
    "\n",
    "        g = min(8, cout)\n",
    "        while cout % g != 0 and g > 1:\n",
    "            g -= 1\n",
    "        self.norm2 = nn.GroupNorm(g, cout)\n",
    "        self.skip = None\n",
    "        if stride != 1 or cin != cout:\n",
    "            self.skip = nn.Conv2d(cin, cout, 1, stride=stride, bias=False)\n",
    "\n",
    "        self.act = nn.SiLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x if self.skip is None else self.skip(x)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        if self.dropblock is not None:\n",
    "            out = self.dropblock(out)\n",
    "\n",
    "        out = self.norm2(self.conv2(out))\n",
    "\n",
    "        out = out + identity\n",
    "        return self.act(out)\n",
    "    \n",
    "class SmallResNetDropBlock(nn.Module):\n",
    "    def __init__(self, num_classes=10, dropblock_cfg=None):\n",
    "        super().__init__()\n",
    "\n",
    "        # 1) dropblock_cfg sözlüğü ile stage'lere ayrı DropBlock bağlayacağız\n",
    "        dropblock_cfg = dropblock_cfg or {}\n",
    "        db1 = dropblock_cfg.get(\"stage1\", None)\n",
    "        db2 = dropblock_cfg.get(\"stage2\", None)\n",
    "        db3 = dropblock_cfg.get(\"stage3\", None)\n",
    "\n",
    "        # 2) Stem: girişte kanal artır\n",
    "        self.stem = ConvGNAct(3, 64, k=3, s=1, p=1)\n",
    "\n",
    "        # 3) Stage 1: aynı çözünürlükte residual bloklar\n",
    "        self.stage1 = nn.Sequential(\n",
    "            ResidualBlock(64, 64, stride=1, dropblock=db1),\n",
    "            ResidualBlock(64, 64, stride=1, dropblock=db1),\n",
    "        )\n",
    "\n",
    "        # 4) Stage 2: stride=2 ile downsample + kanal artır\n",
    "        self.stage2 = nn.Sequential(\n",
    "            ResidualBlock(64, 128, stride=2, dropblock=db2),\n",
    "            ResidualBlock(128, 128, stride=1, dropblock=db2),\n",
    "        )\n",
    "\n",
    "        # 5) Stage 3: tekrar downsample + kanal artır\n",
    "        self.stage3 = nn.Sequential(\n",
    "            ResidualBlock(128, 256, stride=2, dropblock=db3),\n",
    "            ResidualBlock(256, 256, stride=1, dropblock=db3),\n",
    "        )\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.stage1(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.pool(x).flatten(1)\n",
    "        return self.fc(x)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) Cihaz seçimi\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # 2) DropBlock olmayan baseline model\n",
    "    baseline = SmallResNetDropBlock(num_classes=10, dropblock_cfg={}).to(device)\n",
    "\n",
    "    # 3) DropBlock'lu model:\n",
    "    dropblock_cfg = {\n",
    "        \"stage2\": DropBlock2D_Scheduled(max_drop_prob=0.15, block_size=5, total_steps=2000),\n",
    "        \"stage3\": DropBlock2D_Scheduled(max_drop_prob=0.20, block_size=7, total_steps=2000),\n",
    "    }\n",
    "    model_db = SmallResNetDropBlock(num_classes=10, dropblock_cfg=dropblock_cfg).to(device)\n",
    "\n",
    "    # 4) Dummy input üret\n",
    "    x = torch.randn(4, 3, 32, 32, device=device)\n",
    "\n",
    "    # 5) Train mod: DropBlock aktif\n",
    "    model_db.train()\n",
    "    y = model_db(x)\n",
    "    print(\"train out:\", y.shape)\n",
    "\n",
    "    # 6) Eval mod: DropBlock pasif\n",
    "    model_db.eval()\n",
    "    y2 = model_db(x)\n",
    "    print(\"eval out:\", y2.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
