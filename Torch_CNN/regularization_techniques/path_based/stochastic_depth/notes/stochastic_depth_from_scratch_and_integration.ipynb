{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stochastic Depth (Residual Block Drop) — Temelden Derine (PyTorch)\n",
        "\n",
        "Bu notebook şunları bitirir ✅  \n",
        "1) **Stochastic Depth nedir?** (mantık + amaç)  \n",
        "2) **DropPath ile ilişkisi** (aynı aile, farklı genelleme)  \n",
        "3) Matematiksel formül (inverted scaling)  \n",
        "4) **Sıfırdan implementasyon** (`stochastic_depth` + `StochasticDepth` module)  \n",
        "5) **Residual bloğa entegrasyon** (doğru yer: branch)  \n",
        "6) **Derinlik boyunca drop rate schedule** (linear decay)  \n",
        "7) Mini model örneği + sanity check\n",
        "\n",
        "> Kısa tanım: Stochastic Depth, eğitim sırasında bazı residual blokları **rastgele bypass** eder.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0) Problem: Derin ağlarda neden işe yarar?\n",
        "\n",
        "Derin ağlarda (ResNet gibi) şu risk var:\n",
        "- Model, çok derin olunca **overfit** ve **optimizasyon zorluğu** artar.\n",
        "- Her blok sürekli aktif olduğu için model belirli blok kombinasyonlarına aşırı bağımlı kalabilir.\n",
        "\n",
        "**Stochastic Depth** fikri:\n",
        "- Eğitimde bazı blokları kapat (skip et)\n",
        "- Model, farklı derinliklerde “alt ağlar” ile öğrenmiş gibi olur (**implicit ensemble**)\n",
        "- Testte tüm bloklar aktif kalır (tam kapasite)\n",
        "\n",
        "Bu Dropout’un \"neuron-level\" karşılığı değil; **block-level** bir regularization.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Stochastic Depth vs DropPath (çok net)\n",
        "\n",
        "- **Stochastic Depth**: genelde **residual bloğun tamamını** (branch'i) düşürür.\n",
        "- **DropPath**: daha genel isim; herhangi bir **path/branch** düşürebilir (Transformer/MBConv vs).\n",
        "\n",
        "ResNet için çoğu pratikte:\n",
        "> Stochastic Depth ≈ DropPath (residual branch üzerinde)\n",
        "\n",
        "Senin DropPath implementasyonun varsa, Stochastic Depth onun **özel hali** gibi düşünebilirsin.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Matematik (inverted scaling)\n",
        "\n",
        "Residual yapı:\n",
        "\\[\n",
        "y = x + F(x)\n",
        "\\]\n",
        "\n",
        "Stochastic Depth'te eğitim sırasında:\n",
        "- Olasılık \\(q = 1-p\\) ile branch tutulur\n",
        "- Olasılık \\(p\\) ile branch kapatılır (F(x)=0)\n",
        "\n",
        "Mask:\n",
        "\\[\n",
        "m \\sim Bernoulli(q) \\quad (m \\in \\{0,1\\})\n",
        "\\]\n",
        "\n",
        "İnverted scaling (beklenen değeri korumak için):\n",
        "\\[\n",
        "y = x + \\frac{m}{q} F(x)\n",
        "\\]\n",
        "\n",
        "- Eğer \\(m=0\\) → \\(y=x\\)  (blok bypass)\n",
        "- Eğer \\(m=1\\) → \\(y=x + F(x)/q\\)\n",
        "\n",
        "Eval modunda:\n",
        "\\[\n",
        "y = x + F(x)\n",
        "\\]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "# ===== 3) Imports & seed =====\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(0)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Sıfırdan: stochastic_depth fonksiyonu\n",
        "\n",
        "Bu fonksiyon **residual branch çıktısı** üzerinde çalışır.\n",
        "\n",
        "Girdi:\n",
        "- `x` = branch çıktısı (F(x))  -> shape: [B, C, H, W] (veya farklı)\n",
        "- `p` = drop probability\n",
        "- `training` = sadece train'de aktif\n",
        "\n",
        "Çıktı:\n",
        "- Ya 0'lanmış branch\n",
        "- Ya da ölçeklenmiş branch ( / q )\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "def stochastic_depth(x: torch.Tensor, p: float, training: bool) -> torch.Tensor:\n",
        "    \"\"\"Stochastic Depth / DropPath on a residual branch output.\n",
        "    x: residual branch output (F(x))\n",
        "    p: drop probability\n",
        "    \"\"\"\n",
        "    if not (0.0 <= p < 1.0):\n",
        "        raise ValueError(\"p must be in [0, 1).\")\n",
        "    if (not training) or p == 0.0:\n",
        "        return x\n",
        "\n",
        "    q = 1.0 - p  # keep prob\n",
        "\n",
        "    # Mask'i batch bazında üretiriz: [B, 1, 1, 1] -> tüm kanallara ve alana broadcast\n",
        "    # (ResNet Stochastic Depth'in tipik hali: sample-wise drop)\n",
        "    shape = (x.size(0),) + (1,) * (x.ndim - 1)\n",
        "    mask = torch.empty(shape, device=x.device, dtype=x.dtype).bernoulli_(q)\n",
        "\n",
        "    # inverted scaling: beklenen değer korunur\n",
        "    return x * mask / q\n",
        "\n",
        "# sanity check\n",
        "B, C, H, W = 4, 8, 16, 16\n",
        "branch = torch.randn(B, C, H, W)\n",
        "out = stochastic_depth(branch, p=0.5, training=True)\n",
        "out.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1) Maskeyi gözlemek (hangi örneklerde branch düştü?)\n",
        "\n",
        "Maske sample-wise olduğu için, bazı batch örnekleri tamamen 0'lanır.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "# Hangi örnekler düştü? (tam 0 olanları yakalayalım)\n",
        "p = 0.5\n",
        "branch = torch.randn(6, 4, 8, 8)\n",
        "d = stochastic_depth(branch, p=p, training=True)\n",
        "\n",
        "energy = d.abs().mean(dim=(1,2,3))  # her örnek için enerji\n",
        "energy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) nn.Module olarak: StochasticDepth\n",
        "\n",
        "`model.train()` iken çalışır, `model.eval()` iken identity davranır (branch'i dokunmadan bırakır).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "class StochasticDepth(nn.Module):\n",
        "    def __init__(self, p: float = 0.1):\n",
        "        super().__init__()\n",
        "        if not (0.0 <= p < 1.0):\n",
        "            raise ValueError(\"p must be in [0, 1).\")\n",
        "        self.p = float(p)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return stochastic_depth(x, p=self.p, training=self.training)\n",
        "\n",
        "sd = StochasticDepth(p=0.5)\n",
        "sd.train()\n",
        "a = sd(torch.randn(4,3,8,8))\n",
        "sd.eval()\n",
        "b = sd(torch.randn(4,3,8,8))\n",
        "a.shape, b.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Entegrasyon: Residual bloğa doğru yerleştirme\n",
        "\n",
        "**Kural:** Stochastic Depth, **residual branch (F(x))** üzerinde uygulanır.\n",
        "\n",
        "Yanlış:\n",
        "- skip yoluna uygulamak (identity'yi bozarsın)\n",
        "- residual toplama öncesi değil de, toplama sonrası rastgele sıfırlamak (felsefe değişir)\n",
        "\n",
        "Doğru akış:\n",
        "1) `out = F(x)`\n",
        "2) `out = SD(out)`\n",
        "3) `y = x + out`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "class BasicResBlockSD(nn.Module):\n",
        "    def __init__(self, cin: int, cout: int, stride: int = 1, sd_p: float = 0.1, act: str = \"relu\"):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(cin, cout, 3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(cout)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(cout, cout, 3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(cout)\n",
        "\n",
        "        self.act = nn.ReLU(inplace=True) if act == \"relu\" else nn.SiLU(inplace=True)\n",
        "\n",
        "        # Stochastic Depth module (branch üzerinde)\n",
        "        self.sd = StochasticDepth(p=sd_p)\n",
        "\n",
        "        # shortcut/proj\n",
        "        self.shortcut = nn.Identity()\n",
        "        if stride != 1 or cin != cout:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(cin, cout, 1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(cout)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = self.shortcut(x)\n",
        "\n",
        "        out = self.act(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "\n",
        "        # SD -> branch drop / scale\n",
        "        out = self.sd(out)\n",
        "\n",
        "        out = out + identity\n",
        "        out = self.act(out)\n",
        "        return out\n",
        "\n",
        "blk = BasicResBlockSD(16, 16, sd_p=0.5).to(device)\n",
        "blk.train()\n",
        "y = blk(torch.randn(4,16,32,32, device=device))\n",
        "y.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Drop rate schedule (derinlik boyunca lineer artış)\n",
        "\n",
        "Pratikte Stochastic Depth şöyle uygulanır:\n",
        "- Erken bloklar: düşük drop (p küçük)\n",
        "- Derin bloklar: yüksek drop (p büyük)\n",
        "\n",
        "Çünkü:\n",
        "- Erken bloklar temel feature çıkarır; sık düşürmek istemezsin\n",
        "- Derin bloklar daha spesifik; regularize etmek daha mantıklı\n",
        "\n",
        "Lineer schedule örneği:\n",
        "\\[\n",
        "p_i = p_{max} \\cdot \\frac{i}{L-1}\n",
        "\\]\n",
        "(i: blok index, L: toplam blok sayısı)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "def make_sd_probs(num_blocks: int, p_max: float):\n",
        "    if num_blocks <= 1:\n",
        "        return [p_max]\n",
        "    return [p_max * i / (num_blocks - 1) for i in range(num_blocks)]\n",
        "\n",
        "make_sd_probs(6, 0.2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Mini model: Stage'lerde SD schedule ile kullan\n",
        "\n",
        "Bu model:\n",
        "- stem\n",
        "- 6 residual block\n",
        "- her block için farklı sd_p (lineer)\n",
        "- GAP + FC\n",
        "\n",
        "Amaç: entegrasyon kalıbını görmek.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "class TinyResNetWithStochasticDepth(nn.Module):\n",
        "    def __init__(self, num_classes=10, base_channels=32, blocks=6, sd_max=0.2):\n",
        "        super().__init__()\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(3, base_channels, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(base_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        probs = make_sd_probs(blocks, sd_max)\n",
        "        layers = []\n",
        "        c = base_channels\n",
        "        for i in range(blocks):\n",
        "            # örnek amaçlı: 3 bloktan sonra downsample\n",
        "            if i == blocks // 2:\n",
        "                layers.append(BasicResBlockSD(c, c*2, stride=2, sd_p=probs[i]))\n",
        "                c *= 2\n",
        "            else:\n",
        "                layers.append(BasicResBlockSD(c, c, stride=1, sd_p=probs[i]))\n",
        "        self.blocks = nn.Sequential(*layers)\n",
        "\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Linear(c, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        x = self.blocks(x)\n",
        "        x = self.pool(x).flatten(1)\n",
        "        return self.fc(x)\n",
        "\n",
        "model = TinyResNetWithStochasticDepth(num_classes=100, blocks=6, sd_max=0.3).to(device)\n",
        "model.train()\n",
        "logits = model(torch.randn(2,3,32,32, device=device))\n",
        "logits.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) Pratik ayarlar (senin repo için net öneri)\n",
        "\n",
        "- Başlangıç `sd_max`: **0.05 – 0.2**\n",
        "- Çok derin modelde (50+ layer) `sd_max`: **0.2 – 0.5** (dataset/augment/WD’e bağlı)\n",
        "- Dropout/SpatialDropout ile birlikte kullanacaksan:\n",
        "  - SD (block-level) ana regularizer olur\n",
        "  - activation-level dropout’u düşük tut (p≈0.05–0.15)\n",
        "\n",
        "**Yerleşim:**  \n",
        "- `F(x)` çıktısına, `x + F(x)` toplamadan hemen önce.\n",
        "\n",
        "Sıradaki adım (istersen):  \n",
        "- Bu SD’yi senin mevcut `DropPath` kodunla aynı API’ye bağlamak (tek modül, iki mod).\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}