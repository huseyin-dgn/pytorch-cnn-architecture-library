{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stochastic Depth — Modele Entegrasyon (DropPath/SD) | Baştan Sona\n",
        "\n",
        "Bu notebook **entegrasyon odaklıdır** ✅  \n",
        "Spatial Dropout notebook’undaki gibi şu akış var:\n",
        "\n",
        "1) Kısaca: Stochastic Depth nedir, nerede durur?  \n",
        "2) En temiz implementasyon: `stochastic_depth()` + `StochasticDepth` modülü  \n",
        "3) **Residual block içine entegrasyon** (doğru yer: branch)  \n",
        "4) **Stage / tüm model entegrasyonu** (make_stage mantığı)  \n",
        "5) **Drop rate schedule** (derinlik boyunca lineer artış)  \n",
        "6) CIFAR tarzı mini model ile “çalışıyor mu?” testi  \n",
        "7) DropPath ile aynı API’ye bağlama önerisi\n",
        "\n",
        "> Not: Stochastic Depth = Residual branch'i bazen bypass etmek.  \n",
        "> Eval modunda tüm bloklar aktiftir.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# ===== 0) Imports =====\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(0)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Entegrasyonun tek kritik kuralı\n",
        "\n",
        "Residual yapı:\n",
        "\\[\n",
        "y = x + F(x)\n",
        "\\]\n",
        "\n",
        "Stochastic Depth'in uygulanacağı yer:\n",
        "- **F(x)** branch çıktısı\n",
        "\n",
        "Doğru:\n",
        "1) `out = F(x)`\n",
        "2) `out = SD(out)`  ✅\n",
        "3) `y = x + out`\n",
        "\n",
        "Yanlış:\n",
        "- identity/skip yolunu düşürmek\n",
        "- toplama sonrası rastgele sıfırlamak\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Core implementasyon\n",
        "\n",
        "- Drop prob: **p**\n",
        "- Keep prob: **q = 1-p**\n",
        "- Sample-wise mask: `[B, 1, 1, 1]` (tüm kanallara/spatial alana broadcast)\n",
        "\n",
        "Inverted scaling:\n",
        "\\[\n",
        "out = out \\cdot \\frac{m}{q}\n",
        "\\]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 16, 16])"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def stochastic_depth(x: torch.Tensor, p: float, training: bool) -> torch.Tensor:\n",
        "\n",
        "    if not (0.0 <= p < 1.0):\n",
        "        raise ValueError(\"p must be in [0, 1).\")\n",
        "    if (not training) or p == 0.0:\n",
        "        return x\n",
        "\n",
        "    q = 1.0 - p\n",
        "    # sample-wise mask: [B, 1, 1, 1] (or broadcast for ndim)\n",
        "    shape = (x.size(0),) + (1,) * (x.ndim - 1)\n",
        "    mask = torch.empty(shape, device=x.device, dtype=x.dtype).bernoulli_(q)\n",
        "    return x * mask / q\n",
        "\n",
        "\n",
        "class StochasticDepth(nn.Module):\n",
        "    def __init__(self, p: float = 0.1):\n",
        "        super().__init__()\n",
        "        if not (0.0 <= p < 1.0):\n",
        "            raise ValueError(\"p must be in [0, 1).\")\n",
        "        self.p = float(p)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return stochastic_depth(x, p=self.p, training=self.training)\n",
        "\n",
        "# quick sanity\n",
        "sd = StochasticDepth(p=0.5)\n",
        "sd.train()\n",
        "t = sd(torch.randn(4, 8, 16, 16))\n",
        "t.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Residual Block'a entegrasyon (en klasik kalıp)\n",
        "\n",
        "Burada SD, **ikinci conv sonrası** branch çıktısına uygulanır.\n",
        "\n",
        "Akış:\n",
        "- conv1 → bn1 → act\n",
        "- conv2 → bn2\n",
        "- **sd(out)**\n",
        "- out + identity\n",
        "- act\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 32, 32, 32])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class BasicResBlockSD(nn.Module):\n",
        "    def __init__(self, cin: int, cout: int, stride: int = 1, sd_p: float = 0.0, act: str = \"relu\"):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(cin, cout, 3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(cout)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(cout, cout, 3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(cout)\n",
        "\n",
        "        self.act = nn.ReLU(inplace=True) if act == \"relu\" else nn.SiLU(inplace=True)\n",
        "        self.sd = StochasticDepth(p=sd_p)\n",
        "\n",
        "        self.shortcut = nn.Identity()\n",
        "        if stride != 1 or cin != cout:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(cin, cout, 1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(cout)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = self.shortcut(x)\n",
        "\n",
        "        out = self.act(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "\n",
        "        # ✅ Stochastic Depth branch üzerinde\n",
        "        out = self.sd(out)\n",
        "\n",
        "        out = out + identity\n",
        "        out = self.act(out)\n",
        "        return out\n",
        "\n",
        "blk = BasicResBlockSD(32, 32, sd_p=0.2).to(device)\n",
        "blk.train()\n",
        "y = blk(torch.randn(4,32,32,32, device=device))\n",
        "y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Tüm modele entegrasyon: Stage + SD schedule\n",
        "\n",
        "Gerçek projede en doğru kullanım:\n",
        "- blok sayısı boyunca **sd_p lineer artar**\n",
        "- erken bloklar: sd_p küçük\n",
        "- derin bloklar: sd_p büyük\n",
        "\n",
        "Lineer schedule:\n",
        "\\[\n",
        "p_i = p_{max} \\cdot \\frac{i}{L-1}\n",
        "\\]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.0,\n",
              " 0.04285714285714286,\n",
              " 0.08571428571428572,\n",
              " 0.12857142857142856,\n",
              " 0.17142857142857143,\n",
              " 0.21428571428571427,\n",
              " 0.2571428571428571,\n",
              " 0.3]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "def make_sd_probs(num_blocks: int, p_max: float):\n",
        "    if num_blocks <= 1:\n",
        "        return [p_max]\n",
        "    return [p_max * i / (num_blocks - 1) for i in range(num_blocks)]\n",
        "\n",
        "make_sd_probs(8, 0.3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1) make_stage \n",
        "\n",
        "Aşağıdaki fonksiyon:\n",
        "- `num_blocks` kadar block üretir\n",
        "- her block’a farklı `sd_p` verir\n",
        "- stride sadece ilk blokta uygulanır (klasik ResNet stage)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_stage(cin: int, cout: int, num_blocks: int, stride: int, sd_probs, act=\"relu\"):\n",
        "    layers = []\n",
        "    for i in range(num_blocks):\n",
        "        s = stride if i == 0 else 1\n",
        "        layers.append(BasicResBlockSD(cin if i == 0 else cout, cout, stride=s, sd_p=sd_probs[i], act=act))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "# örnek\n",
        "sd_probs = make_sd_probs(3, 0.2)\n",
        "stage = make_stage(32, 64, num_blocks=3, stride=2, sd_probs=sd_probs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Mini model: CIFAR-like ResNet + SD\n",
        "\n",
        "- Stem\n",
        "- Stage1 (32)\n",
        "- Stage2 (64, downsample)\n",
        "- Stage3 (128, downsample)\n",
        "- GAP + FC\n",
        "\n",
        "SD schedule:\n",
        "- Tüm bloklar sayılır\n",
        "- sd_p, `sd_max`’e kadar lineer artar\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 10])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "class TinyResNetStochasticDepth(nn.Module):\n",
        "    def __init__(self, num_classes=100, sd_max=0.2, blocks=(2,2,2), act=\"relu\"):\n",
        "        super().__init__()\n",
        "\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True) if act == \"relu\" else nn.SiLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        total_blocks = sum(blocks)\n",
        "        all_probs = make_sd_probs(total_blocks, sd_max)\n",
        "\n",
        "        idx = 0\n",
        "        probs1 = all_probs[idx: idx+blocks[0]]; idx += blocks[0]\n",
        "        probs2 = all_probs[idx: idx+blocks[1]]; idx += blocks[1]\n",
        "        probs3 = all_probs[idx: idx+blocks[2]]; idx += blocks[2]\n",
        "\n",
        "        self.stage1 = make_stage(32, 32, blocks[0], stride=1, sd_probs=probs1, act=act)\n",
        "        self.stage2 = make_stage(32, 64, blocks[1], stride=2, sd_probs=probs2, act=act)\n",
        "        self.stage3 = make_stage(64, 128, blocks[2], stride=2, sd_probs=probs3, act=act)\n",
        "\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "        x = self.stage3(x)\n",
        "        x = self.pool(x).flatten(1)\n",
        "        return self.fc(x)\n",
        "\n",
        "model = TinyResNetStochasticDepth(num_classes=10, sd_max=0.3, blocks=(2,2,2)).to(device)\n",
        "model.train()\n",
        "logits = model(torch.randn(2,3,32,32, device=device))\n",
        "logits.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Entegrasyon doğrulama: train vs eval farkı\n",
        "\n",
        "- `model.train()` → bazı örneklerde branch drop olur\n",
        "- `model.eval()` → drop yok, tüm bloklar aktif\n",
        "\n",
        "Aşağıda aynı input ile train/eval çıktıları aynı olmak zorunda değil (BN, dropout vs), ama SD’nin aktif/pasif olduğunu gözlemleyebilirsin.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train outputs equal?  False\n",
            "eval outputs equal?   True\n"
          ]
        }
      ],
      "source": [
        "\n",
        "x = torch.randn(2,3,32,32, device=device)\n",
        "\n",
        "model.train()\n",
        "y_train_1 = model(x)\n",
        "y_train_2 = model(x)  # SD maskesi değişebilir\n",
        "\n",
        "model.eval()\n",
        "y_eval_1 = model(x)\n",
        "y_eval_2 = model(x)\n",
        "\n",
        "print(\"train outputs equal? \", torch.allclose(y_train_1, y_train_2))\n",
        "print(\"eval outputs equal?  \", torch.allclose(y_eval_1, y_eval_2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Pratik ayarlar (kısa ve net)\n",
        "\n",
        "- CIFAR benzeri küçük modeller: `sd_max = 0.05 – 0.2`\n",
        "- Daha derin/Transformer: `sd_max = 0.1 – 0.5`\n",
        "\n",
        "Kombinasyon:\n",
        "- Eğer Dropout/SpatialDropout da varsa: onları düşük tut.\n",
        "- SD ana regularizer olsun (block-level).\n",
        "\n",
        "En sık hata:\n",
        "- SD’yi **skip yoluna** koymak ❌\n",
        "- Doğru yer: **residual branch** ✅\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "torch_gpu",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
