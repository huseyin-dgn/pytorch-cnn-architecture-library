{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b4c74bf",
   "metadata": {},
   "source": [
    "# DropPath (Stochastic Depth) — Baştan Sona Tanım, Kod, ve Modele Entegrasyonu\n",
    "\n",
    "Bu notebook 3 şeyi yapar:\n",
    "\n",
    "1) **DropPath’in ne olduğunu** en temelden ileri seviyeye açıklar (neden var, hangi problemi çözer, matematik).  \n",
    "2) DropPath’in **kodunu adım adım inşa eder** (fonksiyonel → modül → schedule).  \n",
    "3) DropPath’i bir **residual CNN modele entegre eder** ve entegrasyonu **model üzerinden açıklar**.\n",
    "\n",
    "> Not: Kodlar “minimal ama gerçek” olacak şekilde seçildi. Amaç: DropPath mantığını net görmek.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb1ed111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab1e72e",
   "metadata": {},
   "source": [
    "## 0) Bu importlar ne işe yarıyor?\n",
    "\n",
    "- `torch`: Tensor işlemleri, GPU kullanımı vb.\n",
    "- `torch.nn`: Modül (layer) tanımlamak için sınıflar (Conv2d, BatchNorm2d, Module vb.)\n",
    "- `torch.nn.functional`: Fonksiyonel API (loss, aktivasyon, bazı opsiyonlar)\n",
    "\n",
    "Bu notebook’ta DropPath bir **nn.Module** olarak yazılacağı için `nn` kullanıyoruz.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020f0bf6",
   "metadata": {},
   "source": [
    "\\\n",
    "## 1) En temel: Residual blok ne yapar?\n",
    "\n",
    "Residual blok fikri:\n",
    "\\[\n",
    "y = x + F(x)\n",
    "\\]\n",
    "\n",
    "- \\(x\\): giriş (identity/skip yol)\n",
    "- \\(F(x)\\): “öğrenen” yol (residual branch)\n",
    "\n",
    "ResNet’in gücü burada:\n",
    "- Eğer \\(F(x)\\) işe yaramazsa model yine de \\(y \\approx x\\) ile stabil kalır.\n",
    "- Derin ağlarda gradyan akışı daha sağlıklı olur.\n",
    "\n",
    "DropPath tam bu yapıya oturur: **bazen \\(F(x)\\) yolunu kapatıp sadece \\(x\\) ile geçmek**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddde13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Çok minimal bir residual ifade (sadece fikir)\n",
    "def residual_forward(x, fx):\n",
    "    return x + fx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743f0736",
   "metadata": {},
   "source": [
    "### Bu kod bloğu ne anlatıyor?\n",
    "\n",
    "- Bu bir “model” değil; sadece matematiksel fikri kodlaştırdık.\n",
    "- `fx` burada \\(F(x)\\) üretimi gibi düşün.\n",
    "- Çıktı: `x + fx` → residual toplama.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5a7f1c",
   "metadata": {},
   "source": [
    "\\\n",
    "## 2) DropPath fikri: “Yolu bazen kapat”\n",
    "\n",
    "DropPath eğitim sırasında şu işlemi yapar:\n",
    "\n",
    "\\[\n",
    "y = x + \\frac{m}{p}F(x), \\quad m \\sim \\mathrm{Bernoulli}(p)\n",
    "\\]\n",
    "\n",
    "- \\(p\\): **keep probability** (yolu açık tutma olasılığı)\n",
    "- \\(m\\): 0 veya 1 üreten rastgele maske\n",
    "  - \\(m = 0\\) → residual yol kapalı → \\(y = x\\)\n",
    "  - \\(m = 1\\) → residual yol açık → \\(y = x + \\frac{1}{p}F(x)\\)\n",
    "\n",
    "Neden \\(\\frac{1}{p}\\) ile ölçekliyoruz?\n",
    "- Çünkü eğitimde bazen kapatıyoruz → beklenen değer düşer.\n",
    "- \\(\\frac{1}{p}\\) ile ölçekleyerek **beklenen (expected) aktivasyon seviyesini** koruyoruz.\n",
    "\n",
    "**Inference (eval)** zamanında DropPath kapalıdır:\n",
    "\\[\n",
    "y = x + F(x)\n",
    "\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbb7931",
   "metadata": {},
   "source": [
    "## 3) DropPath’i en basit haliyle fonksiyon olarak yazalım\n",
    "\n",
    "Önce “modül sınıfı” yazmadan önce, fikri fonksiyonla kurmak anlaşılır:\n",
    "- training’de maske üret\n",
    "- residual çıkışı `mask / keep_prob` ile çarp\n",
    "- eval’de dokunma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94ae9ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def droppath_fn(x: torch.Tensor, drop_prob: float, training: bool) -> torch.Tensor:\n",
    "    \"\"\"Fonksiyonel DropPath.\n",
    "    x: residual branch çıktısı (F(x))\n",
    "    drop_prob: yolu kapatma olasılığı\n",
    "    \"\"\"\n",
    "    if drop_prob == 0.0 or (not training):\n",
    "        return x\n",
    "\n",
    "    keep_prob = 1.0 - drop_prob\n",
    "\n",
    "    # Batch-wise maske: her örnek için tek karar (0/1)\n",
    "    shape = (x.shape[0],) + (1,) * (x.ndim - 1)  # (B,1,1,1) veya (B,1)\n",
    "    mask = torch.empty(shape, device=x.device, dtype=x.dtype).bernoulli_(keep_prob)\n",
    "\n",
    "    # Beklenen değeri koru\n",
    "    return x * mask / keep_prob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b710ea1",
   "metadata": {},
   "source": [
    "### Bu kod bloğu ne yapıyor? (satır satır mantık)\n",
    "\n",
    "- `drop_prob == 0` veya `training=False` ise: **hiçbir şey yapmadan** `x` döndürür.\n",
    "- `keep_prob = 1 - drop_prob`: yolun açık kalma olasılığı.\n",
    "- `shape = (B,1,1,1,...)`: **batch bazlı** mask üretir.\n",
    "  - Yani her örnek için “bu residual yol açık mı kapalı mı?” tek bir Bernoulli kararı.\n",
    "- `bernoulli_(keep_prob)`: keep_prob olasılıkla 1 üretir.\n",
    "- `x * mask / keep_prob`: kapalıysa sıfır, açıksa ölçekli residual döner.\n",
    "\n",
    "Bu fonksiyonun önemli özelliği:\n",
    "> DropPath **spatial bir maske üretmez**, feature map’in bir kısmını değil **residual yolun tamamını** etkiler.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7255f1c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 64, 16, 16]), 0.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick sanity check\n",
    "x = torch.randn(4, 64, 16, 16)\n",
    "y_train = droppath_fn(x, drop_prob=0.5, training=True)\n",
    "y_eval  = droppath_fn(x, drop_prob=0.5, training=False)\n",
    "\n",
    "y_train.shape, (y_eval - x).abs().max().item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84693cd4",
   "metadata": {},
   "source": [
    "### Bu test ne gösterir?\n",
    "- `y_train.shape` aynı kalır (DropPath şekli bozmaz).\n",
    "- `training=False` iken `y_eval == x` (maks fark ~0) → inference’ta DropPath devre dışıdır.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70e78d9",
   "metadata": {},
   "source": [
    "## 4) DropPath’i nn.Module olarak yazalım (pratik kullanım)\n",
    "\n",
    "Model içine tak-çıkar için DropPath genelde şu şekilde yazılır:\n",
    "- `DropPath(drop_prob)` bir katman gibi durur\n",
    "- `forward()` içinde training kontrolü yapar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30984c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropPath(nn.Module):\n",
    "    \"\"\"DropPath (Stochastic Depth) - path-level dropout.\"\"\"\n",
    "    def __init__(self, drop_prob: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.drop_prob = float(drop_prob)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return droppath_fn(x, self.drop_prob, self.training)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba38ca3",
   "metadata": {},
   "source": [
    "### Bu kod bloğu ne yapıyor?\n",
    "\n",
    "- `DropPath` bir **katman gibi** davranır.\n",
    "- `self.training` PyTorch’un standart flag’ıdır:\n",
    "  - `model.train()` → training=True\n",
    "  - `model.eval()` → training=False\n",
    "- `forward()` içinde az önce yazdığımız fonksiyona delegasyon yapıyoruz.\n",
    "\n",
    "Bu yapı, DropPath’i model içinde şu şekilde kullanmanı sağlar:\n",
    "```python\n",
    "self.dp = DropPath(0.1)\n",
    "out = self.dp(residual_out)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8713d8c2",
   "metadata": {},
   "source": [
    "\\\n",
    "## 5) İleri seviye: DropPath oranını derinliğe göre schedule etmek\n",
    "\n",
    "Pratikte DropPath genelde şu şekilde ayarlanır:\n",
    "\n",
    "- Sığ bloklar: drop düşük\n",
    "- Derin bloklar: drop yüksek\n",
    "\n",
    "Lineer schedule örneği:\n",
    "\\[\n",
    "drop(\\ell) = d_{max} \\cdot \\frac{\\ell}{L-1}\n",
    "\\]\n",
    "\n",
    "- \\(\\ell\\): blok index’i (0..L-1)\n",
    "- \\(L\\): toplam blok sayısı\n",
    "- \\(d_{max}\\): maksimum drop rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fafdd23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.04000000000000001, 0.08000000000000002, 0.12, 0.16000000000000003, 0.2]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def droppath_rate_at(block_idx: int, num_blocks: int, max_drop: float) -> float:\n",
    "    if num_blocks <= 1:\n",
    "        return 0.0\n",
    "    return float(max_drop) * (block_idx / (num_blocks - 1))\n",
    "\n",
    "# örnek: 6 blokta max_drop=0.2\n",
    "rates = [droppath_rate_at(i, 6, 0.2) for i in range(6)]\n",
    "rates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162198c5",
   "metadata": {},
   "source": [
    "### Bu kod bloğu ne yapıyor?\n",
    "\n",
    "- `block_idx=0` için drop ≈ 0 (sığ katmanlar stabil kalsın)\n",
    "- `block_idx` arttıkça drop artar\n",
    "- Son blokta drop ≈ `max_drop`\n",
    "\n",
    "Bu schedule özellikle derin ResNet/Transformer’larda stabiliteyi artırır.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80da6b2b",
   "metadata": {},
   "source": [
    "## 6) DropPath’i residual bloğa entegre edelim\n",
    "\n",
    "En önemli kural:\n",
    "> DropPath **residual branch çıktısına** uygulanır ve **toplama öncesinde** durur.\n",
    "\n",
    "Yani:\n",
    "1) \\(F(x)\\) hesaplanır  \n",
    "2) `DropPath(F(x))` uygulanır  \n",
    "3) `+ x` yapılır  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a56bdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicResBlock(nn.Module):\n",
    "    \"\"\"Conv-BN-Act -> Conv-BN -> DropPath -> +Skip -> Act\"\"\"\n",
    "    def __init__(self, cin: int, cout: int, stride: int = 1, drop_path: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(cin, cout, 3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(cout)\n",
    "        self.act = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(cout, cout, 3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(cout)\n",
    "\n",
    "        # DropPath residual yolun ÇIKIŞINA uygulanacak\n",
    "        self.dp = DropPath(drop_path)\n",
    "\n",
    "        self.skip = nn.Identity()\n",
    "        if stride != 1 or cin != cout:\n",
    "            self.skip = nn.Sequential(\n",
    "                nn.Conv2d(cin, cout, 1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(cout),\n",
    "            )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        identity = self.skip(x)\n",
    "\n",
    "        out = self.act(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "\n",
    "        out = self.dp(out)  # <-- DropPath: residual branch'e uygulanır\n",
    "        out = self.act(out + identity)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377f7cda",
   "metadata": {},
   "source": [
    "### Bu kod bloğu (model entegrasyonu) ne anlatıyor?\n",
    "\n",
    "- `identity = self.skip(x)` → skip yolu (x veya 1×1 projeksiyon)\n",
    "- `out = ...` → residual branch \\(F(x)\\) üretimi\n",
    "- `out = self.dp(out)` → **DropPath burada**:\n",
    "  - training’de bazen `out` sıfırlanır → blok “atlandı” gibi olur\n",
    "  - eval’de dokunulmaz\n",
    "  - açık kaldığında `1/keep_prob` ile ölçeklenir\n",
    "- `out + identity` → residual toplama\n",
    "- final `act` → blok çıkışı\n",
    "\n",
    "Bu entegrasyon DropBlock’tan farklıdır:\n",
    "- DropBlock: feature map’in **bazı bölgelerini** siler (spatial)\n",
    "- DropPath: residual branch’in **tamamını** kapatır (structural)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24ad7cc",
   "metadata": {},
   "source": [
    "## 7) Küçük bir modelde DropPath’i “blok bazlı schedule” ile kullanalım\n",
    "\n",
    "Aşağıda CIFAR benzeri girişler için küçük bir ResNet türevi var:\n",
    "- 6 adet residual blok\n",
    "- DropPath oranı blok derinliğine göre lineer artıyor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3b2f9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetSmallDropPath(nn.Module):\n",
    "    def __init__(self, num_classes: int = 100, max_drop: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # toplam blok sayısı: 6 (2 + 2 + 2)\n",
    "        total_blocks = 6\n",
    "        idx = 0\n",
    "\n",
    "        # stage1 (32x32)\n",
    "        dp1 = droppath_rate_at(idx, total_blocks, max_drop); idx += 1\n",
    "        dp2 = droppath_rate_at(idx, total_blocks, max_drop); idx += 1\n",
    "        self.stage1 = nn.Sequential(\n",
    "            BasicResBlock(64, 64, stride=1, drop_path=dp1),\n",
    "            BasicResBlock(64, 64, stride=1, drop_path=dp2),\n",
    "        )\n",
    "\n",
    "        # stage2 (16x16)\n",
    "        dp3 = droppath_rate_at(idx, total_blocks, max_drop); idx += 1\n",
    "        dp4 = droppath_rate_at(idx, total_blocks, max_drop); idx += 1\n",
    "        self.stage2 = nn.Sequential(\n",
    "            BasicResBlock(64, 128, stride=2, drop_path=dp3),\n",
    "            BasicResBlock(128, 128, stride=1, drop_path=dp4),\n",
    "        )\n",
    "\n",
    "        # stage3 (8x8)\n",
    "        dp5 = droppath_rate_at(idx, total_blocks, max_drop); idx += 1\n",
    "        dp6 = droppath_rate_at(idx, total_blocks, max_drop); idx += 1\n",
    "        self.stage3 = nn.Sequential(\n",
    "            BasicResBlock(128, 256, stride=2, drop_path=dp5),\n",
    "            BasicResBlock(256, 256, stride=1, drop_path=dp6),\n",
    "        )\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.stem(x)\n",
    "        x = self.stage1(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        return self.head(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e334a7af",
   "metadata": {},
   "source": [
    "### Bu kod bloğu ne yapıyor? (entegrasyonu model üzerinden oku)\n",
    "\n",
    "- `max_drop`: en derin blokta uygulanacak maksimum drop rate (örn 0.1)\n",
    "- `droppath_rate_at(...)`: blok indeksi arttıkça drop rate artar\n",
    "- Her `BasicResBlock` kendi `drop_path` oranıyla `DropPath` içerir:\n",
    "  - `BasicResBlock(... drop_path=dp_k)`\n",
    "- Böylece:\n",
    "  - erken bloklar ≈ 0’a yakın drop (stabil öğrenme)\n",
    "  - geç bloklar daha yüksek drop (regularization)\n",
    "\n",
    "Bu modelin “DropPath’i entegre etme” şekli:\n",
    "> DropPath her residual bloğun içinde, residual branch çıktısına uygulanarak yapılır.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770e1b26",
   "metadata": {},
   "source": [
    "## 8) Hızlı Çalışma Testi (Shape + Train/Eval farkı)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d2d0377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 100]), torch.Size([8, 100]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNetSmallDropPath(num_classes=100, max_drop=0.2)\n",
    "x = torch.randn(8, 3, 32, 32)\n",
    "\n",
    "model.train()\n",
    "y_train = model(x)\n",
    "\n",
    "model.eval()\n",
    "y_eval = model(x)\n",
    "\n",
    "y_train.shape, y_eval.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952c3633",
   "metadata": {},
   "source": [
    "### Bu test neyi gösterir?\n",
    "- Train ve eval modda çıktı şekli aynıdır.\n",
    "- Train modda DropPath aktif olduğu için `y_train` deterministik değildir (her forward’da mask değişebilir).\n",
    "- Eval modda DropPath kapalıdır, model deterministik davranır.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
