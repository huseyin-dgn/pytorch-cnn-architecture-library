{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d36f9a84",
   "metadata": {},
   "source": [
    "# DropPath (Generalized Stochastic Depth) — Teori Notları\n",
    "\n",
    "Bu notlar DropPath (genelleştirilmiş *Stochastic Depth*) fikrini, amaçlarını ve pratikte nasıl kullanıldığını özetler.  \n",
    "Odak: **residual/skip bağlantılı ağlarda** *path* seviyesinde düzenlileştirme (regularization).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c478e814",
   "metadata": {},
   "source": [
    "\\\n",
    "## 1) Dropout → DropPath geçiş motivasyonu\n",
    "\n",
    "**Dropout** klasik olarak *aktivasyonları* (nöronları) rastgele sıfırlar:  \n",
    "\\[\n",
    "y = x \\odot m,\\quad m_i \\sim \\mathrm{Bernoulli}(p)\n",
    "\\]\n",
    "- Burada \\(p\\): *keep probability* (tutma olasılığı).\n",
    "\n",
    "CNN/ResNet gibi yapılarda kritik bir gözlem var:\n",
    "\n",
    "- “Tek tek nöron düşürmek” yerine, **bir bloğun (residual branch’in) tamamını** bazen kapatmak daha doğal bir düzenlileştirme sağlar.\n",
    "- Çünkü ResNet’te öğrenme çoğunlukla “**identity + residual**” kombinasyonu üzerinden yürür.\n",
    "\n",
    "Bu fikirden **Stochastic Depth** doğar:  \n",
    "> Eğitim sırasında bazı residual bloklar *rastgele atlanır* (skip yolu açık kalır).\n",
    "\n",
    "DropPath bunun **genelleştirilmiş** formudur:  \n",
    "> Sadece “blok atlama” değil, model içindeki farklı *branch/path* bileşenlerini rastgele düşürmeye izin verir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ed91de",
   "metadata": {},
   "source": [
    "\\\n",
    "## 2) DropPath nedir?\n",
    "\n",
    "Tipik residual blok:\n",
    "\\[\n",
    "y = x + F(x)\n",
    "\\]\n",
    "DropPath ile eğitim sırasında:\n",
    "- \\(F(x)\\) bazen sıfırlanır (*path drop*),\n",
    "- bazen korunur (*keep*).\n",
    "\n",
    "Formül:\n",
    "\\[\n",
    "y = x + \\frac{m}{p} F(x),\\quad m \\sim \\mathrm{Bernoulli}(p)\n",
    "\\]\n",
    "\n",
    "- \\(m=0\\) ise \\(F(x)\\) tamamen kapanır → \\(y = x\\)\n",
    "- \\(m=1\\) ise residual korunur ama **\\(\\frac{1}{p}\\)** ile ölçeklenir (beklenen değer korunur).\n",
    "\n",
    "> \\(\\frac{m}{p}\\) ölçekleme, test zamanında “her şeyi açık” çalıştırırken beklenen aktivasyon seviyesini sabitlemek içindir.\n",
    "\n",
    "**Test (eval) modunda** DropPath kapalıdır:\n",
    "\\[\n",
    "y = x + F(x)\n",
    "\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a546a4b7",
   "metadata": {},
   "source": [
    "\\\n",
    "## 3) Amaç / neyi çözer?\n",
    "\n",
    "### (a) Daha derin ağlarda genelleme\n",
    "Derinleştikçe model kapasitesi artar → overfit riski artar.  \n",
    "DropPath, “aktif derinliği” eğitim boyunca değiştirerek ensemble benzeri etki üretir:\n",
    "\n",
    "- bazı iterasyonlarda ağ daha sığ\n",
    "- bazı iterasyonlarda daha derin\n",
    "\n",
    "Bu, tek bir ağı “çok sayıda alt-ağa” dönüştürür.\n",
    "\n",
    "### (b) Residual branch’in aşırı güvenilmesini önleme\n",
    "ResNet’te model bazen residual branch’i fazla agresif kullanır.  \n",
    "DropPath, residual’a *rastgele kapatma* uygulayarak “identity” yolunun da anlamlı kalmasını sağlar.\n",
    "\n",
    "### (c) Path/branch tabanlı mimarilerde doğal düzenlileştirme\n",
    "- ResNeXt (çoklu branch)\n",
    "- Inception benzeri paralel yollar\n",
    "- Transformer blokları (MLP + Attention yolları)\n",
    "DropPath bu yapılarda “branch-level dropout” gibi davranır.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e808a0",
   "metadata": {},
   "source": [
    "\\\n",
    "## 4) DropPath vs Stochastic Depth\n",
    "\n",
    "- **Stochastic Depth**: genelde *residual block* seviyesinde “blok düşürme” olarak anlatılır.\n",
    "- **DropPath**: aynı fikrin daha genel implementasyon ismi (özellikle modern kütüphanelerde).\n",
    "\n",
    "Pratikte çoğu repo:\n",
    "- `DropPath` sınıfı yazar\n",
    "- “stochastic depth” hyperparametresiyle bu sınıfı kullanır.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce32cd72",
   "metadata": {},
   "source": [
    "\\\n",
    "## 5) Drop prob / keep prob nasıl seçilir? (schedule mantığı)\n",
    "\n",
    "DropPath genelde katman derinliği arttıkça güçlenir:\n",
    "- erken katmanlar: daha az drop\n",
    "- geç katmanlar: daha çok drop\n",
    "\n",
    "Sık kullanılan lineer schedule:\n",
    "\\[\n",
    "p_\\ell = 1 - d \\cdot \\frac{\\ell}{L}\n",
    "\\]\n",
    "- \\(d\\): maksimum drop rate (örn. 0.1–0.3)\n",
    "- \\(\\ell\\): katman indeksi\n",
    "- \\(L\\): toplam katman sayısı\n",
    "\n",
    "Yani “en derindeki bloklar daha sık kapanır”.\n",
    "\n",
    "> Bu mantık DropBlock’daki “schedule” ile benzer: eğitim/derinlik arttıkça düzenlileştirme artar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e8103d",
   "metadata": {},
   "source": [
    "\\\n",
    "## 6) Nereye uygulanır?\n",
    "\n",
    "### Temel kural\n",
    "DropPath, **residual toplamından önce** residual branch çıktısına uygulanır.\n",
    "\n",
    "\\[\n",
    "y = x + \\mathrm{DropPath}(F(x))\n",
    "\\]\n",
    "\n",
    "- `Conv → BN → Act → ... → F(x)` üret\n",
    "- `F(x)` üstüne DropPath uygula\n",
    "- `+ x` ile topla\n",
    "\n",
    "**Not:** Pre-activation ResNet'te de aynı mantık geçerlidir: DropPath residual branch çıkışında, toplama öncesinde durur.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30e2786",
   "metadata": {},
   "source": [
    "\\\n",
    "## 7) Beklenen davranış\n",
    "\n",
    "- Train loss genelde biraz daha yüksek çıkar (regularization)\n",
    "- Test acc daha stabil olabilir\n",
    "- Çok yüksek drop rate seçilirse underfit görülebilir\n",
    "\n",
    "Tipik aralıklar:\n",
    "- CIFAR küçük modeller: \\(d \\approx 0.05\\)–\\(0.15\\)\n",
    "- ImageNet büyük modeller: \\(d \\approx 0.1\\)–\\(0.3\\)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f153a65f",
   "metadata": {},
   "source": [
    "\\\n",
    "## 8) Kısa özet\n",
    "\n",
    "- DropPath = “residual/path seviyesinde dropout”\n",
    "- Ana formül: \\(x + \\frac{m}{p}F(x)\\)\n",
    "- Testte kapalı, eğitimde açık\n",
    "- Derine gidildikçe drop rate artırmak yaygın\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b54b986",
   "metadata": {},
   "source": [
    "## Minimal Kod: DropPath Modülü (PyTorch)\n",
    "Aşağıdaki implementasyon, residual branch çıktısına uygulanacak şekilde tasarlanmıştır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43a0572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DropPath(nn.Module):\n",
    "    \"\"\"DropPath (Stochastic Depth) - path-level dropout.\n",
    "    Eğitimde: x * mask / keep_prob\n",
    "    Testte: x (değişmeden)\n",
    "    \"\"\"\n",
    "    def __init__(self, drop_prob: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.drop_prob = float(drop_prob)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if self.drop_prob == 0.0 or (not self.training):\n",
    "            return x\n",
    "\n",
    "        keep_prob = 1.0 - self.drop_prob\n",
    "        shape = (x.shape[0],) + (1,) * (x.ndim - 1)  # batch-wise mask\n",
    "        mask = torch.empty(shape, device=x.device, dtype=x.dtype).bernoulli_(keep_prob)\n",
    "        return x * mask / keep_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd321597",
   "metadata": {},
   "source": [
    "## Minimal Kullanım: Residual Blok İçinde\n",
    "DropPath, residual branch'in çıktısına uygulanır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cedb589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64, 32, 32])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicResBlock(nn.Module):\n",
    "    def __init__(self, cin, cout, stride=1, drop_path=0.0):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(cin, cout, 3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(cout)\n",
    "        self.act = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(cout, cout, 3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(cout)\n",
    "\n",
    "        self.dp = DropPath(drop_path)\n",
    "\n",
    "        self.skip = nn.Identity()\n",
    "        if stride != 1 or cin != cout:\n",
    "            self.skip = nn.Sequential(\n",
    "                nn.Conv2d(cin, cout, 1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(cout),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.skip(x)\n",
    "        out = self.act(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = self.dp(out)          # <-- DropPath burada\n",
    "        out = self.act(out + identity)\n",
    "        return out\n",
    "\n",
    "# quick check\n",
    "x = torch.randn(4, 64, 32, 32)\n",
    "blk = BasicResBlock(64, 64, drop_path=0.1).train()\n",
    "y = blk(x)\n",
    "y.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fe266a",
   "metadata": {},
   "source": [
    "## Basit DropPath Schedule (Derinliğe Göre)\n",
    "Lineer artış örneği: en sonda maksimum drop rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10094796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.04000000000000001, 0.08000000000000002, 0.12, 0.16000000000000003, 0.2]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def droppath_rate_at(layer_idx: int, num_layers: int, max_drop: float) -> float:\n",
    "    if num_layers <= 1:\n",
    "        return 0.0\n",
    "    return max_drop * (layer_idx / (num_layers - 1))\n",
    "\n",
    "rates = [droppath_rate_at(i, 6, 0.2) for i in range(6)]\n",
    "rates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e681e9",
   "metadata": {},
   "source": [
    "## Pratik Notlar\n",
    "\n",
    "- DropPath'i en baştaki katmanlara yüksek vermek genelde stabil değildir; derine doğru artırmak daha iyi çalışır.\n",
    "- DropPath “spatial bilgi silmez”; bir branch’i tamamen kapatır. Bu yüzden DropBlock/Cutout gibi yöntemlerden farklı davranır.\n",
    "- Çok yüksek drop rate seçilirse model \"aktif derinlik\" olarak fazla sığ kalır → underfit.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
