{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c3f7b61",
   "metadata": {},
   "source": [
    "# Coordinate Attention Güçlendirme Eklentileri \n",
    "Bu notebook, **mevcut CoordAtt koduna** ekleyebileceğin parçaları verir. Matematik yok; her ek için:\n",
    "- **Ne eklenir (kod)**\n",
    "- **Ne işe yarar (amaç)**\n",
    "- **Model neden güçlenir (etki)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41a9623",
   "metadata": {},
   "source": [
    "## 0) Başlangıç: Referans CoordAtt (temel)\n",
    "Aşağıdaki sınıf, eklentilerin üzerine oturtulacağı **temel** sürümdür. Eklentiler bu yapıyı bozmadan güçlendirmeyi hedefler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe57974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class HSwish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * F.relu6(x + 3.0, inplace=True) / 6.0\n",
    "\n",
    "class CoordinateAtt(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        reduction: int = 32,\n",
    "        min_mid_channels: int = 8,\n",
    "        act: str = \"hswish\",\n",
    "        alpha: float = 1.0,\n",
    "        learnable_alpha: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        mid_channels = max(min_mid_channels, in_channels // reduction)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, mid_channels, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(mid_channels)\n",
    "\n",
    "        if act.lower() == \"hswish\":\n",
    "            self.act = HSwish()\n",
    "        elif act.lower() == \"relu\":\n",
    "            self.act = nn.ReLU(inplace=True)\n",
    "        else:\n",
    "            raise ValueError(\"act must be 'hswish' or 'relu'\")\n",
    "\n",
    "        self.conv_h = nn.Conv2d(mid_channels, in_channels, kernel_size=1, bias=True)\n",
    "        self.conv_w = nn.Conv2d(mid_channels, in_channels, kernel_size=1, bias=True)\n",
    "\n",
    "        if learnable_alpha:\n",
    "            self.alpha = nn.Parameter(torch.tensor(float(alpha)))\n",
    "        else:\n",
    "            self.register_buffer(\"alpha\", torch.tensor(float(alpha)))\n",
    "\n",
    "        self._last_ah = None\n",
    "        self._last_aw = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "\n",
    "        x_h = x.mean(dim=3, keepdim=True)                    # (B,C,H,1)\n",
    "        x_w = x.mean(dim=2, keepdim=True).permute(0,1,3,2)   # (B,C,W,1)\n",
    "\n",
    "        y = torch.cat([x_h, x_w], dim=2)                     # (B,C,H+W,1)\n",
    "        y = self.act(self.bn1(self.conv1(y)))                # (B,mid,H+W,1)\n",
    "\n",
    "        y_h, y_w = torch.split(y, [H, W], dim=2)             # (B,mid,H,1) & (B,mid,W,1)\n",
    "        y_w = y_w.permute(0,1,3,2)                           # (B,mid,1,W)\n",
    "\n",
    "        a_h = torch.sigmoid(self.conv_h(y_h))                # (B,C,H,1)\n",
    "        a_w = torch.sigmoid(self.conv_w(y_w))                # (B,C,1,W)\n",
    "\n",
    "        self._last_ah = a_h\n",
    "        self._last_aw = a_w\n",
    "\n",
    "        att = a_h * a_w                                      # (B,C,H,W)\n",
    "        scale = (1.0 - self.alpha) + self.alpha * att\n",
    "\n",
    "        return x * scale\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def last_mask_stats(self):\n",
    "        if self._last_ah is None or self._last_aw is None:\n",
    "            return None\n",
    "        ah = self._last_ah\n",
    "        aw = self._last_aw\n",
    "        return {\n",
    "            \"a_h\": {\"min\": float(ah.min()), \"mean\": float(ah.mean()), \"max\": float(ah.max()), \"std\": float(ah.std())},\n",
    "            \"a_w\": {\"min\": float(aw.min()), \"mean\": float(aw.mean()), \"max\": float(aw.max()), \"std\": float(aw.std())},\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62631931",
   "metadata": {},
   "source": [
    "## 1) Multi-Scale Axis Pooling (Mean + Max)\n",
    "**Amaç:** Sadece ortalama almak bazen ayrıntıyı düzleştirir. Mean+Max ile eksen özetleri daha zengin olur.\n",
    "**Model neden güçlenir:** Maskeler daha ayırt edici çıkar; zayıf ama önemli aktivasyonlar kaybolmaz.\n",
    "\n",
    "**Ne eklenir:** forward içinde `x_h` ve `x_w` hesaplarını aşağıdaki gibi değiştir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16d8d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eski:\n",
    "# x_h = x.mean(dim=3, keepdim=True)\n",
    "# x_w = x.mean(dim=2, keepdim=True).permute(0,1,3,2)\n",
    "\n",
    "# Yeni (Mean + Max):\n",
    "x_h_mean = x.mean(dim=3, keepdim=True)\n",
    "x_h_max  = x.amax(dim=3, keepdim=True)\n",
    "x_h = 0.5 * (x_h_mean + x_h_max)                           # (B,C,H,1)\n",
    "\n",
    "x_w_mean = x.mean(dim=2, keepdim=True)\n",
    "x_w_max  = x.amax(dim=2, keepdim=True)\n",
    "x_w = 0.5 * (x_w_mean + x_w_max)                           # (B,C,1,W)\n",
    "x_w = x_w.permute(0, 1, 3, 2)                              # (B,C,W,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c762b9",
   "metadata": {},
   "source": [
    "## 2) Axis-wise Depthwise Conv (Lokal eksen bilgisi)\n",
    "**Amaç:** Eksen özetleri sadece global istatistik olmasın; eksen boyunca lokal süreklilik de görülsün.\n",
    "**Model neden güçlenir:** İnce konum farkları daha iyi yakalanır; maskeler daha stabil olur.\n",
    "\n",
    "**Ne eklenir:** `__init__` içine iki depthwise katman, `forward` içinde x_h/x_w üzerine uygula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c20a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# __init__ içine ekle:\n",
    "self.dw_h = nn.Conv2d(in_channels, in_channels, kernel_size=(3,1), padding=(1,0), groups=in_channels, bias=False)\n",
    "self.dw_w = nn.Conv2d(in_channels, in_channels, kernel_size=(1,3), padding=(0,1), groups=in_channels, bias=False)\n",
    "\n",
    "# forward içinde (x_h ve x_w hesaplandıktan sonra):\n",
    "x_h = self.dw_h(x_h)                      # (B,C,H,1)\n",
    "\n",
    "x_w_1w = x_w.permute(0,1,3,2)             # (B,C,1,W)\n",
    "x_w_1w = self.dw_w(x_w_1w)                # (B,C,1,W)\n",
    "x_w = x_w_1w.permute(0,1,3,2)             # (B,C,W,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73887c11",
   "metadata": {},
   "source": [
    "## 3) Dilated Axis Conv (Daha geniş bağlam)\n",
    "**Amaç:** Eksen boyunca daha uzak ilişkileri de kapsamak.\n",
    "**Model neden güçlenir:** Büyük objelerde/uzun yapılarlarda daha tutarlı attention çıkar.\n",
    "\n",
    "**Ne eklenir:** 2) maddesindeki depthwise conv’ları dilated yap (yalnızca parametrelerle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a0ee7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# __init__ içinde (örnek: dilation=2):\n",
    "d = 2\n",
    "self.dw_h = nn.Conv2d(in_channels, in_channels, kernel_size=(3,1), padding=(d,0), dilation=(d,1),\n",
    "                      groups=in_channels, bias=False)\n",
    "self.dw_w = nn.Conv2d(in_channels, in_channels, kernel_size=(1,3), padding=(0,d), dilation=(1,d),\n",
    "                      groups=in_channels, bias=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cd3326",
   "metadata": {},
   "source": [
    "## 4) Eksen Bazlı Alpha (alpha_h, alpha_w)\n",
    "**Amaç:** Dikey ve yatay maskelerin etkisini ayrı kontrol etmek.\n",
    "**Model neden güçlenir:** Stabilite artar; bir eksen hatalıysa diğerini daha az etkiler.\n",
    "\n",
    "**Ne eklenir:** tek `alpha` yerine iki alpha. `scale` hesaplaması değişir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17c0cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# __init__ içinde tek alpha yerine:\n",
    "if learnable_alpha:\n",
    "    self.alpha_h = nn.Parameter(torch.tensor(float(alpha)))\n",
    "    self.alpha_w = nn.Parameter(torch.tensor(float(alpha)))\n",
    "else:\n",
    "    self.register_buffer(\"alpha_h\", torch.tensor(float(alpha)))\n",
    "    self.register_buffer(\"alpha_w\", torch.tensor(float(alpha)))\n",
    "\n",
    "# forward sonunda:\n",
    "scale_h = (1.0 - self.alpha_h) + self.alpha_h * a_h         # (B,C,H,1)\n",
    "scale_w = (1.0 - self.alpha_w) + self.alpha_w * a_w         # (B,C,1,W)\n",
    "scale = scale_h * scale_w                                   # (B,C,H,W)\n",
    "return x * scale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c306f54",
   "metadata": {},
   "source": [
    "## 5) Sigmoid yerine Hard-Sigmoid (Daha stabil kapı)\n",
    "**Amaç:** Maskeler çok erken 0/1’e yapışmasın.\n",
    "**Model neden güçlenir:** Grad akışı daha stabil olur; maskeler ‘ölmez’.\n",
    "\n",
    "**Ne eklenir:** `torch.sigmoid` yerine `F.hardsigmoid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3af9549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eski:\n",
    "# a_h = torch.sigmoid(self.conv_h(y_h))\n",
    "# a_w = torch.sigmoid(self.conv_w(y_w))\n",
    "\n",
    "# Yeni:\n",
    "a_h = F.hardsigmoid(self.conv_h(y_h), inplace=True)\n",
    "a_w = F.hardsigmoid(self.conv_w(y_w), inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda10bea",
   "metadata": {},
   "source": [
    "## 6) Attention Residual (Maske kapatmasın)\n",
    "**Amaç:** Maskeler 0’a yaklaşınca sinyalin tamamen kapanmasını engellemek.\n",
    "**Model neden güçlenir:** Over-suppression azalır; özellikle derin ağlarda daha güvenli.\n",
    "\n",
    "**Ne eklenir:** `att` üzerine küçük residual form (isteğe bağlı beta)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdbf52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# __init__ içine (isteğe bağlı):\n",
    "self.beta = 0.5  # 0.2–1.0 aralığında denenebilir (learnable da yapılabilir)\n",
    "\n",
    "# forward sonunda:\n",
    "att = a_h * a_w\n",
    "att = 1.0 + self.beta * (att - 1.0)\n",
    "scale = (1.0 - self.alpha) + self.alpha * att\n",
    "return x * scale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824e8596",
   "metadata": {},
   "source": [
    "## 7) Mid Katmanını Güçlendirme (2 katmanlı bottleneck)\n",
    "**Amaç:** Ortak latent uzayın ifade gücünü artırmak.\n",
    "**Model neden güçlenir:** Maskeler daha ‘anlamlı’ çıkar; çok az ek maliyetle kapasite artar.\n",
    "\n",
    "**Ne eklenir:** `conv1` tek katman yerine iki 1×1 katman (mid içinde)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8450d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# __init__ içinde:\n",
    "self.conv1a = nn.Conv2d(in_channels, mid_channels, kernel_size=1, bias=False)\n",
    "self.bn1a   = nn.BatchNorm2d(mid_channels)\n",
    "self.conv1b = nn.Conv2d(mid_channels, mid_channels, kernel_size=1, bias=False)\n",
    "self.bn1b   = nn.BatchNorm2d(mid_channels)\n",
    "\n",
    "# forward içinde:\n",
    "y = self.act(self.bn1a(self.conv1a(y)))\n",
    "y = self.act(self.bn1b(self.conv1b(y)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932d6ed8",
   "metadata": {},
   "source": [
    "## 8) Head’leri Hafifletme (Grouped 1×1)\n",
    "**Amaç:** Parametre ve hesap maliyetini düşürmek.\n",
    "**Model neden güçlenir:** Aynı bütçede daha büyük backbone mümkün olur (pratik kazanç).\n",
    "\n",
    "**Ne eklenir:** `conv_h/conv_w` için groups>1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22affa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# __init__ içinde (in_channels % g == 0 olmalı):\n",
    "g = 4\n",
    "self.conv_h = nn.Conv2d(mid_channels, in_channels, kernel_size=1, groups=g, bias=True)\n",
    "self.conv_w = nn.Conv2d(mid_channels, in_channels, kernel_size=1, groups=g, bias=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773e58d6",
   "metadata": {},
   "source": [
    "## 9) Mini Spatial Gate (Çok hafif 2D düzeltme)\n",
    "**Amaç:** CoordAtt eksensel çalışır; bazen küçük bir 2D düzeltme faydalıdır.\n",
    "**Model neden güçlenir:** İnce 2D konum hassasiyeti artar; CBAM-SA kadar ağır olmadan kazanım sağlar.\n",
    "\n",
    "**Ne eklenir:** CoordAtt çıkışı sonrası küçük depthwise 3×3 gate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a580a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# __init__ içine:\n",
    "self.spatial_dw = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1, groups=in_channels, bias=False)\n",
    "self.spatial_pw = nn.Conv2d(in_channels, in_channels, kernel_size=1, bias=True)\n",
    "\n",
    "# forward sonunda (return’dan önce):\n",
    "out = x * scale\n",
    "gate = torch.sigmoid(self.spatial_pw(self.spatial_dw(out)))\n",
    "return out * gate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b73fbb",
   "metadata": {},
   "source": [
    "## 10) Debug: Maske çökmesi var mı?\n",
    "**Amaç:** Maske dağılımı aşırı daralıyor mu (std çok küçük) veya saturasyon var mı görmek.\n",
    "**Model neden güçlenir:** Hızlı teşhis → doğru eklentiyi seçersin (örn. hard-sigmoid, alpha düşürme).\n",
    "\n",
    "**Ne eklenir:** Hızlı kontrol fonksiyonu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824d0c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def quick_mask_check(att_module, x):\n",
    "    att_module.eval()\n",
    "    _ = att_module(x)\n",
    "    stats = att_module.last_mask_stats() if hasattr(att_module, \"last_mask_stats\") else None\n",
    "    print(stats)\n",
    "    if stats is not None:\n",
    "        if stats[\"a_h\"][\"std\"] < 0.02 or stats[\"a_w\"][\"std\"] < 0.02:\n",
    "            print(\"UYARI: maske std çok düşük -> maske sabitleniyor olabilir.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
