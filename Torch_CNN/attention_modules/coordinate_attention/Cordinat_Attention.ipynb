{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b24992fb",
   "metadata": {},
   "source": [
    "# Coordinate Attention (Koordinat Dikkati) — Anlatım Notları\n",
    "\n",
    "Bu notlar **Coordinate Attention (CA / CoordAtt)** mekanizmasını; **neden ortaya çıktığını**, **hangi problemi çözdüğünü**, **nasıl çalıştığını** ve **nerede daha verimli kullanıldığını** anlaşılır ama teknik doğrulukla özetler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b866434",
   "metadata": {},
   "source": [
    "## 1) Coordinate Attention nedir?\n",
    "\n",
    "**Coordinate Attention**, bir CNN ara-özellik haritası üzerinde **kanal (channel) ağırlıklandırmasını** yaparken aynı zamanda **konumsal (spatial) bilgiyi** korumayı hedefleyen bir dikkat (attention) bloğudur.\n",
    "\n",
    "Klasik channel attention yaklaşımlarında (ör. SE/ECA gibi) özellik haritası genellikle **Global Average Pooling** ile tek bir vektöre indirgenir. Bu indirgeme, **\"hangi kanal önemli?\"** sorusunu cevaplar; ancak **\"nerede önemli?\"** bilgisi büyük ölçüde kaybolur.\n",
    "\n",
    "Coordinate Attention’ın temel fikri:\n",
    "\n",
    "- Uzamsal bilgiyi tamamen silen tek bir global havuzlama yerine,\n",
    "- **Yükseklik (H) ve genişlik (W) eksenlerini ayrı ayrı** encode ederek,\n",
    "- Kanal ağırlıklandırmasına **konum duyarlılığı (positional awareness)** kazandırmak."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cbc4d0",
   "metadata": {},
   "source": [
    "## 2) Neden ortaya çıktı? (Motivasyon)\n",
    "\n",
    "CNN tabanlı birçok modelde **attention** blokları performansı artırır; fakat iki sık görülen problem vardır:\n",
    "\n",
    "1. **Global pooling kaynaklı konum kaybı**\n",
    "   - SE (Squeeze-and-Excitation) gibi yapılar **H×W uzamını tek bir sayıya** indirger.\n",
    "   - Bu, sınıflandırmada işe yarar; ancak **detection/segmentation** gibi görevlerde konum bilgisi kritik olduğundan, kazanç sınırlı kalabilir.\n",
    "\n",
    "2. **2D spatial attention'ın maliyeti**\n",
    "   - CBAM’in Spatial Attention kısmı gibi 2D maske üretimi (ör. 7×7 conv) bazı senaryolarda ek maliyet getirir.\n",
    "   - Mobil/edge hedeflerde veya düşük gecikme istenen sistemlerde bu maliyet istenmeyebilir.\n",
    "\n",
    "Coordinate Attention bu iki sorunu **dengeleyerek** çözmeyi hedefler:\n",
    "- Konum bilgisini korur (global pooling gibi tamamen silmez).\n",
    "- 2D maske üretmek yerine **1D eksen bazlı** temsillerle çalışarak maliyeti düşürür."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab09e80",
   "metadata": {},
   "source": [
    "## 3) Hangi problemi çözer? (Çekirdek fikir)\n",
    "\n",
    "Girdi özellik haritası:\n",
    "\n",
    "\\$\n",
    "\\mathbf{X} \\in \\mathbb{R}^{B \\times C \\times H \\times W}\n",
    "\\$\n",
    "\n",
    "Amaç, her konumda (h, w) için kanalları yeniden ölçeklemek:\n",
    "\n",
    "\\$\n",
    "\\mathbf{Y}_{c,h,w} = \\mathbf{X}_{c,h,w} \\cdot \\alpha_{c,h} \\cdot \\beta_{c,w}\n",
    "\\$\n",
    "\n",
    "Burada:\n",
    "- \\(\\alpha\\): **yükseklik yönü** boyunca öğrenilen dikkat katsayıları (H ekseni)\n",
    "- \\(\\beta\\): **genişlik yönü** boyunca öğrenilen dikkat katsayıları (W ekseni)\n",
    "\n",
    "Bu çarpım, kanalı sadece \"genel\" biçimde değil, **eksene bağlı olarak** modüle eder. Yani CA, kanal dikkatini **konum ile bağlar**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6da248",
   "metadata": {},
   "source": [
    "## 4) Nasıl çalışır? (Adım adım)\n",
    "\n",
    "### 4.1) Eksen bazlı havuzlama (Coordinate Information Embedding)\n",
    "\n",
    "SE’deki gibi tek bir global pooling yerine iki ayrı pooling yapılır:\n",
    "\n",
    "- **Yükseklik yönünde havuzlama** (W boyunca ortalama):\n",
    "\n",
    "\\$\n",
    "\\mathbf{z}^{h}_{c}(h) = \\frac{1}{W}\\sum_{w=1}^{W} \\mathbf{X}_{c,h,w}\n",
    "\\$\n",
    "Sonuç boyutu: \\(\\mathbf{z}^h \\in \\mathbb{R}^{B \\times C \\times H \\times 1}\\)\n",
    "\n",
    "- **Genişlik yönünde havuzlama** (H boyunca ortalama):\n",
    "\n",
    "\\$\n",
    "\\mathbf{z}^{w}_{c}(w) = \\frac{1}{H}\\sum_{h=1}^{H} \\mathbf{X}_{c,h,w}\n",
    "\\$\n",
    "Sonuç boyutu: \\(\\mathbf{z}^w \\in \\mathbb{R}^{B \\times C \\times 1 \\times W}\\)\n",
    "\n",
    "Bu iki özet, uzamsal yapıyı tamamen yok etmez:\n",
    "- \\(\\mathbf{z}^h\\) yüksekliğe göre değişir\n",
    "- \\(\\mathbf{z}^w\\) genişliğe göre değişir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb396bd",
   "metadata": {},
   "source": [
    "### 4.2) Paylaşımlı dönüşüm (Shared Transform)\n",
    "\n",
    "Amaç: iki eksenden gelen bilgiyi **ortak bir gömleme uzayında** birleştirip kanallar arası ilişkiyi öğrenmek.\n",
    "\n",
    "Genelde şu akış kullanılır:\n",
    "1. \\(\\mathbf{z}^h\\) ve \\(\\mathbf{z}^w\\) uygun şekilde birleştirilir (concat).\n",
    "2. Kanal sıkıştırma için \\(1\\times1\\) konvolüsyon uygulanır:\n",
    "\\$\n",
    "\\mathbf{f} = \\delta(\\mathrm{BN}(\\mathrm{Conv}_{1\\times1}([\\mathbf{z}^h; \\mathbf{z}^w])))\n",
    "\\$\n",
    "- \\(\\delta\\): genelde **h-swish** (mobil uyumlu aktivasyon)\n",
    "- Ara kanal sayısı çoğunlukla \\(C/r\\) (r: reduction oranı)\n",
    "\n",
    "Bu aşama, SE’deki MLP benzeri yapının konvolüsyonla ve eksen temsilleriyle yapılmış halidir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957baf04",
   "metadata": {},
   "source": [
    "### 4.3) Dikkat haritalarının ayrıştırılması\n",
    "\n",
    "Paylaşımlı \\(\\mathbf{f}\\) tekrar iki kola ayrılır ve iki ayrı \\(1\\times1\\) conv ile attention üretilir:\n",
    "\n",
    "\\$\n",
    "\\alpha = \\sigma(\\mathrm{Conv}_{1\\times1}^{h}(\\mathbf{f}^{h})) \\in \\mathbb{R}^{B \\times C \\times H \\times 1}\n",
    "\\$\n",
    "\n",
    "\\$\n",
    "\\beta  = \\sigma(\\mathrm{Conv}_{1\\times1}^{w}(\\mathbf{f}^{w})) \\in \\mathbb{R}^{B \\times C \\times 1 \\times W}\n",
    "\\$\n",
    "\n",
    "- \\(\\sigma\\): sigmoid\n",
    "\n",
    "Son olarak çıktı:\n",
    "\\$\n",
    "\\mathbf{Y} = \\mathbf{X} \\odot \\alpha \\odot \\beta\n",
    "\\$\n",
    "\n",
    "Bu yapı, **2D spatial attention** üretmeden, iki eksen üzerinden “nerede önemli?” bilgisini taşır."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f91de6",
   "metadata": {},
   "source": [
    "## 5) Neden iyi çalışır? (Sezgisel açıklama)\n",
    "\n",
    "- **SE**: Kanalı global ölçekte ağırlıklandırır. Konum kaybolur.\n",
    "- **CBAM-SA**: 2D maske ile “nerede”yi bulur ama kanal-uzay etkileşimi daha dolaylıdır ve ek maliyet getirir.\n",
    "- **Coordinate Attention**:\n",
    "  - Kanal önemini hesaplarken konumu tamamen yok etmez.\n",
    "  - “Bu kanal **yükseklikte** nerede, **genişlikte** nerede daha aktif?” bilgisini taşır.\n",
    "  - Özellikle yönsel/şerit benzeri yapılar (yol, kenar, yazı, insan silüeti gibi) için güçlü sinyal verir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15da4567",
   "metadata": {},
   "source": [
    "## 6) Hangi hedeflerde daha rahat kullanılır?\n",
    "\n",
    "### 6.1) En çok fayda görülen görevler\n",
    "- **Object Detection**: Kutuların yerini ve küçük objeleri yakalamada konum duyarlılığı değerlidir.\n",
    "- **Segmentation**: Piksel seviyesinde kararlar konuma bağlıdır; CA bu bağlamda güçlüdür.\n",
    "- **ReID / Fine-grained recognition**: İnsan/ürün gibi nesnelerde ayırt edici bölgeler yönsel dağılım gösterebilir.\n",
    "\n",
    "### 6.2) Sınıflandırma (Classification)\n",
    "- Sınıflandırmada da fayda sağlar, fakat bazen SE/ECA zaten yeterli olur.\n",
    "- CA’nın avantajı, sınıflandırmada özellikle **arka plan karmaşası** ve **lokal ayırt edici bölgeler** (ör. kuş başı, araç farı) gibi durumlarda artar.\n",
    "\n",
    "### 6.3) Mobil / düşük gecikme hedefleri\n",
    "- CA tasarım olarak mobil dostudur (h-swish, 1×1 conv ağırlıklı).\n",
    "- 2D spatial attention’a göre genellikle daha hafif bir alternatif sunar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedf2d90",
   "metadata": {},
   "source": [
    "## 7) Parametre ve maliyet sezgisi\n",
    "\n",
    "Bir CA bloğunda parametrelerin büyük kısmı **1×1 konvolüsyonlardan** gelir.\n",
    "\n",
    "- Girdi kanal sayısı: \\(C\\)\n",
    "- Reduction: \\(r\\) (ör. 16, 32)\n",
    "\n",
    "Yaklaşık parametre ölçeği:\n",
    "- Shared 1×1 conv: \\(C \\times (C/r)\\)\n",
    "- İki ayrı 1×1 conv: \\((C/r)\\times C\\) + \\((C/r)\\times C\\)\n",
    "\n",
    "Toplam kabaca:\n",
    "\\$\n",
    "\\mathcal{O}\\left(\\frac{2C^2}{r}\\right)\n",
    "\\$\n",
    "\n",
    "Bu, 2D büyük kernel’li spatial attention (ör. 7×7 conv) ile kıyaslandığında genellikle daha kontrollü bir maliyet profili verir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ea29b6",
   "metadata": {},
   "source": [
    "## 8) Pratik tasarım notları (uygulamada dikkat edilmesi gerekenler)\n",
    "\n",
    "1. **Reduction (r) seçimi**\n",
    "   - Çok küçük r (ör. 4): daha güçlü kapasite ama daha fazla maliyet\n",
    "   - Çok büyük r (ör. 64): kapasite düşer, kazanç azalabilir\n",
    "   - Mobilde genellikle 16/32 gibi değerler dengelidir.\n",
    "\n",
    "2. **Aktivasyon**\n",
    "   - CA literatürde sıkça **h-swish** kullanır; mobil mimarilerle uyumludur.\n",
    "   - ReLU da kullanılabilir; ancak mobil hedefte h-swish tercih edilir.\n",
    "\n",
    "3. **Yerleşim (block içinde nereye konur?)**\n",
    "   - Bottleneck bloklarının sonunda veya residual eklemeden önce/sonra denenebilir.\n",
    "   - Çok agresif bastırma oluyorsa (özellik std aşırı düşüyorsa), CA çıktısını residual ile dengelemek veya ölçekleme katsayısı eklemek iyi olabilir.\n",
    "\n",
    "4. **CBAM ile birlikte kullanım**\n",
    "   - CA zaten konum duyarlılığı getirdiği için, CBAM’in SA kısmını ağır tutmak çoğu zaman gereksizdir.\n",
    "   - Daha sağlıklı hibrit: **CBAM-CA + CoordAtt** veya **CoordAtt + mikro SA (depthwise 3×3)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638d0df1",
   "metadata": {},
   "source": [
    "## 9) Coordinate Attention ile Coordinate Convolution aynı şey değil (kısa not)\n",
    "\n",
    "Sıklıkla isim benzerliği karışır:\n",
    "\n",
    "- **Coordinate Attention (CoordAtt)**: Attention bloğu. Amaç: feature’ları yeniden ağırlıklandırmak.\n",
    "- **Coordinate Convolution (CoordConv)**: Konvolüsyon girişine koordinat kanalları (x, y, r gibi) ekleyerek modelin konumsal fonksiyonları daha kolay öğrenmesini sağlamak.\n",
    "\n",
    "İkisi birlikte de kullanılabilir; ancak kavramsal olarak farklı bileşenlerdir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd2027d",
   "metadata": {},
   "source": [
    "## 10) Kod tarafı (çok kısa): PyTorch iskeleti\n",
    "\n",
    "Aşağıdaki kod, mekanizmanın ana fikrini göstermek için minimal bir iskelettir. Projede kullanılacak üretim kodu; hata kontrolleri, cihaz/dtype uyumu ve optimizasyonlarla genişletilebilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40854f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class HSwish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * F.relu6(x + 3.0, inplace=True) / 6.0\n",
    "\n",
    "class CoordAtt(nn.Module):\n",
    "    def __init__(self, in_channels: int, reduction: int = 32):\n",
    "        super().__init__()\n",
    "        mid = max(8, in_channels // reduction)  # pratikte alt sınır konur\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, mid, kernel_size=1, bias=False)\n",
    "        self.bn1   = nn.BatchNorm2d(mid)\n",
    "        self.act   = HSwish()\n",
    "\n",
    "        self.conv_h = nn.Conv2d(mid, in_channels, kernel_size=1, bias=True)\n",
    "        self.conv_w = nn.Conv2d(mid, in_channels, kernel_size=1, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "\n",
    "        # Height pooling: W boyunca ortalama -> (B, C, H, 1)\n",
    "        x_h = x.mean(dim=3, keepdim=True)\n",
    "\n",
    "        # Width pooling: H boyunca ortalama -> (B, C, 1, W)\n",
    "        x_w = x.mean(dim=2, keepdim=True)\n",
    "        x_w = x_w.permute(0, 1, 3, 2)  # (B, C, W, 1) gibi düşünmek için\n",
    "\n",
    "        # Birleştir (H + W eksen bilgisi)\n",
    "        y = torch.cat([x_h, x_w], dim=2)  # (B, C, H+W, 1)\n",
    "\n",
    "        y = self.act(self.bn1(self.conv1(y)))\n",
    "\n",
    "        # Tekrar ayır\n",
    "        y_h, y_w = torch.split(y, [h, w], dim=2)\n",
    "\n",
    "        y_w = y_w.permute(0, 1, 3, 2)  # (B, mid, 1, W)\n",
    "\n",
    "        a_h = torch.sigmoid(self.conv_h(y_h))  # (B, C, H, 1)\n",
    "        a_w = torch.sigmoid(self.conv_w(y_w))  # (B, C, 1, W)\n",
    "\n",
    "        out = x * a_h * a_w\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd11444",
   "metadata": {},
   "source": [
    "## 11) Kısa özet (akılda kalacak şekilde)\n",
    "\n",
    "- **Coordinate Attention**, channel attention’a **konum duyarlılığı** katar.\n",
    "- Bunu 2D spatial maskeyle değil; **H ve W eksenlerini ayrı encode ederek** yapar.\n",
    "- **Detection/Segmentation** gibi konum hassas görevlerde genellikle daha belirgin kazanım sağlar.\n",
    "- Mobil/düşük gecikme hedeflerde, klasik 2D spatial attention’a göre daha dengeli bir alternatiftir."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
