{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "401e4ba1",
   "metadata": {},
   "source": [
    "# 1) En temel ECA bloğu (sabit k ile)\n",
    "\n",
    "* Önce adaptif k falan yok. Mantığı net görmek için k=3 ile başlıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2198d05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ECABlock(nn.Module):\n",
    "    def __init__(self, channels: int, k: int = 3):\n",
    "        super().__init__()\n",
    "        if k % 2 == 0:\n",
    "            k += 1\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.conv1d = nn.Conv1d(1, 1, kernel_size=k, padding=(k - 1)//2, bias=False)\n",
    "        self.gate = nn.Sigmoid()\n",
    "\n",
    "# padding=(k-1)//2 seçimi:\n",
    "\n",
    "# çıktı uzunluğu girişle aynı kalsın diye\n",
    "\n",
    "# same padding uygulamak için\n",
    "\n",
    "# ve odd kernel ile simetrik komşuluk sağlamak için\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        s = self.pool(x).squeeze(-1).squeeze(-1)   # (B,C)\n",
    "        s = s.unsqueeze(1)                         # (B,1,C)\n",
    "        a = self.conv1d(s)                         # (B,1,C)\n",
    "        w = self.gate(a).squeeze(1).unsqueeze(-1).unsqueeze(-1)  # (B,C,1,1)\n",
    "        return x * w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d31f6c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 64, 56, 56]) torch.Size([2, 64, 56, 56])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 64, 56, 56)\n",
    "eca = ECABlock(64, k=3)\n",
    "y = eca(x)\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08bcf4c",
   "metadata": {},
   "source": [
    "# 2) Adaptif k ekleyelim \n",
    "\n",
    "Şimdi k otomatik seçilsin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37825fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def _make_odd(k: int) -> int:\n",
    "    return k if (k % 2 == 1) else (k + 1)\n",
    "\n",
    "def eca_kernel_size(channels: int, gamma: int = 2, b: int = 1, k_min: int = 1, k_max: int = 15) -> int:\n",
    "    k = int(abs((math.log2(max(1, channels)) / gamma) + b))\n",
    "    k = _make_odd(max(k_min, min(k, k_max)))\n",
    "    return k\n",
    "\n",
    "class ECABlock(nn.Module):\n",
    "    def __init__(self, channels: int, gamma: int = 2, b: int = 1):\n",
    "        super().__init__()\n",
    "        k = eca_kernel_size(channels, gamma=gamma, b=b)\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.conv1d = nn.Conv1d(1, 1, kernel_size=k, padding=(k - 1)//2, bias=False)\n",
    "        self.gate = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        s = self.pool(x).squeeze(-1).squeeze(-1)   # (B,C)\n",
    "        s = s.unsqueeze(1)                         # (B,1,C)\n",
    "        a = self.conv1d(s)                         # (B,1,C)\n",
    "        w = self.gate(a).squeeze(1).unsqueeze(-1).unsqueeze(-1)  # (B,C,1,1)\n",
    "        return x * w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150de102",
   "metadata": {},
   "source": [
    "# 3) ECA’yı bir Conv bloğun içine takalım\n",
    "\n",
    "ECA tek başına “model” değil; blok içinde kullanılır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "339a58e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBNAct(nn.Module):\n",
    "    def __init__(self, cin, cout, k=3, s=1, p=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(cin, cout, k, stride=s, padding=p, bias=False),\n",
    "            nn.BatchNorm2d(cout),\n",
    "            nn.SiLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class ConvECA(nn.Module):\n",
    "    def __init__(self, cin, cout, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv = ConvBNAct(cin, cout, k=3, s=stride, p=1)\n",
    "        self.eca = ECABlock(cout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.eca(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef9e7f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 128, 56, 56])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 64, 56, 56)\n",
    "blk = ConvECA(64, 128, stride=1)\n",
    "y = blk(x)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e8bd1a",
   "metadata": {},
   "source": [
    "# 4) Basit bir ECA’lı classification modeli yazalım"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7714e050",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECANetLite(nn.Module):\n",
    "    def __init__(self, num_classes=10, in_ch=3, base=32):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            ConvBNAct(in_ch, base, k=3, s=2, p=1),\n",
    "            ECABlock(base),\n",
    "        )\n",
    "\n",
    "        self.stage1 = nn.Sequential(\n",
    "            ConvECA(base, base, stride=1),\n",
    "            ConvECA(base, base, stride=1),\n",
    "        )\n",
    "        self.stage2 = nn.Sequential(\n",
    "            ConvECA(base, base*2, stride=2),\n",
    "            ConvECA(base*2, base*2, stride=1),\n",
    "        )\n",
    "        self.stage3 = nn.Sequential(\n",
    "            ConvECA(base*2, base*4, stride=2),\n",
    "            ConvECA(base*4, base*4, stride=1),\n",
    "        )\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(base*4, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.stage1(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.pool(x).flatten(1)\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5fa5868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10])\n"
     ]
    }
   ],
   "source": [
    "m = ECANetLite(num_classes=10, in_ch=3, base=32)\n",
    "x = torch.randn(2, 3, 224, 224)\n",
    "y = m(x)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b75ec1c",
   "metadata": {},
   "source": [
    "# ECA’lı Residual Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b35b3e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10])\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def _make_odd(k: int) -> int:\n",
    "    return k if (k % 2 == 1) else (k + 1)\n",
    "\n",
    "def eca_kernel_size(channels: int, gamma: int = 2, b: int = 1, k_min: int = 1, k_max: int = 15) -> int:\n",
    "    k = int(abs((math.log2(max(1, channels)) / gamma) + b))\n",
    "    k = _make_odd(max(k_min, min(k, k_max)))\n",
    "    return k\n",
    "\n",
    "class ECABlock(nn.Module):\n",
    "    def __init__(self, channels: int, gamma: int = 2, b: int = 1):\n",
    "        super().__init__()\n",
    "        k = eca_kernel_size(channels, gamma=gamma, b=b)\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.conv1d = nn.Conv1d(1, 1, kernel_size=k, padding=(k - 1)//2, bias=False)\n",
    "        self.gate = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        s = self.pool(x).squeeze(-1).squeeze(-1).unsqueeze(1)\n",
    "        a = self.conv1d(s)\n",
    "        w = self.gate(a).squeeze(1).unsqueeze(-1).unsqueeze(-1)\n",
    "        return x * w\n",
    "\n",
    "class ConvBNAct(nn.Module):\n",
    "    def __init__(self, cin, cout, k=3, s=1, p=1, act=\"silu\"):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(cin, cout, k, stride=s, padding=p, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(cout)\n",
    "        self.act = nn.SiLU(inplace=True) if act == \"silu\" else nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.bn(self.conv(x)))\n",
    "\n",
    "class ECAResBlock(nn.Module):\n",
    "    def __init__(self, cin, cout, stride=1, gamma=2, b=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = ConvBNAct(cin, cout, k=3, s=stride, p=1, act=\"silu\")\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(cout, cout, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(cout),\n",
    "        )\n",
    "        self.eca = ECABlock(cout, gamma=gamma, b=b)\n",
    "        self.out_act = nn.SiLU(inplace=True)\n",
    "\n",
    "        self.short = None\n",
    "        if stride != 1 or cin != cout:\n",
    "            self.short = nn.Sequential(\n",
    "                nn.Conv2d(cin, cout, 1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(cout)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x if self.short is None else self.short(x)\n",
    "        y = self.conv1(x)\n",
    "        y = self.conv2(y)\n",
    "        y = self.eca(y)\n",
    "        y = y + identity\n",
    "        return self.out_act(y)\n",
    "\n",
    "class ECAResNetLite(nn.Module):\n",
    "    def __init__(self, num_classes=10, in_ch=3, base=32, gamma=2, b=1):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            ConvBNAct(in_ch, base, k=3, s=2, p=1),\n",
    "            ConvBNAct(base, base, k=3, s=1, p=1),\n",
    "        )\n",
    "\n",
    "        self.stage1 = nn.Sequential(\n",
    "            ECAResBlock(base, base, stride=1, gamma=gamma, b=b),\n",
    "            ECAResBlock(base, base, stride=1, gamma=gamma, b=b),\n",
    "        )\n",
    "        self.stage2 = nn.Sequential(\n",
    "            ECAResBlock(base, base*2, stride=2, gamma=gamma, b=b),\n",
    "            ECAResBlock(base*2, base*2, stride=1, gamma=gamma, b=b),\n",
    "        )\n",
    "        self.stage3 = nn.Sequential(\n",
    "            ECAResBlock(base*2, base*4, stride=2, gamma=gamma, b=b),\n",
    "            ECAResBlock(base*4, base*4, stride=1, gamma=gamma, b=b),\n",
    "        )\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(base*4, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.stage1(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.pool(x).flatten(1)\n",
    "        return self.fc(x)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    m = ECAResNetLite(num_classes=10, in_ch=3, base=32)\n",
    "    x = torch.randn(2, 3, 224, 224)\n",
    "    y = m(x)\n",
    "    print(y.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
