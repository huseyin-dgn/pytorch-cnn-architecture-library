{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df52fc6a",
   "metadata": {},
   "source": [
    "\n",
    "# ChannelAttentionFusionT â€” **SatÄ±r SatÄ±r, Parametre Parametre Ä°nceleme**\n",
    "Bu notebook, aÅŸaÄŸÄ±daki PyTorch modÃ¼lÃ¼nÃ¼ **en ince ayrÄ±ntÄ±sÄ±na kadar** aÃ§Ä±klamak iÃ§in hazÄ±rlanmÄ±ÅŸtÄ±r.\n",
    "\n",
    "> Hedef: Kodun **her parametresi**, **her satÄ±rÄ±**, hatta â€œkÃ¼Ã§Ã¼kâ€ gÃ¶rÃ¼nen seÃ§imlerin (Ã¶r. `bias`, `eps`, `inplace=True`, `register_buffer`, `softmax dim=0` vb.) **neden var olduÄŸunu** ve **ne etkisi olduÄŸunu** anlamak.\n",
    "\n",
    "---\n",
    "\n",
    "## Ä°ncelenen Kod\n",
    "AÅŸaÄŸÄ±daki kod, CBAM tarzÄ± **Channel Attention** mekanizmasÄ±nÄ±n geliÅŸtirilmiÅŸ bir sÃ¼rÃ¼mÃ¼dÃ¼r:\n",
    "- AvgPool + MaxPool squeeze\n",
    "- Ortak MLP\n",
    "- Avg/Max fusion: `sum` veya **Ã¶ÄŸrenilebilir `softmax`**\n",
    "- Gate: `sigmoid` veya `hardsigmoid`\n",
    "- **Temperature** ile â€œmaskenin keskinliÄŸiâ€ kontrolÃ¼\n",
    "- Ä°steÄŸe baÄŸlÄ± **learnable temperature** (pozitif kalmasÄ± garanti)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a133b088",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ChannelAttentionFusionT(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels: int,\n",
    "        reduction: int = 16,\n",
    "        min_hidden: int = 4,\n",
    "        fusion: str = \"softmax\",        # \"sum\" | \"softmax\"\n",
    "        gate: str = \"sigmoid\",          # \"sigmoid\" | \"hardsigmoid\"\n",
    "        temperature: float = 1.0,\n",
    "        learnable_temperature: bool = False,\n",
    "        eps: float = 1e-6,\n",
    "        act: str = \"relu\",              # \"relu\" | \"silu\"\n",
    "        bias: bool = True,\n",
    "        return_fusion_weights: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if fusion not in (\"sum\", \"softmax\"):\n",
    "            raise ValueError(\"fusion 'sum' veya 'softmax' olmalÄ±.\")\n",
    "        if gate.lower() not in (\"sigmoid\", \"hardsigmoid\"):\n",
    "            raise ValueError(\"gate 'sigmoid' veya 'hardsigmoid' olmalÄ±.\")\n",
    "        if temperature <= 0:\n",
    "            raise ValueError(\"temperature pozitif olmalÄ±.\")\n",
    "        if act not in (\"relu\", \"silu\"):\n",
    "            raise ValueError(\"act 'relu' veya 'silu' olmalÄ±.\")\n",
    "\n",
    "        self.fusion = fusion\n",
    "        self.return_fusion_weights = return_fusion_weights\n",
    "        self.eps = eps\n",
    "\n",
    "        hidden = max(min_hidden, channels // reduction)\n",
    "\n",
    "        self.avg = nn.AdaptiveAvgPool2d(1)\n",
    "        self.mx  = nn.AdaptiveMaxPool2d(1)\n",
    "\n",
    "        self.fc1 = nn.Conv2d(channels, hidden, 1, bias=bias)\n",
    "        self.act = nn.ReLU(inplace=True) if act == \"relu\" else nn.SiLU(inplace=True)\n",
    "        self.fc2 = nn.Conv2d(hidden, channels, 1, bias=bias)\n",
    "\n",
    "        if gate.lower() == \"sigmoid\":\n",
    "            self.gate_fn = torch.sigmoid\n",
    "        else:\n",
    "            self.gate_fn = F.hardsigmoid\n",
    "\n",
    "        if fusion == \"softmax\":\n",
    "            self.fusion_logits = nn.Parameter(torch.zeros(2))\n",
    "        else:\n",
    "            self.fusion_logits = None\n",
    "\n",
    "        self.learnable_temperature = learnable_temperature\n",
    "        if learnable_temperature:\n",
    "            t_raw = torch.tensor(float(temperature))\n",
    "            t_inv = torch.log(torch.exp(t_raw) - 1.0 + eps)\n",
    "            self.t_raw = nn.Parameter(t_inv)\n",
    "        else:\n",
    "            self.register_buffer(\"T\", torch.tensor(float(temperature)))\n",
    "\n",
    "    def _get_T(self) -> torch.Tensor:\n",
    "        if self.learnable_temperature:\n",
    "            return F.softplus(self.t_raw) + self.eps\n",
    "        return self.T\n",
    "\n",
    "    def _mlp(self, s: torch.Tensor) -> torch.Tensor:\n",
    "        return self.fc2(self.act(self.fc1(s)))\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        a = self._mlp(self.avg(x))\n",
    "        m = self._mlp(self.mx(x))\n",
    "\n",
    "        fusion_w = None\n",
    "        if self.fusion == \"sum\":\n",
    "            z = a + m\n",
    "        else:\n",
    "            fusion_w = torch.softmax(self.fusion_logits, dim=0)  # (2,)\n",
    "            z = fusion_w[0] * a + fusion_w[1] * m\n",
    "\n",
    "        T = self._get_T()\n",
    "        ca = self.gate_fn(z / T)  # (B,C,1,1)\n",
    "        y = x * ca\n",
    "\n",
    "        if self.return_fusion_weights and (fusion_w is not None):\n",
    "            return y, ca, fusion_w\n",
    "        return y, ca\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a52fc3",
   "metadata": {},
   "source": [
    "----\n",
    "----\n",
    "----\n",
    "## CÃ¼mle Ã¶zeti aÅŸaÄŸÄ±daki gibidir:\n",
    "\n",
    "**Ã–ncelikle gerekli parametreleri aldÄ±k ve fusion, return_fusion_weights ve eps deÄŸiÅŸkenlerini self iÃ§ine kaydettik. Daha sonra hidden kanal sayÄ±sÄ±nÄ± belirledik; bunu yaparken channels // reduction deÄŸerinin Ã§ok kÃ¼Ã§Ã¼k olmamasÄ± iÃ§in max(min_hidden, ...) kullandÄ±k. ArdÄ±ndan kanal bilgisini sÄ±kÄ±ÅŸtÄ±rmak iÃ§in AdaptiveAvgPool2d(1) ve AdaptiveMaxPool2d(1) tanÄ±mladÄ±k. SonrasÄ±nda bu sÄ±kÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ kanal bilgilerini iÅŸleyecek olan MLP yapÄ±sÄ±nÄ± kurduk; bunun iÃ§in Ã¶nce channels â†’ hidden dÃ¶nÃ¼ÅŸÃ¼mÃ¼nÃ¼ yapan fc1 katmanÄ±nÄ±, ardÄ±ndan aktivasyon fonksiyonunu (ReLU veya SiLU) ve son olarak hidden â†’ channels dÃ¶nÃ¼ÅŸÃ¼mÃ¼nÃ¼ yapan fc2 katmanÄ±nÄ± tanÄ±mladÄ±k. Daha sonra kanal maskesini Ã¼retirken kullanÄ±lacak gate_fn fonksiyonunu (sigmoid veya hardsigmoid) belirledik. SÄ±caklÄ±ÄŸÄ±n Ã¶ÄŸrenilebilir olup olmadÄ±ÄŸÄ±na gÃ¶re iki yol izledik; eÄŸer Ã¶ÄŸrenilebilir ise verilen temperature deÄŸerini baÅŸlangÄ±Ã§ta korunacak ÅŸekilde softplusâ€™Ä±n tersini alarak t_inv hesapladÄ±k ve bunu t_raw adlÄ± Ã¶ÄŸrenilebilir parametre olarak tanÄ±mladÄ±k, eÄŸer Ã¶ÄŸrenilebilir deÄŸilse temperature deÄŸerini register_buffer ile sabit bir deÄŸiÅŸken olarak modele ekledik. ArdÄ±ndan sÄ±caklÄ±ÄŸÄ± gÃ¼venli ÅŸekilde elde etmek iÃ§in _get_T fonksiyonunu tanÄ±mladÄ±k ve kanal Ã¶zetlerini iÅŸlemek iÃ§in _mlp yardÄ±mcÄ± fonksiyonunu yazdÄ±k. Forward aÅŸamasÄ±nda Ã¶nce giriÅŸten avg ve max pooling ile kanal Ã¶zetlerini Ã§Ä±kardÄ±k ve bunlarÄ± MLPâ€™den geÃ§irerek a ve m deÄŸerlerini elde ettik. EÄŸer fusion yÃ¶ntemi sum ise bu iki deÄŸeri doÄŸrudan topladÄ±k, deÄŸilse fusion_logits Ã¼zerinden softmax alarak modelin avg ve max kaynaklarÄ±ndan hangisine daha fazla gÃ¼veneceÄŸini Ã¶ÄŸrendiÄŸi aÄŸÄ±rlÄ±klarÄ± elde ettik ve bu aÄŸÄ±rlÄ±klarla a ve m deÄŸerlerini birleÅŸtirerek z deÄŸerini oluÅŸturduk. Daha sonra _get_T fonksiyonu ile sÄ±caklÄ±k deÄŸerini aldÄ±k, z / T iÅŸlemini uygulayÄ±p bunu gate_fn fonksiyonundan geÃ§irerek kanal attention maskesini ca olarak Ã¼rettik ve son olarak bu maskeyi giriÅŸ tensorÃ¼ ile Ã§arparak attention uygulanmÄ±ÅŸ Ã§Ä±ktÄ± y deÄŸerini elde ettik; eÄŸer istenirse analiz amacÄ±yla fusion aÄŸÄ±rlÄ±klarÄ±nÄ± da Ã§Ä±ktÄ± olarak dÃ¶ndÃ¼rdÃ¼k.**\n",
    "\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882bb76e",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# 1) Bu ModÃ¼l Ne YapÄ±yor? (YÃ¼ksek Seviye)\n",
    "Input: `x âˆˆ R^{BÃ—CÃ—HÃ—W}`  \n",
    "Output:\n",
    "- `y âˆˆ R^{BÃ—CÃ—HÃ—W}` (attention uygulanmÄ±ÅŸ feature)\n",
    "- `ca âˆˆ R^{BÃ—CÃ—1Ã—1}` (channel attention maskesi)\n",
    "- opsiyonel `fusion_w âˆˆ R^{2}` (avg/max karÄ±ÅŸÄ±m aÄŸÄ±rlÄ±klarÄ±)\n",
    "\n",
    "**Kanal attention** ÅŸunu yapar:\n",
    "- Her kanal iÃ§in bir â€œÃ¶nem katsayÄ±sÄ±â€ Ã¼retir.\n",
    "- `ca[:, c, 0, 0]` bÃ¼yÃ¼dÃ¼kÃ§e o kanal daha Ã§ok korunur/boost edilir.\n",
    "- `y = x * ca` ile her kanal Ã¶lÃ§eklenir.\n",
    "\n",
    "Bu yaklaÅŸÄ±m, Ã¶zellikle CNN backboneâ€™larda â€œhangi kanalÄ±n daha faydalÄ±â€ olduÄŸunu adaptif seÃ§meye yarar.\n",
    "\n",
    "---\n",
    "# 2) Åekil Takibi (Shape Tracking)\n",
    "Bir kez netleÅŸtirelim:\n",
    "\n",
    "- `x`: `(B, C, H, W)`\n",
    "- `avg(x)`: `(B, C, 1, 1)`\n",
    "- `max(x)`: `(B, C, 1, 1)`\n",
    "- `MLP(avg(x))`: `(B, C, 1, 1)`\n",
    "- `MLP(max(x))`: `(B, C, 1, 1)`\n",
    "- `z`: `(B, C, 1, 1)`\n",
    "- `ca = gate(z/T)`: `(B, C, 1, 1)`\n",
    "- `y = x * ca`: `(B, C, H, W)` (broadcast ile)\n",
    "\n",
    "Bu notasyonu notebook boyunca referans alacaÄŸÄ±z.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdbe904",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# 3) Parametreler: Tek Tek, Ne Ä°ÅŸe Yarar?\n",
    "AÅŸaÄŸÄ±daki parametrelerin her biri modelin kapasitesini, stabilitesini veya davranÄ±ÅŸÄ±nÄ± deÄŸiÅŸtirir.\n",
    "\n",
    "## `channels: int`\n",
    "- Input tensorâ€™Ã¼n kanal sayÄ±sÄ±: `C`\n",
    "- Bu modÃ¼lÃ¼n â€œkanal maskesiâ€ de aynÄ± `C` boyutunda Ã¼retilir.\n",
    "- YanlÄ±ÅŸ verilirse shape uyumsuzluÄŸu Ã§Ä±kar (Ã¶rn. `Conv2d` aÄŸÄ±rlÄ±klarÄ± uyuÅŸmaz).\n",
    "\n",
    "## `reduction: int = 16`\n",
    "- Bottleneck oranÄ±.\n",
    "- Hidden boyut yaklaÅŸÄ±k `C / reduction` olur.\n",
    "- AmaÃ§: MLP parametre sayÄ±sÄ±nÄ± dÃ¼ÅŸÃ¼rmek, overfit/hesap maliyetini azaltmak.\n",
    "\n",
    "> Ã–rnek: `C=256, reduction=16 => hiddenâ‰ˆ16`\n",
    "\n",
    "## `min_hidden: int = 4`\n",
    "- Ã‡ok kÃ¼Ã§Ã¼k `C` deÄŸerlerinde `C//reduction` sÄ±fÄ±ra yaklaÅŸabilir.\n",
    "- `min_hidden`, hidden boyutunu â€œen az ÅŸu kadarâ€ yapar.\n",
    "- Bu, modÃ¼lÃ¼n â€œÃ§alÄ±ÅŸabilirâ€ kalmasÄ±nÄ± garanti eder.\n",
    "\n",
    "## `fusion: str = \"softmax\"`  (`\"sum\"` | `\"softmax\"`)\n",
    "- Avg ve Max squeeze sonuÃ§larÄ±nÄ±n nasÄ±l birleÅŸtirileceÄŸini seÃ§er.\n",
    "\n",
    "### `fusion=\"sum\"`\n",
    "- Klasik CBAM davranÄ±ÅŸÄ±: `z = a + m`\n",
    "- Avg ve Max aynÄ± aÄŸÄ±rlÄ±kla (1,1) katkÄ± verir.\n",
    "- Ã–ÄŸrenilebilir deÄŸildir.\n",
    "\n",
    "### `fusion=\"softmax\"`\n",
    "- Ä°ki learnable logit vardÄ±r: `fusion_logits = [l_avg, l_max]`\n",
    "- `fusion_w = softmax(fusion_logits)` ile `w_avg+w_max=1`\n",
    "- `z = w_avg*a + w_max*m`\n",
    "- Model datasetâ€™e gÃ¶re â€œavg mi max mÄ± daha iyi?â€ Ã¶ÄŸrenebilir.\n",
    "\n",
    "**Ã–nemli nÃ¼ans:** Bu aÄŸÄ±rlÄ±klar **global** (sampleâ€™a gÃ¶re deÄŸil). Yani her input iÃ§in aynÄ± `fusion_w` kullanÄ±lÄ±r.\n",
    "\n",
    "## `gate: str = \"sigmoid\"` (`\"sigmoid\"` | `\"hardsigmoid\"`)\n",
    "- Son maske Ã¼retirken kullanÄ±lan aktivasyon.\n",
    "- `sigmoid`: daha yumuÅŸak, standart, tÃ¼revleri dÃ¼zgÃ¼n.\n",
    "- `hardsigmoid`: daha hÄ±zlÄ±, bazÄ± donanÄ±mlarda daha verimli, saturasyon davranÄ±ÅŸÄ± farklÄ±.\n",
    "\n",
    "> `hardsigmoid` Ã¶zellikle mobil/edge modellerde tercih edilebilir.\n",
    "\n",
    "## `temperature: float = 1.0`\n",
    "- `z` logitlerinin gateâ€™e girmeden Ã¶nce Ã¶lÃ§eklenmesi: `z / T`\n",
    "- `T` kÃ¼Ã§Ã¼kse => daha â€œsertâ€ maskeler (0/1â€™e yaklaÅŸÄ±r)\n",
    "- `T` bÃ¼yÃ¼kse => daha â€œyumuÅŸakâ€ maskeler (0.5 civarÄ±na yaklaÅŸÄ±r)\n",
    "\n",
    "## `learnable_temperature: bool = False`\n",
    "- `T` sabit mi olacak, Ã¶ÄŸrenilecek mi?\n",
    "- `False`: `T` buffer olarak sabit tutulur.\n",
    "- `True`: `T` bir parametre olur ama **pozitif kalmasÄ± garanti** edilir (softplus ile).\n",
    "\n",
    "## `eps: float = 1e-6`\n",
    "- SayÄ±sal stabilite iÃ§in.\n",
    "- Ã–ÄŸrenilebilir temperature ters dÃ¶nÃ¼ÅŸÃ¼mÃ¼nde ve softplus sonrasÄ± eklenir.\n",
    "- AmaÃ§: `log(0)` gibi patlamalarÄ± engellemek, `T=0` olmasÄ±nÄ± Ã¶nlemek.\n",
    "\n",
    "## `act: str = \"relu\"` (`\"relu\"` | `\"silu\"`)\n",
    "- MLP iÃ§indeki nonlinearity.\n",
    "- `relu`: hÄ±zlÄ±, yaygÄ±n\n",
    "- `silu`: daha pÃ¼rÃ¼zsÃ¼z, bazen daha iyi performans (Ã¶zellikle modern convnetâ€™lerde)\n",
    "\n",
    "## `bias: bool = True`\n",
    "- `fc1` ve `fc2` 1Ã—1 conv katmanlarÄ±nda bias kullanÄ±lsÄ±n mÄ±?\n",
    "- BN/LN gibi normalizasyon yoksa bias bazen faydalÄ± olabilir.\n",
    "- Ama bazÄ± tasarÄ±mlarda bias gereksiz parametre olur (Ã¶zellikle sonraki norm katmanÄ± varsa).\n",
    "\n",
    "## `return_fusion_weights: bool = False`\n",
    "- Debug/analiz iÃ§in.\n",
    "- `fusion=\"softmax\"` iken `fusion_w` dÃ¶ndÃ¼rmek isteyebilirsin.\n",
    "- EÄŸitim sÄ±rasÄ±nda genelde kapalÄ± tutulur (API sadeleÅŸir).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c6021d",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# 4) â€œVirgÃ¼lÃ¼ne Kadarâ€ Kod YapÄ±sÄ± ve Python Ä°mzalarÄ±\n",
    "Bu bÃ¶lÃ¼m, kÃ¼Ã§Ã¼k gÃ¶rÃ¼nen ama Ã¶nemli olan dil/uygulama detaylarÄ±nÄ± aÃ§Ä±klar.\n",
    "\n",
    "## `def __init__( self, ... , ):`\n",
    "- Parametre listesinin sonunda virgÃ¼l olmasÄ± (PEP8):\n",
    "  - Diffâ€™lerde satÄ±r ekleme/Ã§Ä±karma kolaylaÅŸÄ±r.\n",
    "  - Otomatik formatterâ€™larla uyumludur.\n",
    "  - HiÃ§bir runtime etkisi yoktur; bakÄ±m kolaylÄ±ÄŸÄ± saÄŸlar.\n",
    "\n",
    "## Type hints: `channels: int`\n",
    "- PyTorch iÃ§in zorunlu deÄŸil.\n",
    "- Okunabilirlik ve IDE autocompletion iÃ§in faydalÄ±dÄ±r.\n",
    "- MyPy gibi statik analiz araÃ§larÄ±yla hata yakalamayÄ± saÄŸlar.\n",
    "\n",
    "## `super().__init__()`\n",
    "- `nn.Module` iÃ§ yapÄ±sÄ±nÄ± kurar:\n",
    "  - Parameter/buffer kaydÄ±\n",
    "  - `state_dict` mekanizmasÄ±\n",
    "  - `.to(device)` / `.cuda()` davranÄ±ÅŸlarÄ±\n",
    "- Bunu Ã§aÄŸÄ±rmazsan modÃ¼lÃ¼n parametreleri dÃ¼zgÃ¼n kayÄ±t olmaz.\n",
    "\n",
    "---\n",
    "# 5) Girdi ValidasyonlarÄ±: Neden Bu `if` Kontrolleri Var?\n",
    "```python\n",
    "if fusion not in (\"sum\",\"softmax\"): raise ValueError(...)\n",
    "```\n",
    "Bu kontroller:\n",
    "- Sessiz bugâ€™larÄ± Ã¶nler (Ã¶rn. `fusion=\"sofmax\"` typo).\n",
    "- Hata Ã§Ä±ktÄ±sÄ±nÄ± daha anlaÅŸÄ±lÄ±r yapar.\n",
    "- Deney/ablasyon yaparken yanlÄ±ÅŸ konfigÃ¼rasyonu anÄ±nda yakalar.\n",
    "\n",
    "`temperature <= 0` kontrolÃ¼ kritiktir:\n",
    "- `z / T` bÃ¶lÃ¼mÃ¼nde `T=0` tanÄ±msÄ±z\n",
    "- Negatif T maskeyi ters Ã¶lÃ§ekler ve yorumlanabilirliÄŸi bozar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e6556d",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# 6) `hidden = max(min_hidden, channels // reduction)` SatÄ±rÄ±\n",
    "Bu satÄ±r, MLPâ€™nin orta katman kanal sayÄ±sÄ±nÄ± belirler.\n",
    "\n",
    "## Neden bottleneck var?\n",
    "- Kanal attention MLPâ€™si normalde `C -> C/r -> C`\n",
    "- `C` bÃ¼yÃ¼kse doÄŸrudan `C->C` dense Ã§ok pahalÄ± olur.\n",
    "- Bottleneck, parametre ve MACâ€™i dÃ¼ÅŸÃ¼rÃ¼r.\n",
    "\n",
    "## Neden `//` (integer division)?\n",
    "- PyTorch `Conv2d` kanal sayÄ±sÄ± integer olmalÄ±.\n",
    "- `channels/reduction` float Ã¼retmesin diye `//` kullanÄ±lÄ±r.\n",
    "\n",
    "## Neden `max(min_hidden, ...)`?\n",
    "- `C=8`, `reduction=16` olursa `8//16=0` Ã§Ä±kar.\n",
    "- 0 kanal diye bir ÅŸey olamaz.\n",
    "- `min_hidden` bunu engeller ve â€œen az 4â€ gibi bir taban verir.\n",
    "\n",
    "**Pratik Ã¶neri:**  \n",
    "KÃ¼Ã§Ã¼k backbone katmanlarÄ±nda (`C=16/32`) `min_hidden` Ã¶zellikle Ã¶nemlidir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a398c2",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# 7) `AdaptiveAvgPool2d(1)` ve `AdaptiveMaxPool2d(1)` Ne Demek?\n",
    "```python\n",
    "self.avg = nn.AdaptiveAvgPool2d(1)\n",
    "self.mx  = nn.AdaptiveMaxPool2d(1)\n",
    "```\n",
    "Bu katmanlar, `HÃ—W` boyutunu **1Ã—1**â€™e indirir.\n",
    "\n",
    "## Adaptive ne saÄŸlar?\n",
    "- Girdi boyutu deÄŸiÅŸse bile (Ã¶r. 56Ã—56, 80Ã—80) Ã§Ä±kÄ±ÅŸ her zaman 1Ã—1 olur.\n",
    "- Bu sayede blok â€œresolution-agnosticâ€ Ã§alÄ±ÅŸÄ±r.\n",
    "\n",
    "## Avg vs Max farkÄ±\n",
    "- Avg: kanalÄ±n genel daÄŸÄ±lÄ±mÄ±nÄ± Ã¶lÃ§er (smooth/istikrarlÄ±).\n",
    "- Max: kanalÄ±n en gÃ¼Ã§lÃ¼ aktivasyonunu yakalar (spike/edge/trigger).\n",
    "\n",
    "CBAMâ€™in fikri: Ä°kisi birlikte daha iyi sinyal verir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef156f31",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# 8) MLP Neden `Conv2d(1Ã—1)` ile YazÄ±lmÄ±ÅŸ?\n",
    "```python\n",
    "self.fc1 = nn.Conv2d(channels, hidden, 1, bias=bias)\n",
    "self.fc2 = nn.Conv2d(hidden, channels, 1, bias=bias)\n",
    "```\n",
    "Bu kullanÄ±m, SE/CBAM literatÃ¼rÃ¼ndeki klasik yaklaÅŸÄ±mdÄ±r.\n",
    "\n",
    "## Neden Linear deÄŸil?\n",
    "- Ã‡Ã¼nkÃ¼ tensor shapeâ€™i `(B,C,1,1)` ve Conv2d bunu doÄŸal iÅŸler.\n",
    "- Linear kullanÄ±rsan reshape/squeeze gerekir.\n",
    "- Conv2d ile PyTorch graphâ€™Ä± daha â€œstandart CNNâ€ gibi kalÄ±r.\n",
    "\n",
    "## Parametre sayÄ±sÄ± (yaklaÅŸÄ±k)\n",
    "- `fc1`: `C*hidden` (+ bias varsa `hidden`)\n",
    "- `fc2`: `hidden*C` (+ bias varsa `C`)\n",
    "\n",
    "Toplam yaklaÅŸÄ±k `2*C*hidden` (bias ihmal).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b782226",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# 9) Aktivasyon: `ReLU(inplace=True)` vs `SiLU(inplace=True)`\n",
    "```python\n",
    "self.act = nn.ReLU(inplace=True) if act==\"relu\" else nn.SiLU(inplace=True)\n",
    "```\n",
    "## `inplace=True` ne yapar?\n",
    "- Aktivasyonu aynÄ± tensor Ã¼zerinde uygular (ek memory tahsisini azaltabilir).\n",
    "- BazÄ± durumlarda autograd ile Ã§akÄ±ÅŸma riskleri olabilir ama burada tipik kullanÄ±mda sorun Ã§Ä±kmaz.\n",
    "\n",
    "## ReLU vs SiLU\n",
    "- ReLU: hÄ±zlÄ±, sparse aktivasyon, klasik.\n",
    "- SiLU (Swish): pÃ¼rÃ¼zsÃ¼z, kÃ¼Ã§Ã¼k negatiflerde gradient akÄ±ÅŸÄ± saÄŸlar.\n",
    "- Modern CNNâ€™lerde (EfficientNet, ConvNeXt tÃ¼revleri) SiLU sÄ±k tercih edilir.\n",
    "\n",
    "Bu seÃ§imin dikkat modÃ¼lÃ¼nde etkisi:\n",
    "- MLPâ€™nin Ã¼rettiÄŸi logitsâ€™in daÄŸÄ±lÄ±mÄ±nÄ± deÄŸiÅŸtirir.\n",
    "- DolaylÄ± olarak maskenin keskinliÄŸini/kalibrasyonunu etkileyebilir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732a867c",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# 10) Gate Fonksiyonu SeÃ§imi: `sigmoid` vs `hardsigmoid`\n",
    "```python\n",
    "if gate.lower() == \"sigmoid\":\n",
    "    self.gate_fn = torch.sigmoid\n",
    "else:\n",
    "    self.gate_fn = F.hardsigmoid\n",
    "```\n",
    "## Neden fonksiyonu attribute olarak saklÄ±yoruz?\n",
    "- Forward iÃ§inde `if` yapmaktan kaÃ§Ä±nÄ±r (micro-opt, okunabilirlik).\n",
    "- ModÃ¼l davranÄ±ÅŸÄ± initâ€™te â€œkilitlenirâ€.\n",
    "\n",
    "## `torch.sigmoid` vs `F.hardsigmoid`\n",
    "- Sigmoid: `1/(1+exp(-x))` (smooth)\n",
    "- HardSigmoid: parÃ§alÄ± doÄŸrusal approx (daha hÄ±zlÄ±)\n",
    "\n",
    "HardSigmoid etkisi:\n",
    "- Saturation bÃ¶lgeleri farklÄ±dÄ±r.\n",
    "- BazÄ± donanÄ±mlarda hÄ±z avantajÄ± olabilir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7544013",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# 11) Fusion MantÄ±ÄŸÄ±: `sum` ve `softmax` Derin Analiz\n",
    "Bu bloktaki asÄ±l â€œtwistâ€ burasÄ±.\n",
    "\n",
    "## 11.1) `fusion_logits = nn.Parameter(torch.zeros(2))`\n",
    "- Ä°ki scalar parametre.\n",
    "- BaÅŸlangÄ±Ã§: `[0, 0]`\n",
    "\n",
    "## 11.2) `softmax(..., dim=0)` neden `dim=0`?\n",
    "`fusion_logits` shapeâ€™i `(2,)` olduÄŸu iÃ§in:\n",
    "- `dim=0` tek boyut Ã¼zerinde softmax demek.\n",
    "- SonuÃ§ yine `(2,)` olur ve toplamÄ± 1â€™dir.\n",
    "\n",
    "## 11.3) BaÅŸlangÄ±Ã§ta neden zeros?\n",
    "- `softmax([0,0]) = [0.5, 0.5]`\n",
    "- Yani â€œavg ve max eÅŸitâ€ ile baÅŸlÄ±yor.\n",
    "- EÄŸitim, hangi taraf daha faydalÄ±ysa oraya kaydÄ±rÄ±yor.\n",
    "\n",
    "## 11.4) Bu fusion â€œglobalâ€dÄ±r\n",
    "Dikkat: `fusion_logits` **inputâ€™a baÄŸlÄ± deÄŸil**.\n",
    "- Her batch, her gÃ¶rÃ¼ntÃ¼ iÃ§in aynÄ± `fusion_w` kullanÄ±lÄ±r.\n",
    "- Bu bir â€œmodel seviyesinde hiperparametreyi Ã¶ÄŸrenmeâ€ gibi Ã§alÄ±ÅŸÄ±r.\n",
    "\n",
    "EÄŸer inputâ€™a baÄŸlÄ± olmasÄ±nÄ± isteseydin:\n",
    "- `fusion_logits`â€™Ä± bir router ile `avg(x), max(x)`â€™ten Ã¼retirdin.\n",
    "\n",
    "## 11.5) `sum` neden hala var?\n",
    "Ablation / baseline iÃ§in:\n",
    "- softmax fusion bazÄ± modellerde gereksiz ek parametre olabilir.\n",
    "- `sum` daha basit ve bazen daha stabil.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11273027",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# 12) Temperature: Matematiksel ve Pratik Etki\n",
    "```python\n",
    "ca = gate_fn(z / T)\n",
    "```\n",
    "Burada `z` gateâ€™e giren logit (B,C,1,1).\n",
    "\n",
    "## 12.1) T kÃ¼Ã§Ã¼lÃ¼rse\n",
    "- `z/T` bÃ¼yÃ¼r (mutlak deÄŸer)\n",
    "- sigmoid daha hÄ±zlÄ± 0/1â€™e gider\n",
    "- maske **keskinleÅŸir**\n",
    "\n",
    "## 12.2) T bÃ¼yÃ¼rse\n",
    "- `z/T` kÃ¼Ã§Ã¼lÃ¼r\n",
    "- sigmoid 0.5 civarÄ±nda kalÄ±r\n",
    "- maske **yumuÅŸar** (daha az agresif)\n",
    "\n",
    "Bu, bir â€œkalibrasyon / confidenceâ€ kontrolÃ¼dÃ¼r.\n",
    "\n",
    "## 12.3) Neden learnable temperature?\n",
    "Her dataset ve her backbone katmanÄ± iÃ§in ideal keskinlik farklÄ± olabilir.\n",
    "- Erken katmanlarda Ã§ok keskin maskeler bilgi kaybettirebilir.\n",
    "- GeÃ§ katmanlarda keskin maskeler faydalÄ± olabilir.\n",
    "\n",
    "Learnable T ile model bunu ayarlayabilir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c4644d",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# 13) Learnable Temperatureâ€™Ä±n Ä°nÅŸa Edilmesi (En Ä°nce Detay)\n",
    "Kod:\n",
    "```python\n",
    "t_raw = torch.tensor(float(temperature))\n",
    "t_inv = torch.log(torch.exp(t_raw) - 1.0 + eps)\n",
    "self.t_raw = nn.Parameter(t_inv)\n",
    "\n",
    "# kullanÄ±m\n",
    "T = softplus(t_raw) + eps\n",
    "```\n",
    "## 13.1) Neden `softplus`?\n",
    "`softplus(x) = log(1+exp(x))` her zaman pozitiftir.\n",
    "- BÃ¶ylece `T > 0` garanti.\n",
    "\n",
    "## 13.2) Neden â€œinverse softplusâ€ gibi bir ÅŸey yapÄ±lÄ±yor?\n",
    "Ä°stenilen: EÄŸitim baÅŸÄ±nda `T` tam olarak `temperature` olsun.\n",
    "\n",
    "EÄŸer direkt `self.t_raw = nn.Parameter(torch.tensor(temperature))` yapsaydÄ±n:\n",
    "- `_get_T()` softplus uygulayacaÄŸÄ± iÃ§in baÅŸlangÄ±Ã§ `T` â‰  temperature olurdu.\n",
    "\n",
    "Bu yÃ¼zden:\n",
    "- `t_inv` seÃ§iliyor ki `softplus(t_inv) â‰ˆ temperature` olsun.\n",
    "\n",
    "YaklaÅŸÄ±k ters:\n",
    "- `softplus^{-1}(t) = log(exp(t) - 1)`\n",
    "- Buradaki `+ eps` sayÄ±sal stabilite iÃ§in.\n",
    "\n",
    "## 13.3) `eps` burada niye kritik?\n",
    "`temperature` Ã§ok kÃ¼Ã§Ã¼kse `exp(t)-1` ~ 0 olabilir.\n",
    "- `log(0)` â†’ `-inf`\n",
    "- `+ eps` bunu Ã¶nler.\n",
    "\n",
    "## 13.4) Learnable deÄŸilse `register_buffer(\"T\", ...)`\n",
    "- Bu bir Parameter deÄŸildir, gradient almaz.\n",
    "- Ama `state_dict`â€™e girer.\n",
    "- `.to(device)` ile GPU/CPU arasÄ±nda taÅŸÄ±nÄ±r.\n",
    "\n",
    "\n",
    "### Ä°ÅŸte LOG ve âˆ’1 buradan geliyor\n",
    "AdÄ±m adÄ±m (Ã§ok basit):\n",
    "\n",
    "1ï¸âƒ£\n",
    "```python\n",
    "log(1 + exp(t_inv)) = temperature\n",
    "```\n",
    "\n",
    "2ï¸âƒ£\n",
    "Logâ€™dan kurtulmak iÃ§in exp al:\n",
    "```python\n",
    "1 + exp(t_inv) = exp(temperature)\n",
    "```\n",
    "\n",
    "\n",
    "3ï¸âƒ£\n",
    "1â€™i karÅŸÄ±ya at:\n",
    "```python\n",
    "exp(t_inv) = exp(temperature) - 1\n",
    "```\n",
    "\n",
    "4ï¸âƒ£\n",
    "Åimdi t_invâ€™i yalnÄ±z bÄ±rakmak iÃ§in log al:\n",
    "```python\n",
    "t_inv = log(exp(temperature) - 1)\n",
    "```\n",
    "\n",
    "\n",
    "ğŸ”¥ Ä°ÅŸte bu yÃ¼zden log var\n",
    "\n",
    "ğŸ”¥ Ä°ÅŸte bu yÃ¼zden âˆ’1 var\n",
    "\n",
    "* BaÅŸka hiÃ§bir numara yok.\n",
    "* Bu sadece softplusâ€™Ä±n tersini almak.\n",
    "\n",
    "Bu, sabit hyperparametreyi â€œmodelin parÃ§asÄ±â€ gibi tutmanÄ±n temiz yoludur.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c121f99",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# 14) YardÄ±mcÄ± Metodlar: `_get_T()` ve `_mlp()` Neden Var?\n",
    "## `_get_T()`\n",
    "- Learnable/sabit T ayrÄ±mÄ±nÄ± tek yerde toplar.\n",
    "- Forwardâ€™Ä± temiz tutar.\n",
    "\n",
    "## `_mlp(s)`\n",
    "```python\n",
    "return fc2(act(fc1(s)))\n",
    "```\n",
    "- Avg ve Max squeeze Ã§Ä±ktÄ±larÄ± aynÄ± MLPâ€™den geÃ§iyor.\n",
    "- Bu â€œshared MLPâ€ CBAMâ€™in standardÄ±dÄ±r.\n",
    "- Kod tekrarÄ±nÄ± azaltÄ±r.\n",
    "\n",
    "**Not:** Shared MLP demek:\n",
    "- Avg ve Max aynÄ± aÄŸÄ±rlÄ±klarÄ± paylaÅŸÄ±r.\n",
    "- BÃ¶ylece model iki squeezeâ€™i aynÄ± â€œÃ¶lÃ§ekteâ€ kÄ±yaslar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2915a319",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# 15) Forward: SatÄ±r SatÄ±r, Ne Oluyor?\n",
    "```python\n",
    "a = _mlp(avg(x))\n",
    "m = _mlp(mx(x))\n",
    "```\n",
    "1) `avg(x)` ile her kanalÄ±n ortalamasÄ± alÄ±nÄ±r â†’ `(B,C,1,1)`  \n",
    "2) MLP ile kanal logitleri Ã¼retilir â†’ `(B,C,1,1)`  \n",
    "3) AynÄ±sÄ± max iÃ§in yapÄ±lÄ±r.\n",
    "\n",
    "```python\n",
    "if fusion==\"sum\": z=a+m\n",
    "else:\n",
    "    fusion_w = softmax(fusion_logits)  # (2,)\n",
    "    z = fusion_w[0]*a + fusion_w[1]*m\n",
    "```\n",
    "4) Ä°ki logit kaynaÄŸÄ± birleÅŸtirilir.\n",
    "- sum: sabit\n",
    "- softmax: Ã¶ÄŸrenilebilir karÄ±ÅŸÄ±m\n",
    "\n",
    "```python\n",
    "T = _get_T()\n",
    "ca = gate_fn(z/T)\n",
    "```\n",
    "5) Temperature ile Ã¶lÃ§ekleme yapÄ±lÄ±r.\n",
    "6) Gate fonksiyonu ile 0..1 aralÄ±ÄŸÄ±na sÄ±kÄ±ÅŸtÄ±rÄ±lÄ±r.\n",
    "\n",
    "```python\n",
    "y = x * ca\n",
    "```\n",
    "7) Broadcast Ã§arpÄ±mÄ±:\n",
    "- `ca` her kanal iÃ§in tek katsayÄ±dÄ±r.\n",
    "- `HÃ—W` boyunca uygulanÄ±r.\n",
    "\n",
    "Return:\n",
    "- Normalde `(y, ca)`\n",
    "- Debug modunda `(y, ca, fusion_w)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00533d3",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# 16) KÃ¶ÅŸe Durumlar ve Hata SenaryolarÄ± (Bu Kod Neyi Ã–nler?)\n",
    "## 16.1) `channels // reduction == 0`\n",
    "- `min_hidden` ile Ã¶nlenir.\n",
    "\n",
    "## 16.2) `temperature <= 0`\n",
    "- bÃ¶lme hatasÄ± / anlamsÄ±z Ã¶lÃ§ekleme\n",
    "- initâ€™te engellenir.\n",
    "\n",
    "## 16.3) `fusion=\"softmax\"` ama `return_fusion_weights=True` deÄŸil\n",
    "- `fusion_w` hesaplanÄ±r ama dÃ¶ndÃ¼rÃ¼lmez.\n",
    "- Bu â€œdebugâ€ iÃ§in gereksiz Ã§Ä±ktÄ± yaratmamak adÄ±na normaldir.\n",
    "\n",
    "## 16.4) `fusion=\"sum\"` iken `return_fusion_weights=True`\n",
    "- `fusion_w` None kalÄ±r, dÃ¶ndÃ¼rÃ¼lmez.\n",
    "- Kod bunu zaten kontrol ediyor: `(fusion_w is not None)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35369e6",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# 17) Mini Deneyler: Åekil KontrolÃ¼, Fusion AÄŸÄ±rlÄ±klarÄ±, Temperature Etkisi\n",
    "AÅŸaÄŸÄ±daki hÃ¼creler:\n",
    "- ModÃ¼lÃ¼ instantiate eder\n",
    "- Output shapeâ€™lerini doÄŸrular\n",
    "- `fusion_w` nasÄ±l deÄŸiÅŸiyor gÃ¶sterir\n",
    "- Temperature maskeyi nasÄ±l keskinleÅŸtiriyor gÃ¶rselleÅŸtirir (istatistiksel)\n",
    "\n",
    "> Not: Bu hÃ¼creler eÄŸitim yapmaz, sadece davranÄ±ÅŸÄ± gÃ¶zlemler.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ca7b0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum: torch.Size([2, 64, 56, 56]) torch.Size([2, 64, 1, 1])\n",
      "softmax: torch.Size([2, 64, 56, 56]) torch.Size([2, 64, 1, 1]) torch.Size([2]) tensor([0.5000, 0.5000], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 17.1) Basit shape testi\n",
    "torch.manual_seed(0)\n",
    "x = torch.randn(2, 64, 56, 56)\n",
    "\n",
    "m_sum = ChannelAttentionFusionT(64, fusion=\"sum\", return_fusion_weights=True)\n",
    "y_sum, ca_sum = m_sum(x)\n",
    "print(\"sum:\", y_sum.shape, ca_sum.shape)\n",
    "\n",
    "m_soft = ChannelAttentionFusionT(64, fusion=\"softmax\", return_fusion_weights=True)\n",
    "y_soft, ca_soft, fw = m_soft(x)\n",
    "print(\"softmax:\", y_soft.shape, ca_soft.shape, fw.shape, fw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa9dd215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'T': 0.5, 'ca_mean': 0.5130427479743958, 'ca_std': 0.29812273383140564, 'ca_min': 0.04223500192165375, 'ca_max': 0.9689000844955444}\n",
      "{'T': 1.0, 'ca_mean': 0.4672200679779053, 'ca_std': 0.21377702057361603, 'ca_min': 0.10203836113214493, 'ca_max': 0.8694762587547302}\n",
      "{'T': 2.0, 'ca_mean': 0.5006216764450073, 'ca_std': 0.13165560364723206, 'ca_min': 0.21391931176185608, 'ca_max': 0.8047383427619934}\n",
      "{'T': 5.0, 'ca_mean': 0.5045205950737, 'ca_std': 0.027636060491204262, 'ca_min': 0.45041096210479736, 'ca_max': 0.549249529838562}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hdgn5\\AppData\\Local\\Temp\\ipykernel_22232\\1634033655.py:7: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\autograd\\generated\\python_variable_methods.cpp:837.)\n",
      "  \"ca_mean\": float(ca.mean()),\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 17.2) Temperature etkisi: maskenin daÄŸÄ±lÄ±mÄ±na bak\n",
    "def stats(t):\n",
    "    m = ChannelAttentionFusionT(64, fusion=\"sum\", temperature=t, learnable_temperature=False)\n",
    "    y, ca = m(x)\n",
    "    return {\n",
    "        \"T\": t,\n",
    "        \"ca_mean\": float(ca.mean()),\n",
    "        \"ca_std\": float(ca.std()),\n",
    "        \"ca_min\": float(ca.min()),\n",
    "        \"ca_max\": float(ca.max()),\n",
    "    }\n",
    "\n",
    "for t in [0.5, 1.0, 2.0, 5.0]:\n",
    "    print(stats(t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c93d5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits=[2,0] => fusion_w: tensor([0.8808, 0.1192], grad_fn=<SoftmaxBackward0>)\n",
      "logits=[0,2] => fusion_w: tensor([0.1192, 0.8808], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 17.3) Fusion logits'i elle oynatÄ±nca fusion_w nasÄ±l deÄŸiÅŸir?\n",
    "m = ChannelAttentionFusionT(64, fusion=\"softmax\", return_fusion_weights=True)\n",
    "with torch.no_grad():\n",
    "    m.fusion_logits[:] = torch.tensor([2.0, 0.0])  # avg aÄŸÄ±rlÄ±ÄŸÄ±nÄ± artÄ±r\n",
    "y, ca, fw = m(x)\n",
    "print(\"logits=[2,0] => fusion_w:\", fw)\n",
    "\n",
    "with torch.no_grad():\n",
    "    m.fusion_logits[:] = torch.tensor([0.0, 2.0])  # max aÄŸÄ±rlÄ±ÄŸÄ±nÄ± artÄ±r\n",
    "y, ca, fw = m(x)\n",
    "print(\"logits=[0,2] => fusion_w:\", fw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e18a0fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaÅŸlangÄ±Ã§ T: 1.7000011205673218 (hedef 1.7 civarÄ±)\n",
      "t_raw artÄ±rÄ±nca T: 2.5772933959960938\n",
      "t_raw Ã§ok azaltÄ±nca T (hala >0 olmalÄ±): 0.0005529767950065434\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 17.4) Learnable temperature gerÃ§ekten pozitif mi? BaÅŸlangÄ±Ã§ta temperature'a eÅŸit mi?\n",
    "m = ChannelAttentionFusionT(64, fusion=\"sum\", temperature=1.7, learnable_temperature=True)\n",
    "T0 = m._get_T().item()\n",
    "print(\"BaÅŸlangÄ±Ã§ T:\", T0, \"(hedef 1.7 civarÄ±)\")\n",
    "\n",
    "# Parametreyi deÄŸiÅŸtirince T nasÄ±l deÄŸiÅŸiyor?\n",
    "with torch.no_grad():\n",
    "    m.t_raw += 1.0\n",
    "print(\"t_raw artÄ±rÄ±nca T:\", m._get_T().item())\n",
    "\n",
    "with torch.no_grad():\n",
    "    m.t_raw -= 10.0\n",
    "print(\"t_raw Ã§ok azaltÄ±nca T (hala >0 olmalÄ±):\", m._get_T().item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5fa7b4",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# 18) Pratik KullanÄ±m NotlarÄ± (Backbone/YOLO iÃ§in)\n",
    "- **Early layers** (yÃ¼ksek Ã§Ã¶zÃ¼nÃ¼rlÃ¼k, dÃ¼ÅŸÃ¼k semantik): Ã‡ok keskin attention zarar verebilir â†’ `temperature` biraz daha bÃ¼yÃ¼k denenebilir.\n",
    "- **Late layers** (dÃ¼ÅŸÃ¼k Ã§Ã¶zÃ¼nÃ¼rlÃ¼k, yÃ¼ksek semantik): Keskin attention faydalÄ± olabilir â†’ `temperature` kÃ¼Ã§Ã¼k denenebilir.\n",
    "- `fusion=\"softmax\"` genelde kÃ¼Ã§Ã¼k bir ek parametreyle â€œhangi squeeze daha iyi?â€yi Ã¶ÄŸrenir; ablation iÃ§in `sum` ile kÄ±yaslamak mantÄ±klÄ±dÄ±r.\n",
    "- `hardsigmoid` hÄ±z odaklÄ± olabilir; `sigmoid` daha standart ve daha pÃ¼rÃ¼zsÃ¼z gradient verir.\n",
    "\n",
    "> En iyi ayar deneysel: backbone, veri, optimizasyon ve batch size ile deÄŸiÅŸir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eaefd7",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# 19) Ek: Parametre SayÄ±sÄ± HesabÄ± (YaklaÅŸÄ±k)\n",
    "`hidden = max(min_hidden, C//reduction)`\n",
    "\n",
    "- `fc1`: `C*hidden` (+ bias varsa `hidden`)\n",
    "- `fc2`: `hidden*C` (+ bias varsa `C`)\n",
    "Toplam: `2*C*hidden + (hidden + C if bias else 0)`\n",
    "\n",
    "Fusion:\n",
    "- `fusion=\"softmax\"` ise +2 parametre (`fusion_logits`)\n",
    "\n",
    "Learnable temperature:\n",
    "- `learnable_temperature=True` ise +1 parametre (`t_raw`)\n",
    "\n",
    "Bu blok Ã§ok ucuz kalÄ±r ama etkisi bÃ¼yÃ¼k olabilir.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
