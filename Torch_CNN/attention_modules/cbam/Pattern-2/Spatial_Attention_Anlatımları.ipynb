{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "250420e9",
   "metadata": {},
   "source": [
    "# DynamicSpatialAttention — Satır Satır ve İnce Detaylı Açıklama\n",
    "\n",
    "Bu not defteri **yalnızca** Spatial Attention (SA) bileşenini açıklar: `DynamicSpatialAttention`.\n",
    "\n",
    "Amaç: Kodun her bölümünün\n",
    "- ne yaptığı,\n",
    "- hangi tensör şekillerini ürettiği,\n",
    "- neden bu tasarımın seçildiği\n",
    "\n",
    "konularını, Channel Attention not defterindeki seviyede ayrıntılandırmaktır.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802b12ce",
   "metadata": {},
   "source": [
    "## 1) Kod (Referans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18635c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def _make_odd(k: int) -> int:\n",
    "    k = int(k)\n",
    "    if k < 1:\n",
    "        raise ValueError(\"Kernel size >= 1 olmalı.\")\n",
    "    return k if (k % 2 == 1) else (k + 1)\n",
    "\n",
    "\n",
    "def _softplus_inverse(y: torch.Tensor, eps: float = 1e-6) -> torch.Tensor:\n",
    "    return torch.log(torch.clamp(torch.exp(y) - 1.0, min=eps)) ## torch.clamp(..., min=eps) şunu garanti eder: exp(y) - 1 asla eps’ten küçük olmayacak.\n",
    "# Burda eğer eps değeri eğer çok küçükse -inf ye gitmesin diye biz buraya kontrol ekliyoruz.\n",
    "\n",
    "\n",
    "def _get_gate(gate: str):\n",
    "    g = gate.lower()\n",
    "    if g == \"sigmoid\":\n",
    "        return torch.sigmoid\n",
    "    if g == \"hardsigmoid\":\n",
    "        return F.hardsigmoid\n",
    "    raise ValueError(\"gate 'sigmoid' veya 'hardsigmoid' olmalı.\")\n",
    "\n",
    "\n",
    "class _DWPointwiseBranch(nn.Module):\n",
    "    \"\"\"Depthwise (in_ch -> in_ch, groups=in_ch) + Pointwise (in_ch -> 1).\"\"\"\n",
    "\n",
    "    def __init__(self, in_ch: int, k: int, dilation: int = 1):\n",
    "        super().__init__()\n",
    "        k = _make_odd(k)\n",
    "        dilation = int(dilation)\n",
    "        if dilation < 1:\n",
    "            raise ValueError(\"dilation >= 1 olmalı.\")\n",
    "        pad = dilation * (k - 1) // 2\n",
    "\n",
    "        self.dw = nn.Conv2d(\n",
    "            in_ch,\n",
    "            in_ch,\n",
    "            kernel_size=k,\n",
    "            padding=pad,\n",
    "            dilation=dilation,\n",
    "            groups=in_ch,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.pw = nn.Conv2d(in_ch, 1, kernel_size=1, bias=False)\n",
    "\n",
    "    def forward(self, s: torch.Tensor) -> torch.Tensor:\n",
    "        return self.pw(self.dw(s))\n",
    "\n",
    "\n",
    "class DynamicSpatialAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Spatial Attention (SA) bloğu:\n",
    "    - CoordConv: avg_map + max_map + x_coord + y_coord -> 4 kanal\n",
    "    - Multi-branch (multi-scale) depthwise+pointwise conv\n",
    "    - Sample-wise router ile branch ağırlıkları (B,K)\n",
    "    - Temperature scaling + gate ile mask üretimi\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        kernels=(3, 7),\n",
    "        use_dilated: bool = True,\n",
    "        dilated_kernel: int = 7,\n",
    "        dilated_d: int = 2,\n",
    "        gate: str = \"sigmoid\",\n",
    "        temperature: float = 1.0,\n",
    "        learnable_temperature: bool = False,\n",
    "        eps: float = 1e-6,\n",
    "        router_hidden: int = 8,\n",
    "        bias: bool = True,\n",
    "        return_router_weights: bool = False,\n",
    "        coord_norm: str = \"minus1to1\",  # \"minus1to1\" | \"0to1\"\n",
    "\n",
    "# # # x_coord: soldan sağa giden “konum” bilgisi\n",
    "# # # y_coord: yukarıdan aşağı giden “konum” bilgisi\n",
    "# # # coord_norm bunun ölçeğini seçiyor.\n",
    "\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if temperature <= 0:\n",
    "            raise ValueError(\"temperature pozitif olmalı.\")\n",
    "        if router_hidden < 1:\n",
    "            raise ValueError(\"router_hidden >= 1 olmalı.\")\n",
    "        if coord_norm not in (\"minus1to1\", \"0to1\"):\n",
    "            raise ValueError(\"coord_norm 'minus1to1' veya '0to1' olmalı.\") \n",
    "        \n",
    "# Çoğu CNN/attention tasarımında minus1to1 daha yaygın ve güvenli.\n",
    "# Çünkü 0 merkezli olması öğrenmeyi kolaylaştırabilir.\n",
    "        \n",
    "##         minus1to1 ne demek?        ## \n",
    "# # x_coord ve y_coord değerleri -1 ile +1 arasında olur.Model için “sağ mı sol mu” gibi yön bilgisi daha simetrik olur.Birçok modelde 0 merkezli girişler optimizasyon açısından daha rahat davranır.\n",
    "\n",
    "# En sol: x = -1\n",
    "# Orta: x ≈ 0\n",
    "# En sağ: x = +1\n",
    "\n",
    "# Benzer şekilde:\n",
    "# En üst: y = -1\n",
    "# Orta: y ≈ 0\n",
    "# En alt: y = +1\n",
    "\n",
    "##         0to1 ne demek?        ## \n",
    "# x_coord ve y_coord değerleri 0 ile 1 arasında olur.\n",
    "# En sol: x = 0\n",
    "# En sağ: x = 1\n",
    "# En üst: y = 0\n",
    "# En alt: y = 1\n",
    "\n",
    "        self.eps = float(eps)\n",
    "        self.return_router_weights = bool(return_router_weights)\n",
    "        self.gate_fn = _get_gate(gate)\n",
    "        self.coord_norm = coord_norm\n",
    "\n",
    "        in_ch = 4  # [avg_map, max_map, x_coord, y_coord]\n",
    "\n",
    "        # Branch pool\n",
    "        ks = []\n",
    "        for k in kernels:\n",
    "            ks.append(_make_odd(int(k)))\n",
    "\n",
    "        branches = []\n",
    "        for k in ks:\n",
    "            branches.append(_DWPointwiseBranch(in_ch=in_ch, k=k, dilation=1))\n",
    "\n",
    "        if use_dilated:\n",
    "            dk = _make_odd(int(dilated_kernel))\n",
    "            dd = int(dilated_d)\n",
    "            if dd < 1:\n",
    "                raise ValueError(\"dilated_d >= 1 olmalı.\")\n",
    "            branches.append(_DWPointwiseBranch(in_ch=in_ch, k=dk, dilation=dd))\n",
    "\n",
    "        self.branches = nn.ModuleList(branches)\n",
    "        self.num_branches = len(self.branches)\n",
    "\n",
    "\n",
    "\n",
    "        # Router: (B,4,H,W) -> pool -> (B,4,1,1) -> (B,hidden,1,1) -> (B,K,1,1)\n",
    "        # Router’ın amacı “seçmek/karıştırmak”.\n",
    "\n",
    "#         Buu formülün çalışması için:       #         \n",
    "        # rw içinde her branch için bir ağırlık olması şart.\n",
    "        # Yani rw mutlaka (B, K) olmalı.\n",
    "        # Bu yüzden router’ın çıkışı (B, K) olacak şekilde tasarlanır:\n",
    "        # Conv(hidden -> K)\n",
    "        self.router = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(in_ch, router_hidden, kernel_size=1, bias=bias),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(router_hidden, self.num_branches, kernel_size=1, bias=bias),\n",
    "        )\n",
    "\n",
    "    # Durum A: Router çıkışı 1 olsaydı\n",
    "    # (B,1) çıkar\n",
    "    # Bu tek sayı, tüm branch’lere aynı ağırlık gibi olur → branch karıştırma yapamazdık\n",
    "\n",
    "    # Durum B: Router çıkışı K olursa:\n",
    "    # Her branch’e bir ağırlık\n",
    "    # Softmax ile normalize\n",
    "    # Ağırlıklı toplam doğrudan ve temiz çalışı\n",
    "\n",
    "        # Temperature\n",
    "        self.learnable_temperature = bool(learnable_temperature)\n",
    "        if self.learnable_temperature:\n",
    "            t0 = torch.tensor(float(temperature))\n",
    "            t_inv = _softplus_inverse(t0, eps=self.eps)\n",
    "            self.t_raw = nn.Parameter(t_inv)\n",
    "        else:\n",
    "            self.register_buffer(\"T\", torch.tensor(float(temperature)))\n",
    "\n",
    "        # Coord cache (opsiyonel): (H,W,device,dtype,norm) -> (xg,yg)\n",
    "        self._coord_cache = {} # Daha önce üretilmiş koordinat gridlerini saklamak\n",
    "\n",
    "    def get_T(self) -> torch.Tensor:\n",
    "        if self.learnable_temperature:\n",
    "            return F.softplus(self.t_raw) + self.eps\n",
    "        return self.T\n",
    "\n",
    "    def _coords(self, B: int, H: int, W: int, device, dtype): # SA’ye “konum bilgisini” eklemek için x ve y koordinat haritaları üretir.\n",
    "# # # # # # # #  “Bu piksel solda mı sağda mı?” → x_coord\n",
    "# # # # # # # # “Bu piksel yukarıda mı aşağıda mı?” → y_coord\n",
    "\n",
    "# # # # avg_map, max_map → “burada aktivasyon var mı?”\n",
    "# # # # Ama bazen modelin şunu bilmesi lazım:\n",
    "# # # # “Bu aktivasyon nerede?”\n",
    "# # # # “Üst tarafta mı, alt tarafta mı, sol köşe mi?”\n",
    "\n",
    "        key = (H, W, str(device), str(dtype), self.coord_norm) # “Aynı H×W, aynı device, aynı dtype ve aynı coord_norm için koordinat gridini bir kez üret, sonra tekrar tekrar üretme.”\n",
    "\n",
    "#    Eğer modelin içinde bu attention çok kez çağrılıyorsa (özellikle backbone’da her blokta), bu tekrarlar gereksiz maliyet olur.\n",
    "# Cache sayesinde:\n",
    "# İlk sefer grid üretilir ve saklanır.\n",
    "# Aynı H,W/device/dtype/norm tekrar gelince:\n",
    "# grid yeniden hesaplanmaz,\n",
    "# direkt hazır grid kullanılır.\n",
    "\n",
    "# Daha önce ürettiğim koordinat haritalarını (x grid ve y grid) cache’den çek, tekrar hesaplama.”\n",
    "        if key in self._coord_cache: # “Bu H,W/device/dtype/norm kombinasyonu için koordinat gridini daha önce üretmiş miydim?”\n",
    "            xg, yg = self._coord_cache[key] # İkisini birlikte saklamak mantıklı; aynı anda üretiliyorlar, aynı koşula bağlılar.\n",
    "\n",
    "# key var mı?\n",
    "# varsa: direkt al (xg, yg = cache[key])\n",
    "# yoksa: xg, yg üret\n",
    "\n",
    "# cache’e kaydet (cache[key]=(xg,yg))\n",
    "# xg: x koordinat grid’i\n",
    "# yg: y koordinat grid’i\n",
    "\n",
    "# Şekilleri genelde:\n",
    "# xg.shape = (1, 1, H, W)\n",
    "# yg.shape = (1, 1, H, W)\n",
    "        else:\n",
    "            if self.coord_norm == \"minus1to1\":\n",
    "                xs = torch.linspace(-1.0, 1.0, W, device=device, dtype=dtype)\n",
    "                ys = torch.linspace(-1.0, 1.0, H, device=device, dtype=dtype)\n",
    "            else:\n",
    "                xs = torch.linspace(0.0, 1.0, W, device=device, dtype=dtype)\n",
    "                ys = torch.linspace(0.0, 1.0, H, device=device, dtype=dtype)\n",
    "\n",
    "            yy, xx = torch.meshgrid(ys, xs, indexing=\"ij\") # meshgrid: 1D xs ve ys’yi 2D (H,W) koordinat haritasına çevirir.\n",
    "\n",
    "# ilk eksen = i = satır = y (H)\n",
    "# ikinci eksen = j = sütun = x (W)\n",
    "\n",
    "\n",
    "# # # # # meshgrid sadece (H,W) üretir.\n",
    "# # # # # (1,1,H,W) şekli tamamen unsqueeze ile kazandırılıyor.\n",
    "            xg = xx.unsqueeze(0).unsqueeze(0)  # (1,1,H,W)\n",
    "            yg = yy.unsqueeze(0).unsqueeze(0)  # (1,1,H,W)\n",
    "            self._coord_cache[key] = (xg, yg)\n",
    "\n",
    "# Bizim elimizdeki cache ifadesi şuydu :: ::  (1, 1, H, W). Ama forwardda SA'ya eklemek için boyutu böyle yapmamız lazım :: :: (B, 1, H, W).Bunu aşağıdaki kod bloğu yapıyor.\n",
    "        return xg.expand(B, -1, -1, -1), yg.expand(B, -1, -1, -1)\n",
    "## expand ne işe yarıyor :: expand gerçek bir kopyalama yapmaz çoğu zaman.Aynı veriyi “B tane varmış gibi” gösterir.\n",
    "\n",
    "# # # # xg’yi batch boyutunda 1 → B büyütüyor\n",
    "# # # # yg’yi batch boyutunda 1 → B büyütüyor\n",
    "# # # # -1 demek: “o boyutu aynen bırak” demek\n",
    "# # # #  Sonuç: (1,1,H,W) → (B,1,H,W)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        B, C, H, W = x.shape\n",
    "\n",
    "        # Channel squeeze maps\n",
    "        avg_map = torch.mean(x, dim=1, keepdim=True)       # (B,1,H,W)\n",
    "        max_map, _ = torch.max(x, dim=1, keepdim=True)     # (B,1,H,W)\n",
    "\n",
    "        # CoordConv channels\n",
    "        x_coord, y_coord = self._coords(B, H, W, x.device, x.dtype)  # (B,1,H,W) each\n",
    "\n",
    "        # SA input\n",
    "        s = torch.cat([avg_map, max_map, x_coord, y_coord], dim=1)    # (B,4,H,W)\n",
    "\n",
    "        # Router weights\n",
    "        logits = self.router(s).flatten(1)              # (B,K) ## Router, her branch’e ne kadar güveneceğini söylüyor\n",
    "        rw = torch.softmax(logits, dim=1)               # (B,K)\n",
    "\n",
    "        # Branch stack\n",
    "        z = torch.stack([br(s) for br in self.branches], dim=1)  # (B,K,1,H,W) ## Branch’ler, farklı kernel ölçeklerinde maske adayları üretiyor; router da bunları ağırlıklı topluyor.\n",
    "\n",
    "# # # # # # # self.branches içinde K tane branch var.\n",
    "# # # # # # # Her br(s) şunu üretir: (B, 1, H, W)\n",
    "# # # # # # #  Sonra stack(..., dim=1) diyoruz: K tane (B,1,H,W) haritasını bir araya koyuyoruz.\n",
    "############# Sonuç :: z = (B, K, 1, H, W)\n",
    "\n",
    "        wlogit = (rw[:, :, None, None, None] * z).sum(dim=1)   # (B,1,H,W) ## K tane maske adayını tek maske adayına indirmek istiyoruz:\n",
    "\n",
    "# # # rw normalde :: (B,K)\n",
    "# # # Ama z:  (B,K,1,H,W) \n",
    "# # # Çarpabilmek için rw’yi şu şekle sokuyoruz :: (B,K,1,1,1)\n",
    "# # # Bunu da None ile yapıyoruz.\n",
    "# # # None şunu yapar: Boyut ekler (unsqueeze gibi)\n",
    "# # # Yani :: (B,K) → (B,K,1,1,1)\n",
    "# # # # # # .sum(dim=1) ne? == K’yı toplayıp tek harita yapıyoruz :: (B,K,1,H,W) → (B,1,H,W)\n",
    "\n",
    "        # Temperature + gate mask \n",
    "        T = self.get_T()\n",
    "        sa = self.gate_fn(wlogit / T)                   # (B,1,H,W)\n",
    "        y = x * sa\n",
    "\n",
    "        if self.return_router_weights:\n",
    "            return y, sa, rw\n",
    "        return y, sa\n",
    "    \n",
    "# #  y: mask uygulanmış çıktı\n",
    "\n",
    "# #  sa: maskenin kendisi (istersen dışarıda görürsün)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c630b35",
   "metadata": {},
   "source": [
    "## 2) SA bloğu ne yapıyor?\n",
    "\n",
    "Girdi:\n",
    "- `x` ∈ ℝ^(B, C, H, W)\n",
    "\n",
    "Çıktı:\n",
    "- `sa` ∈ ℝ^(B, 1, H, W)  (spatial maske)\n",
    "- `y`  ∈ ℝ^(B, C, H, W)  (yeniden ölçeklenmiş çıktı)\n",
    "\n",
    "Temel fikir:\n",
    "- “Hangi **konumlar** önemli?” sorusuna cevap verir.\n",
    "- Maskeyi **multi-scale** (birden fazla kernel) ve **örnek bazlı** (router ağırlıkları) üretir.\n",
    "- Konum bilgisini iyileştirmek için `CoordConv` (x/y koordinat kanalları) ekler.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a307b8",
   "metadata": {},
   "source": [
    "## 3) Yardımcı fonksiyonlar\n",
    "\n",
    "### 3.1) `_make_odd`\n",
    "Kernel boyutunun tek (odd) olmasını garanti eder.\n",
    "\n",
    "- Tek kernel → simetrik padding daha kolay (merkezli filtre)\n",
    "- Çift kernel → “merkez” belirsizleşir; genelde istenmez\n",
    "\n",
    "Bu fonksiyon, çift gelen kernel’i 1 artırarak tek yapar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b937e9f2",
   "metadata": {},
   "source": [
    "### 3.2) `_softplus_inverse` ve temperature mantığı\n",
    "Learnable temperature gerekiyorsa T’nin pozitif kalması gerekir.\n",
    "\n",
    "- `t_raw` serbest parametredir.\n",
    "- `T = softplus(t_raw) + eps` ile T > 0 garanti edilir.\n",
    "- Başlangıçta verilen `temperature` değerine eşit bir T ile başlatmak için inverse-softplus kullanılır.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e748d33",
   "metadata": {},
   "source": [
    "### 3.3) `_get_gate`\n",
    "`sigmoid` veya `hardsigmoid` seçimi yapar.\n",
    "Amaç: logit uzayından (ℝ) maske uzayına ([0,1]) geçiş.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b331497b",
   "metadata": {},
   "source": [
    "## 4) `_DWPointwiseBranch` (branch yapısı)\n",
    "\n",
    "Her branch tek kanallı bir spatial logit üretir.\n",
    "\n",
    "- Girdi: `s` (B,4,H,W)\n",
    "- Çıkış: (B,1,H,W)\n",
    "\n",
    "İçerik:\n",
    "1) Depthwise Conv: her kanal ayrı filtrelenir (maliyet düşer)\n",
    "2) Pointwise Conv: kanalları 1 kanala indirger\n",
    "\n",
    "Bu yapı, kernel havuzunu genişletirken maliyeti kontrol eder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a746ee5",
   "metadata": {},
   "source": [
    "## 5) `__init__`: Branch havuzu (multi-scale)\n",
    "\n",
    "- `kernels=(3,5,7,...)` -> her biri için bir branch\n",
    "- `use_dilated=True` -> ek bir dilated branch\n",
    "\n",
    "`_make_odd`:\n",
    "- kernel çiftse 1 artırılır\n",
    "\n",
    "Dilation branch:\n",
    "- `pad = dilation*(k-1)//2` ile çıktı boyutu korunur.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0e0e31",
   "metadata": {},
   "source": [
    "## 6) `__init__`: Router\n",
    "\n",
    "Router’ın görevi:\n",
    "- her örnek için branch ağırlıklarını (B,K) üretmek\n",
    "\n",
    "Akış:\n",
    "- `AdaptiveAvgPool2d(1)` -> (B,4,1,1) global özet\n",
    "- `Conv(4->hidden)` + ReLU\n",
    "- `Conv(hidden->K)` -> (B,K,1,1) -> flatten -> (B,K)\n",
    "- softmax -> `rw` (B,K), satır toplamı 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b44de81",
   "metadata": {},
   "source": [
    "## 7) CoordConv grid (`_coords`) ve cache\n",
    "\n",
    "`_coords`:\n",
    "- x ve y koordinat gridlerini üretir.\n",
    "- `coord_norm`:\n",
    "  - `minus1to1` -> [-1,1]\n",
    "  - `0to1` -> [0,1]\n",
    "\n",
    "Cache:\n",
    "- aynı (H,W,device,dtype,norm) için grid tekrar üretilmez.\n",
    "- Bu performans içindir; doğruluğu değiştirmez.\n",
    "\n",
    "Önemli: grid `x.device` ve `x.dtype` ile üretilir, dtype/device mismatch engellenir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892fe63b",
   "metadata": {},
   "source": [
    "## 8) `forward(x)` — adım adım\n",
    "\n",
    "### 8.1) Kanal özet haritaları\n",
    "- `avg_map = mean(x, dim=1)` -> (B,1,H,W)\n",
    "- `max_map = max(x, dim=1)`  -> (B,1,H,W)\n",
    "\n",
    "Bu iki harita, her konumda kanal aktivasyonlarının özetidir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad89ac52",
   "metadata": {},
   "source": [
    "### 8.2) CoordConv ekleme ve SA girişi\n",
    "- `x_coord, y_coord` -> (B,1,H,W)\n",
    "- `s = cat([avg_map, max_map, x_coord, y_coord])` -> (B,4,H,W)\n",
    "\n",
    "Burada amaç:\n",
    "- maske üretiminin konum bilgisini doğrudan kullanabilmesi.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a19d207",
   "metadata": {},
   "source": [
    "### 8.3) Router ağırlıkları\n",
    "- `logits = router(s).flatten(1)` -> (B,K)\n",
    "- `rw = softmax(logits, dim=1)`   -> (B,K)\n",
    "\n",
    "`logits` ağırlık değildir; normalize edilince `rw` olur.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a6924b",
   "metadata": {},
   "source": [
    "### 8.4) Branch çıktıları ve ağırlıklı birleşim\n",
    "\n",
    "- Her branch: `br(s)` -> (B,1,H,W)\n",
    "- stack: `z` -> (B,K,1,H,W)\n",
    "\n",
    "Ağırlıklı toplama:\n",
    "- `rw` (B,K) -> broadcast ile (B,K,1,1,1)\n",
    "- `wlogit = sum_k rw_k * z_k` -> (B,1,H,W)\n",
    "\n",
    "Bu, örnek bazlı multi-scale birleşimidir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bd1d84",
   "metadata": {},
   "source": [
    "### 8.5) Temperature + gate + uygulama\n",
    "- `sa = gate(wlogit / T)` -> (B,1,H,W)\n",
    "- `y = x * sa` -> (B,C,H,W)\n",
    "\n",
    "CA’dan fark:\n",
    "- CA kanal bazlı (B,C,1,1)\n",
    "- SA konum bazlı (B,1,H,W)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda7aeff",
   "metadata": {},
   "source": [
    "## 9) Şekil özeti\n",
    "\n",
    "- `s`: (B,4,H,W)\n",
    "- `rw`: (B,K)\n",
    "- `z`: (B,K,1,H,W)\n",
    "- `wlogit`: (B,1,H,W)\n",
    "- `sa`: (B,1,H,W)\n",
    "- `y`: (B,C,H,W)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
