{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0a86f10",
   "metadata": {},
   "source": [
    "# ChannelAttentionFusionT — En İnce Detayına Kadar Yorum\n",
    "\n",
    "Bu not defteri **yalnızca** `ChannelAttentionFusionT` kodunun açıklamasıdır.\n",
    "\n",
    "Hedef: Kodun her satırının **ne yaptığını**, hangi tensör şekillerini ürettiğini, ve tasarım tercihinin **neden** böyle olduğunu açık şekilde ortaya koymak.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3776f12e",
   "metadata": {},
   "source": [
    "## 1) Kod (Referans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d78e861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def _softplus_inverse(y: torch.Tensor, eps: float = 1e-6) -> torch.Tensor:\n",
    "    # softplus(x) = log(1 + exp(x))  ->  inverse: x = log(exp(y) - 1)\n",
    "    return torch.log(torch.clamp(torch.exp(y) - 1.0, min=eps))\n",
    "\n",
    "\n",
    "def _get_gate(gate: str):\n",
    "    g = gate.lower()\n",
    "    if g == \"sigmoid\":\n",
    "        return torch.sigmoid\n",
    "    if g == \"hardsigmoid\":\n",
    "        return F.hardsigmoid\n",
    "    raise ValueError(\"gate 'sigmoid' veya 'hardsigmoid' olmalı.\")\n",
    "\n",
    "\n",
    "def _get_act(act: str):\n",
    "    a = act.lower()\n",
    "    if a == \"relu\":\n",
    "        return nn.ReLU(inplace=True)\n",
    "    if a == \"silu\":\n",
    "        return nn.SiLU(inplace=True)\n",
    "    raise ValueError(\"act 'relu' veya 'silu' olmalı.\")\n",
    "\n",
    "\n",
    "class ChannelAttentionFusionT(nn.Module):\n",
    "    \"\"\"\n",
    "    - Sample-wise fusion: avg vs max weights are produced per-sample (B,2) via fusion_router\n",
    "    - Temperature scaling: optional learnable temperature via inverse-softplus parameterization\n",
    "    - Debug: if return_fusion_weights=True, forward returns (y, ca, fusion_w) where fusion_w is (B,2)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels: int,\n",
    "        reduction: int = 16,\n",
    "        min_hidden: int = 4,\n",
    "        fusion: str = \"softmax\",        # \"sum\" | \"softmax\"\n",
    "        gate: str = \"sigmoid\",          # \"sigmoid\" | \"hardsigmoid\"\n",
    "        temperature: float = 1.0,\n",
    "        learnable_temperature: bool = False,\n",
    "        eps: float = 1e-6,\n",
    "        act: str = \"relu\",\n",
    "        bias: bool = True,\n",
    "        fusion_router_hidden: int = 16,   # router hidden for sample-wise fusion\n",
    "        return_fusion_weights: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if fusion not in (\"sum\", \"softmax\"):\n",
    "            raise ValueError(\"fusion 'sum' veya 'softmax' olmalı.\")\n",
    "        if temperature <= 0:\n",
    "            raise ValueError(\"temperature pozitif olmalı.\")\n",
    "        if fusion_router_hidden < 1:\n",
    "            raise ValueError(\"fusion_router_hidden >= 1 olmalı.\")\n",
    "\n",
    "        self.eps = float(eps)\n",
    "        self.fusion = fusion\n",
    "        self.return_fusion_weights = bool(return_fusion_weights)\n",
    "\n",
    "        self.gate_fn = _get_gate(gate)\n",
    "\n",
    "        hidden = max(int(min_hidden), int(channels) // int(reduction))\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "\n",
    "        self.fc1 = nn.Conv2d(channels, hidden, kernel_size=1, bias=bias)\n",
    "        self.act = _get_act(act)\n",
    "        self.fc2 = nn.Conv2d(hidden, channels, kernel_size=1, bias=bias)\n",
    "\n",
    "        # Sample-wise fusion router (only used if fusion=\"softmax\")\n",
    "        # Input: cat([avg_s, max_s]) -> (B,2C,1,1)  Output: (B,2,1,1) -> flatten -> (B,2)\n",
    "        if self.fusion == \"softmax\":\n",
    "            self.fusion_router = nn.Sequential(\n",
    "                nn.Conv2d(2 * channels, fusion_router_hidden, kernel_size=1, bias=True),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(fusion_router_hidden, 2, kernel_size=1, bias=True),\n",
    "            )\n",
    "        else:\n",
    "            self.fusion_router = None\n",
    "\n",
    "        # Temperature (optional learnable)\n",
    "        self.learnable_temperature = bool(learnable_temperature)\n",
    "        if self.learnable_temperature:\n",
    "            t0 = torch.tensor(float(temperature))\n",
    "            t_inv = _softplus_inverse(t0, eps=self.eps)\n",
    "            self.t_raw = nn.Parameter(t_inv)\n",
    "        else:\n",
    "            self.register_buffer(\"T\", torch.tensor(float(temperature)))\n",
    "\n",
    "    def get_T(self) -> torch.Tensor:\n",
    "        if self.learnable_temperature:\n",
    "            return F.softplus(self.t_raw) + self.eps\n",
    "        return self.T\n",
    "\n",
    "    def mlp(self, s: torch.Tensor) -> torch.Tensor:\n",
    "        return self.fc2(self.act(self.fc1(s)))\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # Squeeze\n",
    "        avg_s = self.avg_pool(x)  # (B,C,1,1)\n",
    "        max_s = self.max_pool(x)  # (B,C,1,1)\n",
    "\n",
    "        # Excitation (shared MLP)\n",
    "        a = self.mlp(avg_s)       # (B,C,1,1)\n",
    "        m = self.mlp(max_s)       # (B,C,1,1)\n",
    "\n",
    "        fusion_w = None\n",
    "        if self.fusion == \"sum\":\n",
    "            z = a + m\n",
    "        else:\n",
    "            # Sample-wise fusion weights\n",
    "            s_cat = torch.cat([avg_s, max_s], dim=1)          # (B,2C,1,1) # Bu “tek kanala indirmek” değil; C’yi 2C yapıp daha fazla bilgi vermek.\n",
    "            logits = self.fusion_router(s_cat).flatten(1)     # (B,2)\n",
    "            #self.fusion_router(s_cat) çıktısı: şekil olarak (B, 2, 1, 1) gelir (çünkü son conv -> 2)\n",
    "\n",
    "# Bu logits dediğimiz değerler ağırlık değil.\n",
    "# Bunlar “ham skor”. Örn:\n",
    "\n",
    "# logits[b] = [2.3, 0.7] olabilir\n",
    "\n",
    "# bu “avg daha iyi” gibi bir eğilim taşır ama daha [0,1] aralığında değil, toplamı 1 değil.\n",
    "\n",
    "            fusion_w = torch.softmax(logits, dim=1)           # (B,2)\n",
    "\n",
    "# fusion_router softmax değil.\n",
    "\n",
    "# fusion_router → logit üretir.\n",
    "\n",
    "# torch.softmax(logits) → ağırlığa çevirir.\n",
    "\n",
    "# Sonra bu ağırlıklarla a ve m karıştırılır.\n",
    "\n",
    "            z = fusion_w[:, 0].view(-1, 1, 1, 1) * a + fusion_w[:, 1].view(-1, 1, 1, 1) * m\n",
    "\n",
    "# # # # # Biz CA bloğunda iki ayrı “kanal önem skoru” üretiyoruz:\n",
    "\n",
    "# # # # # a = mlp(avg_s) → avg tabanlı kanal logitleri (B, C, 1, 1)\n",
    "\n",
    "# # # # # m = mlp(max_s) → max tabanlı kanal logitleri (B, C, 1, 1)\n",
    "\n",
    "# # # # # Bu ikisi aynı şeyi farklı açıdan anlatıyor:\n",
    "\n",
    "# # # # # avg_s: “genel aktivasyon seviyesi” (dağınık/ortalama bilgi)\n",
    "\n",
    "# # # # # max_s: “en güçlü aktivasyon” (pik/tepe bilgi)\n",
    "\n",
    "# # # # # Ama her görüntüde hangisi daha güvenilir sinyal? Aynı değil.\n",
    "\n",
    "# a: avg yolundan gelen kanal logitleri (B,C,1,1)\n",
    "\n",
    "# m: max yolundan gelen kanal logitleri (B,C,1,1)\n",
    "\n",
    "# fusion_w[:,0]: (B,) → sadece avg ağırlığı\n",
    "\n",
    "# fusion_w[:,1]: (B,) → sadece max ağırlığı\n",
    "\n",
    "        # Temperature-scaled gating\n",
    "        T = self.get_T()\n",
    "        ca = self.gate_fn(z / T)  # (B,C,1,1)\n",
    "        y = x * ca ## x.shape = (B, C, H, W)  ##  ca.shape = (B, C, 1, 1) \n",
    "## Her piksel, kendi kanalının katsayısıyla çarpılıyor. ca → (B, C, 1, 1)  ## otomatik olarak → (B, C, H, W) gibi davranıyor\n",
    "\n",
    "# # ca = ses açma/kısma düğmesi\n",
    "\n",
    "# # Kanal 0: ses %90 açık\n",
    "\n",
    "# # Kanal 1: ses %10 açık\n",
    "\n",
    "# # Kanal 2: ses %70 açık\n",
    "\n",
    "# # Kanal 3: neredeyse kapalı\n",
    "\n",
    "# # y = x * ca tam olarak miksaj masası gibi çalışıyor.\n",
    "\n",
    "        if self.return_fusion_weights and (fusion_w is not None):\n",
    "            return y, ca, fusion_w\n",
    "        return y, ca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3b4bc7",
   "metadata": {},
   "source": [
    "## 2) Bu modül ne yapıyor?\n",
    "\n",
    "Girdi bir özellik haritasıdır:\n",
    "\n",
    "- `x`: **(B, C, H, W)**\n",
    "\n",
    "Çıktı iki parçadan oluşur:\n",
    "\n",
    "- `ca`: kanal maskesi **(B, C, 1, 1)**\n",
    "- `y`: yeniden ölçeklenmiş çıktı **(B, C, H, W)**\n",
    "\n",
    "Temel formül:\n",
    "\n",
    "1. Kanal istatistiklerini çıkar: `avg_s`, `max_s`\n",
    "2. Bu istatistikleri küçük bir MLP ile kanal logitlerine çevir: `a`, `m`\n",
    "3. `a` ve `m`’yi birleştir: `z`\n",
    "4. Temperature ile ölçekle: `z / T`\n",
    "5. Gate ile [0,1] aralığına taşı: `ca = gate(z / T)`\n",
    "6. Uygula: `y = x * ca`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571a52c8",
   "metadata": {},
   "source": [
    "## 3) İçe aktarımlar (imports)\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "```\n",
    "\n",
    "- `torch`: tensör işlemleri\n",
    "- `nn`: katmanlar ve `nn.Module` altyapısı\n",
    "- `F`: fonksiyonel API (ör. `softplus`, `hardsigmoid`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b43727",
   "metadata": {},
   "source": [
    "## 4) `_softplus_inverse` neden var?\n",
    "\n",
    "### Problem: Learnable temperature’ın pozitif kalması gerekir\n",
    "Temperature (T) bir bölende kullanıldığı için:\n",
    "- T ≤ 0 olursa matematiksel ve sayısal sorun çıkar.\n",
    "\n",
    "### Çözüm: `T = softplus(t_raw) + eps`\n",
    "- `softplus(·)` çıktısı **daima pozitiftir**.\n",
    "- Böylece `t_raw` serbest (negatif de olabilir), fakat T her zaman > 0.\n",
    "\n",
    "### Neden inverse?\n",
    "Başlangıçta T’nin, kullanıcıdan gelen `temperature` değerine eşit olması istenir.  \n",
    "Bu yüzden `t_raw` şu koşulu sağlayacak şekilde başlatılır:\n",
    "\n",
    "- `softplus(t_raw) ≈ temperature`\n",
    "\n",
    "Bunu sağlayan dönüşüm inverse-softplus’tır:\n",
    "\n",
    "- `t_raw = log(exp(T) - 1)`\n",
    "\n",
    "### `clamp(..., min=eps)` niye var?\n",
    "`exp(T) - 1` küçük T değerlerinde sayısal olarak 0’a yaklaşabilir.  \n",
    "Log içine 0 girmesin diye alt sınır uygulanır.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee8062f",
   "metadata": {},
   "source": [
    "## 5) `_get_gate` ne yapıyor?\n",
    "\n",
    "Bu fonksiyon, `gate` parametresine göre attention maskesinin aktivasyonunu seçer:\n",
    "\n",
    "- `\"sigmoid\"` → `torch.sigmoid`\n",
    "- `\"hardsigmoid\"` → `F.hardsigmoid`\n",
    "\n",
    "Maskeyi üretirken amaç:\n",
    "- logitleri [0,1] aralığına taşımak,\n",
    "- böylece kanal katsayısı gibi kullanabilmek.\n",
    "\n",
    "Geçersiz string gelirse `ValueError` fırlatır. Bu, hatalı konfigürasyonların eğitim başlamadan yakalanması içindir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684552c8",
   "metadata": {},
   "source": [
    "## 6) `_get_act` ne yapıyor?\n",
    "\n",
    "Bu fonksiyon MLP içindeki aktivasyonu seçer:\n",
    "\n",
    "- `\"relu\"` → `nn.ReLU(inplace=True)`\n",
    "- `\"silu\"` → `nn.SiLU(inplace=True)`\n",
    "\n",
    "`inplace=True`:\n",
    "- bellek kullanımını düşürebilir,\n",
    "- ancak bazı karma graf senaryolarında debug zorlaştırabilir. Burada tipik kullanım için uygundur.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e275558b",
   "metadata": {},
   "source": [
    "## 7) Sınıf başlığı ve docstring\n",
    "\n",
    "`ChannelAttentionFusionT(nn.Module)` bir PyTorch modülüdür.\n",
    "\n",
    "Docstring’in söylediği üç temel özellik:\n",
    "\n",
    "1. **Sample-wise fusion**: avg ve max katkıları her örnek için ayrı öğrenilir (B,2).\n",
    "2. **Temperature scaling**: gating öncesi logit ölçeği T ile kontrol edilir; T opsiyonel öğrenilebilir.\n",
    "3. **Debug**: istenirse `fusion_w` geri verilir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25edc60f",
   "metadata": {},
   "source": [
    "## 8) `__init__` parametreleri (ne işe yarar?)\n",
    "\n",
    "- `channels`: C\n",
    "- `reduction`: MLP daraltma oranı; hidden yaklaşık `C/reduction`\n",
    "- `min_hidden`: hidden için alt sınır; çok küçülmeyi engeller\n",
    "- `fusion`: `\"sum\"` veya `\"softmax\"`\n",
    "- `gate`: sigmoid türü\n",
    "- `temperature`: başlangıç sıcaklığı\n",
    "- `learnable_temperature`: T öğrenilsin mi?\n",
    "- `eps`: sayısal stabilite\n",
    "- `act`: MLP aktivasyonu\n",
    "- `bias`: MLP conv’larında bias\n",
    "- `fusion_router_hidden`: fusion router ara kanal boyutu\n",
    "- `return_fusion_weights`: debug çıktısı\n",
    "\n",
    "Bu parametreler hem kapasiteyi (hidden/router_hidden), hem davranışı (fusion/gate), hem de stabiliteyi (temperature/eps) belirler.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1516084c",
   "metadata": {},
   "source": [
    "## 9) `__init__`: Validasyon blokları\n",
    "\n",
    "```python\n",
    "if fusion not in (\"sum\", \"softmax\"):\n",
    "    ...\n",
    "if temperature <= 0:\n",
    "    ...\n",
    "if fusion_router_hidden < 1:\n",
    "    ...\n",
    "```\n",
    "\n",
    "Bu kontrollerin amacı:\n",
    "- yanlış seçimlerin (örn. temperature=0) eğitim sırasında NaN üretmesine engel olmak,\n",
    "- konfigürasyonu “fail fast” prensibiyle erken aşamada durdurmak.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978f6224",
   "metadata": {},
   "source": [
    "## 10) `hidden` hesabı (MLP kapasitesi)\n",
    "\n",
    "```python\n",
    "hidden = max(min_hidden, channels // reduction)\n",
    "```\n",
    "\n",
    "- `channels // reduction`: SE/CBAM geleneğindeki daraltma\n",
    "- `min_hidden`: çok küçük kanal sayılarında hidden’ın 0-1 gibi anlamsız değerlere düşmesini engeller\n",
    "\n",
    "Sonuç:\n",
    "- Küçük C’de bile MLP tamamen “nefessiz” kalmaz,\n",
    "- büyük C’de parametre kontrol altında kalır.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed63fd9",
   "metadata": {},
   "source": [
    "## 11) Squeeze katmanları: neden avg ve max?\n",
    "\n",
    "```python\n",
    "self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "```\n",
    "\n",
    "Squeeze çıktıları:\n",
    "\n",
    "- `avg_s`: (B,C,1,1) — ortalama aktivasyon\n",
    "- `max_s`: (B,C,1,1) — en güçlü aktivasyon\n",
    "\n",
    "İki istatistiğin birlikte kullanılması:\n",
    "- düz/dağınık aktivasyonlarla (avg) tepe aktivasyonları (max) ayrıştırmaya yardımcı olur.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac6bd95",
   "metadata": {},
   "source": [
    "## 12) MLP (Excitation) katmanları\n",
    "\n",
    "```python\n",
    "self.fc1 = nn.Conv2d(C, hidden, 1)\n",
    "self.act = ...\n",
    "self.fc2 = nn.Conv2d(hidden, C, 1)\n",
    "```\n",
    "\n",
    "Neden `Conv2d(..., kernel_size=1)`?\n",
    "- Squeeze sonrası tensör 1×1 olduğundan bu yapı efektif olarak “fully-connected” ile aynı işi yapar,\n",
    "- ama PyTorch’ta kanal ekseninde pratik ve hızlıdır.\n",
    "\n",
    "Bias:\n",
    "- `bias` parametresiyle kontrol edilir.\n",
    "- Bazı tasarımlarda bias maske logitlerinin ofsetini kolaylaştırır.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34835ec4",
   "metadata": {},
   "source": [
    "## 13) Sample-wise fusion router (kritik ek)\n",
    "\n",
    "Bu router yalnızca `fusion=\"softmax\"` iken kurulur:\n",
    "\n",
    "```python\n",
    "Conv2d(2C -> H) + ReLU + Conv2d(H -> 2)\n",
    "```\n",
    "\n",
    "**Girdi:** `cat([avg_s, max_s])` = (B,2C,1,1)  \n",
    "**Çıktı:** (B,2,1,1) → flatten → (B,2)\n",
    "\n",
    "Bu 2 logit:\n",
    "- `w_avg`, `w_max` benzeri iki ağırlığın logitidir.\n",
    "Softmax ile:\n",
    "- her örnek için `w_avg + w_max = 1` olur.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91ba95e",
   "metadata": {},
   "source": [
    "## 14) Temperature kurulumu: parametre mi buffer mı?\n",
    "\n",
    "### Learnable ise:\n",
    "- `self.t_raw = nn.Parameter(...)`\n",
    "- Gerçek temperature: `softplus(self.t_raw) + eps`\n",
    "\n",
    "### Sabit ise:\n",
    "- `self.register_buffer(\"T\", ...)`\n",
    "\n",
    "**Buffer olması ne demek?**\n",
    "- Optimizer güncellemez.\n",
    "- `state_dict` içine girer (model kaydederken T de kaydedilir).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8477d128",
   "metadata": {},
   "source": [
    "## 15) `get_T()` ayrıntısı\n",
    "\n",
    "```python\n",
    "if learnable:\n",
    "    return softplus(t_raw) + eps\n",
    "else:\n",
    "    return T\n",
    "```\n",
    "\n",
    "Burada `eps` eklenmesi, T’nin 0’a yaklaşmasını engelleyerek `z/T` oranının aşırı büyümesini azaltır.\n",
    "\n",
    "Bu, maskenin aşırı saturasyona gitmesini tamamen engellemez; ancak sayısal patlamayı azaltır.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10d43c8",
   "metadata": {},
   "source": [
    "## 16) `mlp(s)` ne bekler?\n",
    "\n",
    "- `s` şekli: (B,C,1,1)\n",
    "- dönüş: (B,C,1,1)\n",
    "\n",
    "Bu fonksiyon aynı MLP’yi hem avg hem max squeeze için kullanır:\n",
    "\n",
    "- parametre paylaşımı vardır,\n",
    "- iki squeeze kaynağı aynı “kanal ilişkileri” uzayında işlenir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a25980",
   "metadata": {},
   "source": [
    "## 17) `forward(x)` — adım adım\n",
    "\n",
    "### 17.1) Squeeze\n",
    "```python\n",
    "avg_s = avg_pool(x)  # (B,C,1,1)\n",
    "max_s = max_pool(x)  # (B,C,1,1)\n",
    "```\n",
    "\n",
    "### 17.2) Excitation\n",
    "```python\n",
    "a = mlp(avg_s)  # (B,C,1,1)\n",
    "m = mlp(max_s)  # (B,C,1,1)\n",
    "```\n",
    "\n",
    "Bu noktada `a` ve `m` gate öncesi logitlerdir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4e8954",
   "metadata": {},
   "source": [
    "## 18) Fusion davranışı\n",
    "\n",
    "### 18.1) `fusion=\"sum\"`\n",
    "```python\n",
    "z = a + m\n",
    "```\n",
    "- iki kaynak eşit önemlidir.\n",
    "\n",
    "### 18.2) `fusion=\"softmax\"`\n",
    "Router üzerinden örnek-bazlı ağırlık üretilir:\n",
    "\n",
    "```python\n",
    "s_cat = cat([avg_s, max_s])      # (B,2C,1,1)\n",
    "logits = fusion_router(s_cat)    # (B,2,1,1) -> flatten -> (B,2)\n",
    "fusion_w = softmax(logits, dim=1)# (B,2)\n",
    "z = w0*a + w1*m\n",
    "```\n",
    "\n",
    "`view(-1,1,1,1)`:\n",
    "- (B,) ağırlığını (B,1,1,1)’e çevirir,\n",
    "- broadcasting ile (B,C,1,1) ile çarpılabilir hale getirir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8ca607",
   "metadata": {},
   "source": [
    "## 19) Temperature + Gate + Uygulama\n",
    "\n",
    "```python\n",
    "T = get_T()\n",
    "ca = gate_fn(z / T)  # (B,C,1,1)\n",
    "y = x * ca           # (B,C,H,W)\n",
    "```\n",
    "\n",
    "- `z/T`: logit ölçeğini ayarlar.\n",
    "- `gate_fn`: maskeyi [0,1] aralığına taşır.\n",
    "- `x * ca`: kanal bazında ölçekleme uygular (ca spatial boyutta broadcast edilir).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312a2bbd",
   "metadata": {},
   "source": [
    "## 20) Debug çıktısı\n",
    "\n",
    "```python\n",
    "if return_fusion_weights and fusion_w is not None:\n",
    "    return y, ca, fusion_w\n",
    "return y, ca\n",
    "```\n",
    "\n",
    "- `fusion=\"sum\"` ise `fusion_w` yoktur (None).\n",
    "- `fusion=\"softmax\"` ise `fusion_w` (B,2) döner.\n",
    "\n",
    "Bu çıktı, router davranışını izlemek içindir:\n",
    "- hep avg’ye yapışma mı var?\n",
    "- hep max mi?\n",
    "- örnekler arasında değişiyor mu?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5bc543",
   "metadata": {},
   "source": [
    "## 21) İnce Riskler ve Kodun Örtük Varsayımları\n",
    "\n",
    "1. **Girdi 4D olmalı (B,C,H,W)**  \n",
    "   Pooling ve Conv2d buna göre çalışır.\n",
    "\n",
    "2. **Router girişi “squeeze” çıktılarıdır (avg_s, max_s)**  \n",
    "   Router, MLP sonrası `a,m` yerine squeeze’i kullanır. Bu, karar mekanizmasının “ham istatistiklere” dayanması demektir.\n",
    "\n",
    "3. **Saturasyon riski**  \n",
    "   `sigmoid` büyük |z/T| değerlerinde 0/1’e yapışır. Temperature bunu yumuşatabilir; ancak tek başına garantili çözüm değildir.\n",
    "\n",
    "4. **Örnek-bazlı ağırlıklar**  \n",
    "   `fusion_w` softmax olduğu için her örnekte iki ağırlığın toplamı 1’dir. Bu, ölçek patlamasını sınırlayan bir normalizasyondur.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20297b94",
   "metadata": {},
   "source": [
    "## 22) Çıkış şekilleri (hızlı kontrol)\n",
    "\n",
    "- `x`: (B,C,H,W)\n",
    "- `avg_s`, `max_s`: (B,C,1,1)\n",
    "- `a`, `m`: (B,C,1,1)\n",
    "- `fusion_w` (softmax modunda): (B,2)\n",
    "- `z`: (B,C,1,1)\n",
    "- `ca`: (B,C,1,1)\n",
    "- `y`: (B,C,H,W)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
