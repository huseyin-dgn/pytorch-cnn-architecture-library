{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dcdf15b",
   "metadata": {},
   "source": [
    "# Residual Bloklar: Wide, Pre-Act, Post-Act, Bottleneck(Expansion), ResNeXt Grouped\n",
    "\n",
    "Bu notebook; aşağıdaki residual blok varyantlarını **kısa ama net** şekilde açıklar ve her biri için **PyTorch örnek implementasyon iskeleti** verir:\n",
    "- **Wide** (Wide ResNet yaklaşımı)\n",
    "- **Post-Activation** (orijinal ResNet bloğu)\n",
    "- **Pre-Activation** (ResNet v2)\n",
    "- **Bottleneck + Expansion** (ResNet-50/101 tarzı)\n",
    "- **ResNeXt Grouped Bottleneck** (cardinality / grouped conv)\n",
    "\n",
    "> Not: Kodlar “notluk” yazıldı: okunabilirlik ve kavramı oturtma amaçlıdır."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5d7e07",
   "metadata": {},
   "source": [
    "## 1) Kısa Kavramlar\n",
    "- **Residual/skip connection:** `y = F(x) + x` (boyutlar uyuyorsa).\n",
    "- **Projection shortcut:** Boyut/kanal değişiyorsa `1x1 conv` ile `x` dönüştürülür.\n",
    "- **Activation yeri:** Pre-Act vs Post-Act farkının özü burasıdır.\n",
    "- **Expansion:** Bottleneck blokta çıkış kanalını büyütme oranı (genelde `4`).\n",
    "- **Groups:** Grouped convolution ile kanal gruplarını ayrı ayrı işler (ResNeXt)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bcb2de",
   "metadata": {},
   "source": [
    "## 2) Wide Residual Block (Wide ResNet yaklaşımı)\n",
    "**Temel fikir:** Derinliği artırmak yerine **kanal genişliğini (width)** artır.\n",
    "\n",
    "**Ne değişir?**\n",
    "- Aynı blok yapısı korunabilir (basic residual), ama `out_channels` daha büyük seçilir.\n",
    "- Çoğu pratikte: daha az derinlik + daha geniş katmanlar → daha stabil eğitim.\n",
    "\n",
    "**Artı/Eksi:**\n",
    "- ✅ Daha stabil/kolay optimize\n",
    "- ❌ Parametre ve hesap maliyeti artar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccb72d2",
   "metadata": {},
   "source": [
    "## 3) Post-Activation Residual Block (ResNet v1)\n",
    "**Akış (tipik):**\n",
    "1) `Conv → BN → ReLU → Conv → BN`\n",
    "2) `+ shortcut`\n",
    "3) `ReLU` (toplamadan sonra)\n",
    "\n",
    "**Öz:** Aktivasyon **toplamadan sonra** gelir. Orijinal ResNet tasarımı bu şekildedir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501d6416",
   "metadata": {},
   "source": [
    "## 4) Pre-Activation Residual Block (ResNet v2)\n",
    "**Akış (tipik):**\n",
    "1) `BN → ReLU → Conv → BN → ReLU → Conv`\n",
    "2) `+ shortcut`\n",
    "\n",
    "**Öz:** BN+ReLU **konvolüsyondan önce** gelir; toplama sonrası ayrıca ReLU şart değildir.\n",
    "\n",
    "**Neden önemli?**\n",
    "- Skip path üzerinden gradient daha “temiz” akar.\n",
    "- Çok derin ağlarda optimizasyonu kolaylaştırır."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec946ba",
   "metadata": {},
   "source": [
    "## 5) Bottleneck (with Expansion)\n",
    "**Amaç:** Hesap maliyetini düşürürken temsil gücünü korumak.\n",
    "\n",
    "**3 katmanlı yapı:**\n",
    "- `1x1` **reduce** (kanalı düşür)\n",
    "- `3x3` **process**\n",
    "- `1x1` **expand** (kanalı büyüt)\n",
    "\n",
    "**Expansion:** Çıkış kanalını `bottleneck_ch * expansion` yapar. ResNet-50/101’de çoğunlukla `expansion=4`.\n",
    "\n",
    "**Örnek:**\n",
    "- bottleneck_ch=64, expansion=4 → block çıkışı 256 kanal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e5ffe8",
   "metadata": {},
   "source": [
    "## 6) ResNeXt Grouped Residual Conv (Grouped Bottleneck)\n",
    "**ResNeXt fikri:** Bottleneck’in ortasındaki `3x3` katmanı **grouped convolution** yap.\n",
    "\n",
    "**Cardinality (groups):**\n",
    "- Derinlik/width yerine “grup sayısını” artırarak kapasiteyi büyütür.\n",
    "\n",
    "**Öz:**\n",
    "- `1x1 reduce` → `3x3 grouped conv (groups=C)` → `1x1 expand`\n",
    "\n",
    "**Artı/Eksi:**\n",
    "- ✅ Benzer FLOPs ile daha güçlü temsil (pratikte iyi)\n",
    "- ❌ Grouped conv donanım/implementasyona göre değişken hız"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b899dd97",
   "metadata": {},
   "source": [
    "## 7) Tek Bakışta Özet Tablo\n",
    "\n",
    "| Blok | Aktivasyon Konumu | İç Yapı | Boyut Eşleme | Tipik Kullanım | Ana Fikir |\n",
    "|---|---|---|---|---|---|\n",
    "| **Wide** | (bloka bağlı) | Genelde Basic/PreAct Basic | Gerekirse 1x1 projection | WideResNet varyantları | Derinlik yerine **kanal genişliği** |\n",
    "| **Post-Act (v1)** | Toplamadan **sonra** ReLU | Conv-BN-ReLU-Conv-BN + Add + ReLU | 1x1 projection opsiyonel | ResNet-18/34/50 (orijinal) | Klasik residual akış |\n",
    "| **Pre-Act (v2)** | Conv’lardan **önce** BN+ReLU | BN-ReLU-Conv-BN-ReLU-Conv + Add | 1x1 projection opsiyonel (çoğu projeksiyon da preact’e uyar) | ResNet v2, çok derin ağlar | Daha temiz gradient akışı |\n",
    "| **Bottleneck + Expansion** | v1 veya v2 tasarımla | 1x1 reduce → 3x3 → 1x1 expand | Sık kullanılır (stride/kanal değişimi) | ResNet-50/101/152 | Ucuz hesapla güçlü temsil |\n",
    "| **ResNeXt Grouped** | v1 veya v2 tasarımla | 1x1 → 3x3 **groups** → 1x1 | Aynı | ResNeXt-50/101 | **Cardinality** ile kapasite |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599efc74",
   "metadata": {},
   "source": [
    "## 8) PyTorch: Ortak Yardımcılar\n",
    "Aşağıda blokları yazarken tekrar etmemek için küçük yardımcı fonksiyonlar var."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e7b2fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Optional, Callable\n",
    "\n",
    "def conv3x3(in_ch: int, out_ch: int, stride: int = 1, groups: int = 1) -> nn.Conv2d:\n",
    "    # 3x3 conv: padding=1 ile uzamsal boyut korunur (stride=1 ise)\n",
    "    return nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=stride, padding=1, bias=False, groups=groups)\n",
    "\n",
    "def conv1x1(in_ch: int, out_ch: int, stride: int = 1) -> nn.Conv2d:\n",
    "    # 1x1 conv: kanal eşleme / projeksiyon için\n",
    "    return nn.Conv2d(in_ch, out_ch, kernel_size=1, stride=stride, padding=0, bias=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04beb72c",
   "metadata": {},
   "source": [
    "## 9) Post-Activation Basic Residual Block (ResNet v1)\n",
    "Bu, ResNet-18/34 tarzı **basic** bloktur.\n",
    "- Aktivasyon: **Add’den sonra** ReLU\n",
    "- Boyut değişirse: shortcut için `1x1 conv` projeksiyon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e305fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlockPostAct(nn.Module):\n",
    "    expansion = 1  # basic block çıkış kanalı = out_ch * expansion\n",
    "\n",
    "    def __init__(self, in_ch: int, out_ch: int, stride: int = 1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = conv3x3(in_ch, out_ch, stride=stride)\n",
    "        self.bn1   = nn.BatchNorm2d(out_ch)\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = conv3x3(out_ch, out_ch, stride=1)\n",
    "        self.bn2   = nn.BatchNorm2d(out_ch)\n",
    "\n",
    "        # shortcut: boyut/kanal değişiyorsa 1x1 projection gerekir\n",
    "        self.downsample = None\n",
    "        if stride != 1 or in_ch != out_ch:\n",
    "            self.downsample = nn.Sequential(\n",
    "                conv1x1(in_ch, out_ch, stride=stride),\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "            )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out = out + identity\n",
    "        out = self.relu(out)  # <-- Post-Act farkı: ReLU burada\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64fdaf9",
   "metadata": {},
   "source": [
    "## 10) Pre-Activation Basic Residual Block (ResNet v2)\n",
    "Bu da basic block ama **BN+ReLU conv'dan önce**.\n",
    "- Çoğu tasarımda add sonrası ekstra ReLU gerekmez.\n",
    "- Downsample (projection) yapılacaksa pre-activation çıkışından beslemek yaygındır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2bce18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlockPreAct(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_ch: int, out_ch: int, stride: int = 1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bn1   = nn.BatchNorm2d(in_ch)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv1 = conv3x3(in_ch, out_ch, stride=stride)\n",
    "\n",
    "        self.bn2   = nn.BatchNorm2d(out_ch)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(out_ch, out_ch, stride=1)\n",
    "\n",
    "        self.downsample = None\n",
    "        if stride != 1 or in_ch != out_ch:\n",
    "            self.downsample = conv1x1(in_ch, out_ch, stride=stride)  # BN opsiyonel\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.bn1(x)\n",
    "        out = self.relu1(out)\n",
    "\n",
    "        # projection shortcut genelde burada preact'ten beslenir\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(out)\n",
    "\n",
    "        out = self.conv1(out)\n",
    "\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        out = out + identity\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7574e912",
   "metadata": {},
   "source": [
    "## 11) Bottleneck (with Expansion) - Post-Act örneği\n",
    "ResNet-50/101 tarzı.\n",
    "- `1x1 reduce` → `3x3` → `1x1 expand`\n",
    "- `expansion=4` tipiktir.\n",
    "- Aktivasyon v1 tarzı: add sonrası ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1769e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottleneckPostAct(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_ch: int, bottleneck_ch: int, stride: int = 1):\n",
    "        super().__init__()\n",
    "        out_ch = bottleneck_ch * self.expansion\n",
    "\n",
    "        self.conv1 = conv1x1(in_ch, bottleneck_ch, stride=1)\n",
    "        self.bn1   = nn.BatchNorm2d(bottleneck_ch)\n",
    "\n",
    "        self.conv2 = conv3x3(bottleneck_ch, bottleneck_ch, stride=stride)\n",
    "        self.bn2   = nn.BatchNorm2d(bottleneck_ch)\n",
    "\n",
    "        self.conv3 = conv1x1(bottleneck_ch, out_ch, stride=1)\n",
    "        self.bn3   = nn.BatchNorm2d(out_ch)\n",
    "\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.downsample = None\n",
    "        if stride != 1 or in_ch != out_ch:\n",
    "            self.downsample = nn.Sequential(\n",
    "                conv1x1(in_ch, out_ch, stride=stride),\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "            )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x); out = self.bn1(out); out = self.relu(out)\n",
    "        out = self.conv2(out); out = self.bn2(out); out = self.relu(out)\n",
    "        out = self.conv3(out); out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out = out + identity\n",
    "        out = self.relu(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c753dd",
   "metadata": {},
   "source": [
    "## 12) ResNeXt Grouped Bottleneck - Post-Act örneği\n",
    "Bottleneck ile aynı mantık, fark: ortadaki 3x3 conv **groups** ile çalışır.\n",
    "\n",
    "ResNeXt’te genelde şu parametrizasyon görülür:\n",
    "- `groups` = cardinality\n",
    "- `width_per_group` ile effective bottleneck width ayarlanır\n",
    "\n",
    "Aşağıdaki implementasyon basit tutuldu: `groups` direkt veriliyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7116cbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNeXtBottleneckPostAct(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_ch: int, bottleneck_ch: int, stride: int = 1, groups: int = 32):\n",
    "        super().__init__()\n",
    "        out_ch = bottleneck_ch * self.expansion\n",
    "\n",
    "        # 1x1 reduce\n",
    "        self.conv1 = conv1x1(in_ch, bottleneck_ch, stride=1)\n",
    "        self.bn1   = nn.BatchNorm2d(bottleneck_ch)\n",
    "\n",
    "        # 3x3 grouped conv\n",
    "        self.conv2 = conv3x3(bottleneck_ch, bottleneck_ch, stride=stride, groups=groups)\n",
    "        self.bn2   = nn.BatchNorm2d(bottleneck_ch)\n",
    "\n",
    "        # 1x1 expand\n",
    "        self.conv3 = conv1x1(bottleneck_ch, out_ch, stride=1)\n",
    "        self.bn3   = nn.BatchNorm2d(out_ch)\n",
    "\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.downsample = None\n",
    "        if stride != 1 or in_ch != out_ch:\n",
    "            self.downsample = nn.Sequential(\n",
    "                conv1x1(in_ch, out_ch, stride=stride),\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "            )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x); out = self.bn1(out); out = self.relu(out)\n",
    "        out = self.conv2(out); out = self.bn2(out); out = self.relu(out)\n",
    "        out = self.conv3(out); out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out = out + identity\n",
    "        out = self.relu(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9e323b",
   "metadata": {},
   "source": [
    "## 13) Wide yaklaşımını koda bağlamak\n",
    "**Wide** ayrı bir blok değildir; genelde blokların `out_ch` değerini büyütmektir.\n",
    "\n",
    "Aşağıdaki örnek: BasicBlockPostAct ile normalde `out_ch=64` kullanacaksan, Wide için `k * 64` (ör. `k=2,4,8`) kullanırsın."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7a3e733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256, 56, 56])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Örnek: Wide factor ile kanal büyütme\n",
    "wide_factor = 4\n",
    "block = BasicBlockPostAct(in_ch=64, out_ch=64 * wide_factor, stride=1)\n",
    "\n",
    "x = torch.randn(2, 64, 56, 56)\n",
    "y = block(x)\n",
    "y.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14b6d10",
   "metadata": {},
   "source": [
    "## 14) Hızlı sanity-check\n",
    "Aşağıdaki hücre tüm blokların çalıştığını hızlıca kontrol eder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c534fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 64, 56, 56]),\n",
       " torch.Size([2, 64, 56, 56]),\n",
       " torch.Size([2, 256, 56, 56]),\n",
       " torch.Size([2, 256, 56, 56]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 64, 56, 56)\n",
    "\n",
    "m1 = BasicBlockPostAct(64, 64, stride=1)\n",
    "m2 = BasicBlockPreAct(64, 64, stride=1)\n",
    "m3 = BottleneckPostAct(64, bottleneck_ch=64, stride=1)  # çıkış 256 kanal\n",
    "m4 = ResNeXtBottleneckPostAct(64, bottleneck_ch=64, stride=1, groups=32)  # çıkış 256 kanal\n",
    "\n",
    "y1 = m1(x)\n",
    "y2 = m2(x)\n",
    "y3 = m3(x)\n",
    "y4 = m4(x)\n",
    "\n",
    "(y1.shape, y2.shape, y3.shape, y4.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
