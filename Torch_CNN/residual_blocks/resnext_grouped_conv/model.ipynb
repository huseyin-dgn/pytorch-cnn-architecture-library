{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8f1ad3e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d181446b",
   "metadata": {},
   "source": [
    "### Adım Adım ResNeXt Grouped Conv Residual "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca175ec",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee0478e",
   "metadata": {},
   "source": [
    "# Adım 1 — En sade iskelet: sadece “residual fikri”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe743b8",
   "metadata": {},
   "source": [
    "* Bu sınıf şimdilik hiç öğrenilebilir katman içermiyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f85c6d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "class ResnetxBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self,x):\n",
    "        identity = x\n",
    "        out = x\n",
    "        out = out + identity\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0eb90b1",
   "metadata": {},
   "source": [
    "* Bu kod “residual”ın matematik iskeleti.\n",
    "* Şimdi bu “out = x” kısmını gerçek bir F(x) yapacağız."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7ee47d",
   "metadata": {},
   "source": [
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5a973e",
   "metadata": {},
   "source": [
    "# 2) Adım 2 — F(x)’i “grouped 3×3” ile başlatalım (en sade öğrenilebilir F)\n",
    "\n",
    "En minimal öğrenilebilir grouped residual:\n",
    "\n",
    ">F(x) = 3×3 grouped conv + BN + ReLU (opsiyon)\n",
    ">Skip = x (boyutlar aynıysa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1839fe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.functional as F\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "class GroupedResidualBlock(nn.Module):\n",
    "    def __init__(self, channels, groups=4):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            channels, channels, kernel_size=3, stride=1, padding=1,\n",
    "            groups=groups, bias=False\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip = x\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = F.relu(out, inplace=True)\n",
    "        return out + skip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6a5033",
   "metadata": {},
   "source": [
    "✅ Bu artık “grouped conv residual block”tır.\n",
    "\n",
    "Ama ResNeXt tarzında genelde iki şey daha istenir:\n",
    "\n",
    "* Kanalı ayarlayabilmek (in_ch ≠ out_ch)\n",
    "\n",
    "* Downsample yapabilmek (stride=2)\n",
    "\n",
    "* Bunu eklemek için projection skip gerekir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9b5497",
   "metadata": {},
   "source": [
    "-----\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba40cd50",
   "metadata": {},
   "source": [
    "# 3) Adım 3 — Boyutlar değişince skip’i düzenlemek (projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69eee887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.functional as F\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "class GroupedResidualBlock(nn.Module):\n",
    "    def __init__(self,in_ch,out_ch,stride=1,groups=4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(in_ch,out_ch,kernel_size=3,stride=stride,padding=1,groups=groups,bias = False)\n",
    "        self.bn = nn.BatchNorm2d(out_ch)\n",
    "\n",
    "        self.proj = None\n",
    "        if stride != 1 or in_ch!=out_ch:\n",
    "            self.proj = nn.Sequential(\n",
    "                nn.Conv2d(in_ch,out_ch,kernel_size=1,stride=1,bias=False),\n",
    "                nn.BatchNorm2d(out_ch))\n",
    "            \n",
    "    def forward(self,x):\n",
    "        skip = x if self.proj is None else self.proj(x)\n",
    "\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = F.relu(out,inplace=True)\n",
    "\n",
    "        return out + skip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a2bbbd",
   "metadata": {},
   "source": [
    "* ✅ Bu, “grouped conv residual block”u tam anlamıyla kullanılabilir hale getirir.\n",
    "\n",
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543018d5",
   "metadata": {},
   "source": [
    "# 4) ResNeXt ile fark nerede?\n",
    "\n",
    "ResNeXt’te “F(x)” sadece tek grouped 3×3 değildir; genelde:\n",
    "\n",
    "* grouped 3×3’ün önünde/arkasında kanal düzenleyen 1×1 katmanlar vardır (bu sayede groups daha verimli kullanılır ve kapasite artışı daha kontrollü olur).\n",
    "\n",
    "* Yani ResNeXt’in standart bloğu bu “sade versiyonun” genişletilmiş halidir.\n",
    "\n",
    "### Şimdi kod (tam standart ResNeXt bloğu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9a4fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def conv1x1(in_ch, out_ch, stride=1):\n",
    "    return nn.Conv2d(in_ch, out_ch, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "def conv3x3(in_ch, out_ch, stride=1, groups=1):\n",
    "    return nn.Conv2d(\n",
    "        in_ch, out_ch, kernel_size=3, stride=stride, padding=1,\n",
    "        groups=groups, bias=False\n",
    "    )\n",
    "\n",
    "class ResNeXtBlock_X(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_ch, bottleneck_ch, stride=1, groups=32, base_width=4):\n",
    "        super().__init__()\n",
    "\n",
    "        # 1) Bloğun çıkış kanal sayısı (standart ResNeXt/ResNet genişletme kuralı)\n",
    "        out_ch = bottleneck_ch * self.expansion\n",
    "\n",
    "        # 2) Grouped 3×3'ün çalışacağı iç kanal (width)\n",
    "        #    width = (per_group_width) * groups\n",
    "        width = int(bottleneck_ch * (base_width / 64.0)) * groups\n",
    "\n",
    "        # -------------------------\n",
    "        # Main path: F(x)\n",
    "        # -------------------------\n",
    "        # (a) 1×1 reduce: in_ch -> width\n",
    "        self.conv1 = conv1x1(in_ch, width)\n",
    "        self.bn1 = nn.BatchNorm2d(width)\n",
    "\n",
    "        # (b) 3×3 grouped: width -> width (stride burada uygulanır)\n",
    "        self.conv2 = conv3x3(width, width, stride=stride, groups=groups)\n",
    "        self.bn2 = nn.BatchNorm2d(width)\n",
    "\n",
    "        # (c) 1×1 expand: width -> out_ch\n",
    "        self.conv3 = conv1x1(width, out_ch)\n",
    "        self.bn3 = nn.BatchNorm2d(out_ch)\n",
    "\n",
    "        # -------------------------\n",
    "        # Skip path: identity veya projection\n",
    "        # -------------------------\n",
    "        self.downsample = None\n",
    "        if stride != 1 or in_ch != out_ch:\n",
    "            self.downsample = nn.Sequential(\n",
    "                conv1x1(in_ch, out_ch, stride=stride),\n",
    "                nn.BatchNorm2d(out_ch)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # skip\n",
    "        identity = x\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        # F(x)\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out, inplace=True)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = F.relu(out, inplace=True)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        out = out + identity\n",
    "        out = F.relu(out, inplace=True)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d765eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([2, 256, 56, 56])\n",
      "y: torch.Size([2, 256, 56, 56])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 256, 56, 56)\n",
    "\n",
    "blk = ResNeXtBlock_X(in_ch=256, bottleneck_ch=64, stride=1, groups=4, base_width=4)\n",
    "y = blk(x)\n",
    "\n",
    "print(\"x:\", x.shape)\n",
    "print(\"y:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2765260e",
   "metadata": {},
   "source": [
    "# Kullanım tablosu: “Ne verirsem ne olur?”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86382530",
   "metadata": {},
   "source": [
    "| Verdiğin parametre         | Ne işe yarar                            | Ne değişir?                                                                                 | Tipik değerler                         | Yan etki / dikkat                                                             |\n",
    "| -------------------------- | --------------------------------------- | ------------------------------------------------------------------------------------------- | -------------------------------------- | ----------------------------------------------------------------------------- |\n",
    "| `in_ch`                    | Bloğa giren feature map’in kanal sayısı | Skip ve ilk 1×1’in giriş boyutu                                                             | Stage’e göre: 64, 128, 256, 512, 1024… | `in_ch` yanlışsa blok bağlanmaz (shape mismatch)                              |\n",
    "| `bottleneck_ch`            | Bloğun “temel kanal ölçeği” (planes)    | Çıkış kanalını belirler: `out_ch = bottleneck_ch*4` ve `width` hesabına girer               | 64, 128, 256, 512 (stage’e göre)       | Yanlış seçilirse block çıkışı beklenen stage kanalına uymaz                   |\n",
    "| `stride`                   | Uzamsal downsample yapıp yapmama        | `H×W` düşer (stride=2) veya aynı kalır (stride=1)                                           | 1 veya 2                               | `stride=2` ise skip’e projection genellikle şart                              |\n",
    "| `groups`                   | Cardinality (kaç grup)                  | Grouped 3×3’ün grup sayısı; grup sayısı artınca “paralel temsil” artar                      | 4, 8, 16, 32                           | `width` mutlaka `groups`’a bölünebilir olmalı (pratikte)                      |\n",
    "| `base_width`               | Grup başına taban genişlik ölçeği       | `width = int(bottleneck_ch*(base_width/64))*groups` üzerinden iç genişliği büyütür/küçültür | 4 (klasik), bazen 8                    | Çok büyütürsen maliyet artar, çok küçültürsen kapasite düşer                  |\n",
    "| `expansion` (sınıf sabiti) | Son 1×1’in genişletme katsayısı         | Çıkış kanal çarpanı                                                                         | Genelde 4                              | Çoğu ResNeXt/ResNet standardı 4’tür; değiştirirsen stage kanal düzeni bozulur |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5c3266",
   "metadata": {},
   "source": [
    "## Örnek A — Boyutlar aynı kalsın (projection yok)\n",
    "\n",
    "Amaç: Sadece blok eklemek, H×W değişmesin.\n",
    "\n",
    "* stride = 1\n",
    "\n",
    "* in_ch ile out_ch eşleşmeli\n",
    "\n",
    "**out_ch=bottleneck_ch×4**\n",
    "\n",
    "*O halde:*\n",
    "\n",
    "**in_ch=bottleneck_ch×4**\n",
    "\n",
    "#### Kullanım:\n",
    "```python \n",
    "# in_ch=256 ise bottleneck_ch=64 seçersek out_ch=256 olur → projection gerekmez\n",
    "ResNeXtBlock(in_ch=256, bottleneck_ch=64, stride=1, groups=4, base_width=4)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa774b8a",
   "metadata": {},
   "source": [
    "## Örnek B — Downsample  (projection var)\n",
    "\n",
    "Amaç: H×W yarıya insin.\n",
    "\n",
    "* stride = 2 (grouped 3×3 üzerinde uygulanır)\n",
    "\n",
    "* Skip hattı: 1×1 conv (stride=2) ile küçültülür\n",
    "\n",
    "#### Kullanım:\n",
    "```python \n",
    "# HxW düşer, kanal out_ch olur\n",
    "ResNeXtBlock(in_ch=256, bottleneck_ch=128, stride=2, groups=4, base_width=4)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9f7daf",
   "metadata": {},
   "source": [
    "#### Ne olur?\n",
    "\n",
    "* out_ch = 128*4 = 512\n",
    "\n",
    "* Çıkış shape: [N, 512, H/2, W/2]\n",
    "\n",
    "* Skip: projection (1×1 + BN, stride=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cc040d",
   "metadata": {},
   "source": [
    "## Örnek C — groups arttırınca ne olur?\n",
    "* Amaç: Daha fazla “paralel temsil” (cardinality ↑)\n",
    "\n",
    "```python \n",
    "ResNeXtBlock(in_ch=256, bottleneck_ch=64, stride=1, groups=8, base_width=4)\n",
    "```\n",
    "\n",
    "#### Ne olur?\n",
    "\n",
    "* width hesabında *groups var → groups artınca width genelde artar\n",
    "\n",
    "* Grouped 3×3 artık 8 gruba bölünür\n",
    "\n",
    "* Kapasite artabilir; maliyet de artabilir (width’a bağlı)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad14ffe0",
   "metadata": {},
   "source": [
    "-------\n",
    "---------\n",
    "------------\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee29adf",
   "metadata": {},
   "source": [
    "## Terimler Sözlüğü (Kısa Açıklamalar)\n",
    "\n",
    "- **Feature map (Özellik haritası):**  \n",
    "  CNN’in bir katmandan ürettiği `[H × W]` boyutundaki haritalardır. Kanal sayısı kadar feature map bulunur.\n",
    "\n",
    "- **Kanal (Channel):**  \n",
    "  Aynı görüntünün farklı “öğrenilmiş özellik” temsilleri. RGB gibi sabit değildir; ağ tarafından öğrenilir.\n",
    "\n",
    "- **Residual / Skip Connection:**  \n",
    "  \\[\n",
    "  y = x + F(x)\n",
    "  \\]  \n",
    "  yapısıdır. Gradyan akışını kolaylaştırır ve derin ağların daha stabil eğitilmesini sağlar.\n",
    "\n",
    "- **Identity (Skip):**  \n",
    "  Boyutlar (kanal ve uzamsal) uyuyorsa skip hattında doğrudan `x`’in kullanılmasıdır.\n",
    "\n",
    "- **Projection (Downsample):**  \n",
    "  Boyutlar uymuyorsa skip hattında `1×1 Conv (+ BN)` kullanılarak kanal ve/veya uzamsal boyut eşlemesi yapılmasıdır.\n",
    "\n",
    "- **Stride:**  \n",
    "  Konvolüsyonun adım boyu.  \n",
    "  `stride = 2` → uzamsal boyutlar (`H × W`) yaklaşık yarıya düşer.\n",
    "\n",
    "- **Groups (Cardinality):**  \n",
    "  3×3 konvolüsyonun kanalları kaç parçaya bölerek çalıştığını belirtir.  \n",
    "  ResNeXt mimarisinin ana ölçekleme eksenidir.\n",
    "\n",
    "- **Grouped Convolution:**  \n",
    "  Kanalların `groups` adet gruba ayrılıp her grubun kendi konvolüsyonunu yapmasıdır.  \n",
    "  Çoğunlukla sonrasında `1×1 Conv` ile gruplar tekrar birleştirilir.\n",
    "\n",
    "- **base_width:**  \n",
    "  Her grup için taban genişlik ölçeğidir.  \n",
    "  `width` hesabında kullanılır ve ResNeXt’in iç kanal düzenini belirler.\n",
    "\n",
    "- **width (Internal Width):**  \n",
    "  Grouped `3×3` konvolüsyonun çalıştığı **toplam iç kanal sayısıdır**.\n",
    "\n",
    "- **expansion:**  \n",
    "  Son `1×1 Conv`’un kanalı kaç kat genişlettiğini belirler.  \n",
    "  ResNeXt / ResNet standartlarında genellikle `4` olarak kullanılır.\n",
    "\n",
    "- **bottleneck_ch (Planes):**  \n",
    "  Stage’in temel kanal parametresidir.  \n",
    "  Çıkış kanalı şu şekilde belirlenir:  \n",
    "  \\[\n",
    "  out\\_ch = bottleneck\\_ch \\times expansion\n",
    "  \\]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
