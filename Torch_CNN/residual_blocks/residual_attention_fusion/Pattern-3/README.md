# Controlled Pre-Attention Residual Fusion (Pattern-3)

Bu yapÄ±, attention ile residual Ã¶ÄŸrenmeyi **daha erken bir aÅŸamada** birleÅŸtirir.  
Ã–nce giriÅŸ Ã¶zelliÄŸi attention ile yumuÅŸak ÅŸekilde yeniden aÄŸÄ±rlÄ±klandÄ±rÄ±lÄ±r, sonra residual dÃ¶nÃ¼ÅŸÃ¼me sokulur.

---

## ğŸ¯ Temel Denklem

Ã–nce giriÅŸ iÃ§in iki temsil oluÅŸturulur:

- **x** â†’ ham Ã¶zellik
- **x_att = A(x) âŠ™ x** â†’ attention ile filtrelenmiÅŸ giriÅŸ

Bunlar karÄ±ÅŸtÄ±rÄ±lÄ±r:

**xÌƒ = (1âˆ’Î»)Â·x + Î»Â·x_att**

Sonra residual blok uygulanÄ±r:

**Ã‡Ä±kÄ±ÅŸ = Aktivasyon( Skip(x) + F(xÌƒ) )**

---

## ğŸ§  Patternâ€™in FarkÄ±

Klasik attention-residual patternâ€™de attention, **F(x)** Ã¼zerine uygulanÄ±r.  
Burada ise attention:

> **Residual Ã¶ÄŸrenme baÅŸlamadan Ã–NCE giriÅŸ temsiline uygulanÄ±r.**

Yani attention, dÃ¶nÃ¼ÅŸÃ¼mÃ¼n girdisini deÄŸiÅŸtirir.

---

## ğŸ”€ Fusion Tipi

Bu pattern:

**Pre-Residual Controlled Attention Fusion**

olarak dÃ¼ÅŸÃ¼nÃ¼lebilir.

- Attention sonrasÄ± temsil, residual branchâ€™e girer
- Skip yolu deÄŸiÅŸmez
- Toplama yine residual mantÄ±kta yapÄ±lÄ±r

---

## âš™ï¸ Î» (Lambda) RolÃ¼

Î», modelin ÅŸuna karar vermesini saÄŸlar:

| Î» deÄŸeri      | DavranÄ±ÅŸ                   |
| ------------- | -------------------------- |
| KÃ¼Ã§Ã¼k         | Ham featureâ€™lar korunur    |
| BÃ¼yÃ¼k         | Attention etkisi artar     |
| Ã–ÄŸrenilebilir | Model en iyi dengeyi bulur |

Bu, attentionâ€™Ä±n aÅŸÄ±rÄ± baskÄ±n olmasÄ±nÄ± engeller.

---

## ğŸ§© Neden Bu YapÄ± Ä°lginÃ§?

âœ” Attention, residual Ã¶ÄŸrenmenin giriÅŸini yÃ¶nlendirir  
âœ” GÃ¼rÃ¼ltÃ¼ daha erken bastÄ±rÄ±lÄ±r  
âœ” Skip hattÄ± yine saf kalÄ±r  
âœ” Residual stabilite korunur  
âœ” Feature refinement daha â€œÃ¶n aÅŸamadaâ€ yapÄ±lÄ±r

---

## ğŸ†š Pattern-2 ile FarkÄ±

|                   | Pattern-2          | Pattern-3          |
| ----------------- | ------------------ | ------------------ |
| Attention nerede? | F(x) sonrasÄ±       | F(x)â€™ten Ã¶nce      |
| KarÄ±ÅŸtÄ±rÄ±lan ÅŸey  | Residual Ã§Ä±ktÄ±lar  | GiriÅŸ featureâ€™larÄ± |
| Etki alanÄ±        | Temsil iyileÅŸtirme | Temsil yÃ¶nlendirme |

---

## ğŸ”š Ã–zet

Bu pattern:

**Attention ile yÃ¶nlendirilmiÅŸ giriÅŸ + Residual Ã¶ÄŸrenme + KontrollÃ¼ karÄ±ÅŸÄ±m**

yaklaÅŸÄ±mÄ±dÄ±r ve attentionâ€™Ä± residual dÃ¶nÃ¼ÅŸÃ¼mÃ¼n daha erken aÅŸamasÄ±na taÅŸÄ±r.
