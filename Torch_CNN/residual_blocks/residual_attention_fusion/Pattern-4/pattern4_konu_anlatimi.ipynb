{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b56920a",
   "metadata": {},
   "source": [
    "------\n",
    "------\n",
    "------\n",
    "\n",
    "\n",
    "### **Pattern-4’te hem x (skip yolu) hem de F(x) (residual yolu) ayrı ayrı attention/gating’den geçirilir ve bu iki modüle edilmiş sinyal toplanarak çıktıya verilir.**\n",
    "\n",
    "-------\n",
    "---------\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dae301d",
   "metadata": {},
   "source": [
    "# Pattern-4 — Dual-path / Skip-aware Fusion (Konu Anlatımı)\n",
    "\n",
    "Bu notebook **konu anlatımı** odaklıdır (model “tam” kodu değil).  \n",
    "Ama “nasıl tasarlanır, neden agresif, nasıl stabil yapılır, Pattern-1/2/3 ile farkı nedir” kısmını **baştan en ileri seviyeye** götürür.\n",
    "\n",
    "---\n",
    "\n",
    "## Pattern-4 tek cümle\n",
    "> **Skip yolunu ve residual yolunu ayrı ayrı attention ile modüle edip sonra topluyoruz.**\n",
    "\n",
    "\\[\n",
    "y = A_s(x) + A_r(F(x))\n",
    "\\]\n",
    "\n",
    "ASCII:\n",
    "```text\n",
    "      x ──► A_s ──► (+) ──► y\n",
    "      x ──►  F  ──► A_r ──^\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee0e5c3",
   "metadata": {},
   "source": [
    "## 0) Sembol sözlüğü (kafa karışmasın)\n",
    "\n",
    "- **x**: giriş feature map \\(\\in \\mathbb{R}^{C\\times H\\times W}\\)  \n",
    "- **F(·)**: residual dönüşüm (Conv/BN/ReLU/Conv/BN gibi)  \n",
    "- **A(·)**: attention/gating modülü (SE/ECA/CBAM/CoordAtt vb.)  \n",
    "- **A_s**: skip (identity) yoluna uygulanan attention  \n",
    "- **A_r**: residual yoluna uygulanan attention  \n",
    "- **⊙**: eleman bazlı çarpma (ölçekleme)  \n",
    "- **+**: residual toplama/fusion\n",
    "\n",
    "> Kritik fikir: Pattern-4’te **identity artık “dokunulmamış” değil**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf2227c",
   "metadata": {},
   "source": [
    "## 1) Pattern-1/2/3 ile net karşılaştırma (tek bakışta)\n",
    "\n",
    "### Pattern-1 — Attention inside residual branch\n",
    "\\[\n",
    "y = x + \\big(A(F(x)) \\odot F(x)\\big)\n",
    "\\]\n",
    "- Skip **saf** kalır  \n",
    "- Attention **residual katkıyı** ayarlar\n",
    "\n",
    "### Pattern-2 — Post-addition attention\n",
    "\\[\n",
    "z = x + F(x), \\quad y = A(z)\\odot z\n",
    "\\]\n",
    "- Skip ve residual önce birleşir  \n",
    "- Attention birleşmiş sinyali modüle eder\n",
    "\n",
    "### Pattern-3 — Pre-residual attention (input conditioning)\n",
    "\\[\n",
    "y = x + F(A(x))\n",
    "\\]\n",
    "- Attention residual dönüşüme girecek sinyali filtreler  \n",
    "- Skip **saf** kalır\n",
    "\n",
    "### Pattern-4 — Dual-path / skip-aware fusion\n",
    "\\[\n",
    "y = A_s(x) + A_r(F(x))\n",
    "\\]\n",
    "- Skip ve residual **ayrı ayrı** modüle edilir  \n",
    "- İfade gücü çok artar  \n",
    "- Ama **stabilite riski** de artar (identity bozulur)\n",
    "\n",
    "> Eğer “güvence” istiyorsan: Pattern-1 veya Pattern-3 daha emniyetli.  \n",
    "> Eğer “maks kontrol / maks ifade gücü” istiyorsan: Pattern-4.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febd5e4f",
   "metadata": {},
   "source": [
    "## 2) Pattern-4’ün amacı ne?\n",
    "\n",
    "Pattern-4 şu soruyu sorar:\n",
    "\n",
    "> “Neden skip yolu hep ‘düz kopya’ olmak zorunda? Skip’i de öğrenilebilir bir taşıyıcı yapsak?”\n",
    "\n",
    "Yani modelin elinde **iki ayrı düğme** olur:\n",
    "\n",
    "1) **Skip düğmesi (A_s)**: temel sinyali ne kadar taşıyacağım?  \n",
    "2) **Residual düğmesi (A_r)**: düzeltmeyi ne kadar ekleyeceğim?\n",
    "\n",
    "Bu, bazı veri/katmanlarda şunları sağlar:\n",
    "- Skip’in baskın olduğu örneklerde residual’ı kısar\n",
    "- Residual’ın gerekli olduğu örneklerde skip’i azaltıp residual’ı artırır\n",
    "- “Sadece ekle” yerine “iki yolu da şekillendir” yapar\n",
    "\n",
    "### Avantaj (neden güçlü?)\n",
    "- Skip + residual = iki bağımsız kontrol → daha esnek temsil\n",
    "- Özellikle orta/son katmanda semantik özelliklerde “hangi yol ağır basacak?” kararı daha anlamlı olur.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4f38eb",
   "metadata": {},
   "source": [
    "## 3) Neden agresif/riskli? (identity bozulması)\n",
    "\n",
    "ResNet’in en büyük avantajı: **identity yolu her zaman açık**.\n",
    "\n",
    "Pattern-4’te eğer `A_s` kötü tasarlanırsa şu olur:\n",
    "- Skip yolu “x” olmaktan çıkar\n",
    "- Model, erken dönemde “güvenli geçiş”i kaybeder\n",
    "- Eğitim dalgalanabilir, özellikle küçük batch + BN + yüksek LR’da\n",
    "\n",
    "### Kötü (riskli) skip örneği\n",
    "\\[\n",
    "A_s(x) = m(x)\\odot x \\quad \\text{(m 0..1)}\n",
    "\\]\n",
    "Burada `m(x)` bazı yerlerde 0’a yaklaşırsa skip sinyali **sıfırlanır** → eğitim kırılabilir.\n",
    "\n",
    "> O yüzden Pattern-4’te asıl mesele: `A_s`’yi **near-identity** yapmak.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd816af",
   "metadata": {},
   "source": [
    "## 4) Stabil Pattern-4 tasarımı: Near-Identity Skip\n",
    "\n",
    "Amaç: `A_s(x)` başlangıçta “neredeyse x” olsun.\n",
    "\n",
    "### En güvenli form (pratikte çok kullanılır)\n",
    "\\[\n",
    "A_s(x) = x \\odot \\big(1 + \\gamma_s \\cdot m_s(x)\\big)\n",
    "\\]\n",
    "- `m_s(x)` 0..1 maske (SE/CBAM/ECA fark etmez)  \n",
    "- `γ_s` küçük başlar (0.0 / 0.05)  \n",
    "- Başlangıçta `γ_s≈0` → \\(A_s(x)\\approx x\\)\n",
    "\n",
    "Böylece:\n",
    "- Identity yolu “tamamen kapanmaz”\n",
    "- `A_s` sadece **ince ayar** yapar\n",
    "\n",
    "### Residual tarafı (daha toleranslı)\n",
    "\\[\n",
    "A_r(f)= f\\odot(1+\\gamma_r\\cdot m_r(f))\n",
    "\\]\n",
    "Burada `γ_r` daha büyük olabilir çünkü residual zaten “ekstra katkı”dır.\n",
    "\n",
    "> Pattern-4’te “güvence”yi skip’te korursun, gücü residual’da artırırsın.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6ed44a",
   "metadata": {},
   "source": [
    "## 5) Hangi attention seçilir? (A_s ve A_r için)\n",
    "\n",
    "Pattern-4 “hangi attention” sorusundan bağımsız bir **füzyon şemasıdır**.\n",
    "\n",
    "Ama pratikte:\n",
    "- **A_s** için: SE/ECA gibi **hafif channel gate** daha güvenli  \n",
    "- **A_r** için: CBAM/CoordAtt gibi daha zengin gate kullanılabilir\n",
    "\n",
    "### Önerilen eşleşmeler\n",
    "- `A_s`: ECA veya SE (hafif, stabil)  \n",
    "- `A_r`: CBAM (channel+spatial) veya CoordAtt (yön bilgisi)\n",
    "\n",
    "> Skip’i ağır attention’a boğmak genelde gereksiz risk.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ea100c",
   "metadata": {},
   "source": [
    "## 6) Pattern-4 akışını “katman katman” düşün\n",
    "\n",
    "Klasik residual blok:\n",
    "```python\n",
    "identity = skip(x)\n",
    "f = F(x)\n",
    "y = ReLU(identity + f)\n",
    "```\n",
    "\n",
    "Pattern-4:\n",
    "```python\n",
    "identity = skip(x)\n",
    "s = A_s(identity)          # skip modülasyonu\n",
    "f = F(x)\n",
    "r = A_r(f)                 # residual modülasyonu\n",
    "y = ReLU(s + r)\n",
    "```\n",
    "\n",
    "Burada kritik fark:\n",
    "- Pattern-1/3’te skip **dokunulmaz**\n",
    "- Pattern-4’te skip de **kontrollü** taşınır\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdedfc9a",
   "metadata": {},
   "source": [
    "## 7) Stabilite tüyoları (kısa ama iş yapan)\n",
    "\n",
    "1) **γ_s’i 0 başlat**  \n",
    "   - İlk başta skip saf kalsın → sonra model öğrenince ayarlasın\n",
    "\n",
    "2) **γ_s < γ_r** tut  \n",
    "   - Skip: ince ayar  \n",
    "   - Residual: daha güçlü müdahale\n",
    "\n",
    "3) Pattern-4’ü **orta/son katmanlara** koy  \n",
    "   - Erken katmanlar gürültülü → risk artar\n",
    "\n",
    "4) Küçük batch kullanıyorsan BN dalgalanabilir  \n",
    "   - GN/LN veya daha büyük batch stabiliteyi artırabilir\n",
    "\n",
    "5) “Post-addition attention” ile karıştırma  \n",
    "   - Pattern-2, birleşik sinyali modüle eder → Pattern-4 gibi skip’i bozmaz.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac988031",
   "metadata": {},
   "source": [
    "## 8) Ne zaman Pattern-4 seçmeli? (karar kuralı)\n",
    "\n",
    "### Pattern-4 mantıklıysa\n",
    "- Modelin zaten stabil öğreniyor (LR/BN ayarlı)\n",
    "- Orta/son katmanda “daha fazla kontrol” istiyorsun\n",
    "- Ablation’da “tavan performans” arıyorsun\n",
    "\n",
    "### Pattern-4 riskliyse\n",
    "- Çok küçük veri / gürültülü veri\n",
    "- Çok erken katmanlarda attention ısrarı\n",
    "- Eğitim zaten zor gidiyor (loss oynuyor)\n",
    "\n",
    "> Kural: “Stabil bir backbone üstüne Pattern-4 eklemek” daha güvenlidir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19203aaa",
   "metadata": {},
   "source": [
    "## 9) Mini pseudo-code \n",
    "\n",
    "Aşağıdaki, Pattern-4’ün “tasarım iskeleti”. Kod yazarken birebir bu sırayı takip edersin:\n",
    "\n",
    "```python\n",
    "INPUT: x\n",
    "\n",
    "# 1) skip path\n",
    "identity = skip(x)\n",
    "\n",
    "# 2) skip attention (hafif, near-identity)\n",
    "s = identity * (1 + gamma_s * mask_s(identity))\n",
    "\n",
    "# 3) residual path\n",
    "f = F(x)\n",
    "\n",
    "# 4) residual attention (daha güçlü olabilir)\n",
    "r = f * (1 + gamma_r * mask_r(f))\n",
    "\n",
    "# 5) fusion\n",
    "y = s + r\n",
    "\n",
    "# 6) output activation\n",
    "y = ReLU(y)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81e5d60",
   "metadata": {},
   "source": [
    "## 10) Pattern-4’ü “tek cümle” ile özetle\n",
    "\n",
    "> Pattern-4, residual toplama öncesinde **skip’i ve residual’ı ayrı ayrı kapılayıp**, sonra toplayan; doğru tasarlanırsa çok güçlü ama skip’i bozarsa dengesizleşebilen bir füzyon şemasıdır.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
