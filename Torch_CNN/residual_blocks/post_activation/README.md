# Basic Residual Blok TabanlÄ± MiniResNet â€” KullanÄ±lan Residual YaklaÅŸÄ±m

Bu mimaride klasik **Basic Residual (ResNet-18/34 tipi)** blok yapÄ±sÄ± kullanÄ±lÄ±r. AmaÃ§, derinlik arttÄ±kÃ§a oluÅŸan **degradation problemi** ve **gradyan zayÄ±flamasÄ±nÄ±** engelleyerek stabil Ã¶ÄŸrenme saÄŸlamaktÄ±r.

---

## ğŸ¯ Temel Prensip

Her blok ÅŸu iÅŸlemi yapar:

**Ã‡Ä±kÄ±ÅŸ = Aktivasyon( F(x) + Skip(x) )**

Burada:

- **F(x)** â†’ KonvolÃ¼syonlardan geÃ§en Ã¶ÄŸrenen ana yol
- **Skip(x)** â†’ GiriÅŸi doÄŸrudan taÅŸÄ±yan kÄ±sa yol

Toplama sayesinde aÄŸ, katman ekledikÃ§e performans kaybetmez.

---

## ğŸ§© Basic Residual YapÄ±sÄ±

Bu blok, bottleneck deÄŸil, **klasik iki 3Ã—3 konvolÃ¼syonlu** residual tasarÄ±mÄ±dÄ±r.

Ana yol:

1. **3Ã—3 Conv â†’ Norm â†’ ReLU**
2. **3Ã—3 Conv â†’ Norm**
3. **(Opsiyonel Attention)**
4. **Skip ile toplama**
5. **ReLU**

Bu yapÄ± uzamsal bilgiyi gÃ¼Ã§lÃ¼ ÅŸekilde iÅŸlerken residual baÄŸlantÄ± bilgi kaybÄ±nÄ± Ã¶nler.

---

## ğŸ” Skip (KÄ±sa Yol) DavranÄ±ÅŸÄ±

| Durum                        | Ne Olur                       |
| ---------------------------- | ----------------------------- |
| Kanal ve Ã§Ã¶zÃ¼nÃ¼rlÃ¼k aynÄ±     | GiriÅŸ direkt eklenir          |
| Kanal farklÄ± veya stride â‰  1 | 1Ã—1 projeksiyon ile eÅŸitlenir |

Bu sayede toplama Ã¶ncesi tensÃ¶r boyutlarÄ± uyumlu hale getirilir.

---

## â¬‡ï¸ Downsample MekanizmasÄ±

Stage geÃ§iÅŸlerinde Ã§Ã¶zÃ¼nÃ¼rlÃ¼k dÃ¼ÅŸÃ¼rmek iÃ§in:

- Ana yolda stride kullanÄ±lÄ±r
- Skip yol da aynÄ± stride ile projeksiyon yapar

Bu sayede hem uzamsal boyut hem kanal sayÄ±sÄ± yeni stageâ€™e taÅŸÄ±nÄ±r.

---

## ğŸ§  Normalization EsnekliÄŸi

Bloklar iki farklÄ± normalizasyonu destekler:

- **BatchNorm** â†’ Standart CNN eÄŸitimi
- **GroupNorm** â†’ KÃ¼Ã§Ã¼k batch boyutlarÄ±nda stabilite

Bu, modeli farklÄ± donanÄ±m ve veri senaryolarÄ±na uyumlu hale getirir.

---

## âœ¨ Attention Entegrasyonu

Blok, residual toplamadan Ã¶nce **attention modÃ¼lÃ¼ eklenmesine izin verir**. BÃ¶ylece:

- Residual Ã¶ÄŸrenme korunur
- Kanal veya uzamsal aÄŸÄ±rlÄ±klandÄ±rma yapÄ±labilir

Bu, performansÄ± artÄ±ran modern bir geniÅŸletmedir.

---

## ğŸ— MiniResNet YapÄ±sÄ±

Model dÃ¶rt stageâ€™den oluÅŸur:

| Stage   | Kanal ArtÄ±ÅŸÄ± | Ã‡Ã¶zÃ¼nÃ¼rlÃ¼k  |
| ------- | ------------ | ----------- |
| Stage 1 | Sabit        | AynÄ±        |
| Stage 2 | Ã—2           | YarÄ±ya iner |
| Stage 3 | Ã—2           | YarÄ±ya iner |
| Stage 4 | Ã—2           | YarÄ±ya iner |

Her stage birden fazla residual blok iÃ§erir.

---

## ğŸ’¡ Bu YaklaÅŸÄ±mÄ±n AvantajlarÄ±

âœ” Derin aÄŸlar stabil eÄŸitilir  
âœ” Gradyan akÄ±ÅŸÄ± korunur  
âœ” Parametre verimliliÄŸi yÃ¼ksektir  
âœ” Attention ve farklÄ± norm tÃ¼rleriyle geniÅŸletilebilir  
âœ” GÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rma backboneâ€™u olarak gÃ¼Ã§lÃ¼dÃ¼r

---

## ğŸ”š Ã–zet

Bu modelde uygulanan residual yaklaÅŸÄ±m:

**Temiz, klasik Basic Residual tasarÄ±mÄ± + esnek norm + opsiyonel attention + stage tabanlÄ± derinleÅŸtirme**

Modern CNN backboneâ€™larÄ±nÄ±n temel yapÄ± taÅŸlarÄ±ndan biridir.
