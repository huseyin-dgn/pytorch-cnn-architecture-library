{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fd1c93e",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "\n",
    "### **Her forward iÃ§inde, belirli katmanlar arasÄ±nda kontrollÃ¼ bilgi birleÅŸimi yapÄ±lÄ±r.**\n",
    "\n",
    "Forward iÃ§inde:\n",
    "\n",
    "âœ”ï¸ C5 bilgisi C4â€™e gider\n",
    "\n",
    "âœ”ï¸ C4 bilgisi C3â€™e gider\n",
    "\n",
    "âœ”ï¸ C3 bilgisi C2â€™ye gider\n",
    "\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7395920d",
   "metadata": {},
   "source": [
    "\n",
    "# Feature Pyramid Network (FPN) â€” DetaylÄ± AnlatÄ±m (Bottomâ€‘Up + Topâ€‘Down + Lateral)\n",
    "\n",
    "Bu notebookâ€™ta **FPN (Feature Pyramid Network)**â€™i â€œne, neden, nasÄ±lâ€ ekseninde adÄ±m adÄ±m anlatÄ±yorum:\n",
    "\n",
    "1. **FPN nedir?**\n",
    "2. **Neden bulundu? (Problem: Ã§ok Ã¶lÃ§ekli nesneler)**\n",
    "3. **Ne iÅŸe yarar? (Detection/segmentation vb.)**\n",
    "4. **Bottomâ€‘Up (aÅŸaÄŸÄ±dan yukarÄ±) izlenimler**\n",
    "5. **Topâ€‘Down (yukarÄ±dan aÅŸaÄŸÄ±) yol + lateral baÄŸlantÄ±lar**\n",
    "6. **Piramidin Ã§Ä±ktÄ±larÄ± (P2â€¦P5/P6/P7)**\n",
    "7. **PyTorch ile basit bir FPN implementasyonu**\n",
    "8. **Pratik ayarlar, artÄ±lar/eksiler ve tÃ¼revleri (PANet, BiFPN)**\n",
    "\n",
    "> AmaÃ§: â€œFPN ne yapÄ±yor?â€ sorusunu kafada **net bir akÄ±ÅŸ** haline getirmek. ğŸ§ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08e057a",
   "metadata": {},
   "source": [
    "\n",
    "## 1) FPN nedir?\n",
    "\n",
    "**FPN (Feature Pyramid Network)**, bir CNN backboneâ€™un farklÄ± derinliklerindeki feature mapâ€™leri birleÅŸtirerek **Ã§ok Ã¶lÃ§ekli (multiâ€‘scale) Ã¶zellik piramidi** Ã¼reten mimari tasarÄ±mdÄ±r.\n",
    "\n",
    "- CNNâ€™in **derin katmanlarÄ±**: yÃ¼ksek semantik (ne olduÄŸu), dÃ¼ÅŸÃ¼k Ã§Ã¶zÃ¼nÃ¼rlÃ¼k (nerede olduÄŸu zayÄ±f)\n",
    "- CNNâ€™in **sÄ±ÄŸ katmanlarÄ±**: yÃ¼ksek Ã§Ã¶zÃ¼nÃ¼rlÃ¼k (nerede olduÄŸu iyi), dÃ¼ÅŸÃ¼k semantik (ne olduÄŸu zayÄ±f)\n",
    "\n",
    "FPN, bu ikisini **topâ€‘down yol** + **lateral (yan) baÄŸlantÄ±lar** ile birleÅŸtirip her Ã¶lÃ§ekte **hem semantik hem konumsal** olarak gÃ¼Ã§lÃ¼ feature mapâ€™ler Ã¼retir.\n",
    "\n",
    "KÄ±saca:\n",
    "- **Bottomâ€‘Up**: backboneâ€™un normal ileri akÄ±ÅŸÄ± (Ã§Ã¶zÃ¼nÃ¼rlÃ¼k azalÄ±r, semantik artar)\n",
    "- **Topâ€‘Down**: Ã¼st seviyeden alt seviyeye upsample + birleÅŸtirme (semantik aÅŸaÄŸÄ± taÅŸÄ±nÄ±r)\n",
    "- **Lateral**: aynÄ± Ã¶lÃ§ekteki backbone Ã¶zelliklerini 1Ã—1 ile hizalayÄ±p toplama\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8608dd56",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Neden bulundu? (Hangi problemi Ã§Ã¶zÃ¼yor?)\n",
    "\n",
    "Nesne tespitinde (object detection) temel dert:\n",
    "- GÃ¶rÃ¼ntÃ¼deki nesneler **Ã§ok farklÄ± boyutlarda** olabilir (kÃ¼Ã§Ã¼k/orta/bÃ¼yÃ¼k).\n",
    "- Tek bir feature map Ã¶lÃ§eÄŸiyle tespit yaparsan:\n",
    "  - BÃ¼yÃ¼k nesneler iyi,\n",
    "  - KÃ¼Ã§Ã¼k nesneler kaÃ§abilir (Ã§Ã¼nkÃ¼ derin katmanlarda Ã§Ã¶zÃ¼nÃ¼rlÃ¼k dÃ¼ÅŸer).\n",
    "\n",
    "Eskiden â€œimage pyramidâ€ (gÃ¶rÃ¼ntÃ¼yÃ¼ farklÄ± Ã¶lÃ§eklerde tekrar tekrar CNNâ€™e sokmak) kullanÄ±lÄ±rdÄ±:\n",
    "- Ã‡ok pahalÄ± (hesap maliyeti yÃ¼ksek),\n",
    "- Pipeline karmaÅŸÄ±k.\n",
    "\n",
    "**FPN**, gÃ¶rÃ¼ntÃ¼yÃ¼ tekrar Ã¶lÃ§eklemek yerine backboneâ€™un zaten Ã¼rettiÄŸi hiyerarÅŸik featureâ€™larÄ± kullanÄ±p **feature pyramid** Ã¼retir:\n",
    "- Daha ucuz,\n",
    "- Daha gÃ¼Ã§lÃ¼,\n",
    "- Daha pratik.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa448ccf",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Ne iÅŸe yarar?\n",
    "\n",
    "FPN en Ã§ok ÅŸu iÅŸlerde kullanÄ±lÄ±r:\n",
    "\n",
    "- **Object Detection**: RetinaNet, Faster Râ€‘CNN (FPNâ€™li), Mask Râ€‘CNN\n",
    "- **Instance Segmentation**: Mask Râ€‘CNN (mask head genelde FPN seviyelerinden beslenir)\n",
    "- **Keypoint / Pose**: farklÄ± Ã¶lÃ§eklerde daha stabil Ã¶zellik Ã§Ä±karÄ±mÄ±\n",
    "- Genel olarak: â€œÃ§ok Ã¶lÃ§ekli hedefâ€ varsa FPN iyi bir default tercihtir âœ…\n",
    "\n",
    "KazandÄ±rdÄ±ÄŸÄ± ÅŸey:\n",
    "- KÃ¼Ã§Ã¼k nesnelerde recall artÄ±ÅŸÄ±\n",
    "- Ã‡ok Ã¶lÃ§ekte daha dengeli temsil (semantik + detay)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb03a6d",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Bottomâ€‘Up (AÅŸaÄŸÄ±dan YukarÄ±) izlenim â€” Backbone akÄ±ÅŸÄ±\n",
    "\n",
    "Backboneâ€™u Ã¶rnekleyelim (ResNet gibi dÃ¼ÅŸÃ¼n):\n",
    "\n",
    "- **C2**: erken katman (yÃ¼ksek Ã§Ã¶zÃ¼nÃ¼rlÃ¼k)\n",
    "- **C3**\n",
    "- **C4**\n",
    "- **C5**: en derin (dÃ¼ÅŸÃ¼k Ã§Ã¶zÃ¼nÃ¼rlÃ¼k, yÃ¼ksek semantik)\n",
    "\n",
    "Genelde Ã§Ã¶zÃ¼nÃ¼rlÃ¼k her seviyede 2Ã— azalÄ±r:\n",
    "- C2: 1/4\n",
    "- C3: 1/8\n",
    "- C4: 1/16\n",
    "- C5: 1/32 (inputâ€™a gÃ¶re)\n",
    "\n",
    "**Bottomâ€‘Up akÄ±ÅŸ** ÅŸu gerÃ§eÄŸi Ã¼retir:\n",
    "- Derine indikÃ§e â€œne olduÄŸuâ€ gÃ¼Ã§lenir (semantik)\n",
    "- Ama â€œnerede olduÄŸuâ€ zayÄ±flar (spatial detay kaybÄ±)\n",
    "\n",
    "Bu yÃ¼zden sadece C5 ile detection yapmak kÃ¼Ã§Ã¼k nesneleri Ã¶ldÃ¼rÃ¼r.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebf6804",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Topâ€‘Down yol + Lateral baÄŸlantÄ±lar â€” FPNâ€™in kalbi â¤ï¸\n",
    "\n",
    "FPNâ€™in â€œbÃ¼yÃ¼sÃ¼â€:\n",
    "\n",
    "### 5.1) Topâ€‘Down (YukarÄ±dan AÅŸaÄŸÄ±)\n",
    "En Ã¼stten baÅŸlarÄ±z:\n",
    "- **P5 = Conv1Ã—1(C5)**  â†’ kanal hizalama (Ã¶r: 256 kanal)\n",
    "\n",
    "Sonra aÅŸaÄŸÄ± ineriz:\n",
    "- **P4 = Up(P5) + Conv1Ã—1(C4)**\n",
    "- **P3 = Up(P4) + Conv1Ã—1(C3)**\n",
    "- **P2 = Up(P3) + Conv1Ã—1(C2)**\n",
    "\n",
    "Burada **Up(Â·)** genelde 2Ã— nearest/bilinear upsampleâ€™dir.\n",
    "\n",
    "### 5.2) Lateral (Yan) baÄŸlantÄ±\n",
    "Conv1Ã—1(Ck) ÅŸu iÅŸi yapar:\n",
    "- Backboneâ€™un farklÄ± katmanlarÄ±nda kanal sayÄ±larÄ± farklÄ±dÄ±r (512, 1024, 2048...)\n",
    "- 1Ã—1 conv ile hepsini aynÄ± kanala indirip (Ã¶r 256) **toplanabilir** hale getirirsin.\n",
    "\n",
    "**Toplama (sum)** kullanmak standarttÄ±r:\n",
    "- Concatenate yaparsan kanal bÃ¼yÃ¼r, maliyet artar.\n",
    "- Sum daha â€œtemizâ€ ve baseline olarak gÃ¼Ã§lÃ¼.\n",
    "\n",
    "### 5.3) â€œSmoothingâ€ (3Ã—3)\n",
    "Toplama sonrasÄ± genelde her Pkâ€™ya 3Ã—3 conv konur:\n",
    "- Upsampleâ€™Ä±n getirdiÄŸi aliasing / checkerboard etkilerini azaltÄ±r,\n",
    "- Daha stabil feature map verir.\n",
    "\n",
    "Ã–zet formÃ¼l:\n",
    "- **Pk = Conv3Ã—3( Up(Pk+1) + Conv1Ã—1(Ck) )**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b3b22e",
   "metadata": {},
   "source": [
    "\n",
    "## 6) FPN Ã§Ä±ktÄ±larÄ±: P2, P3, P4, P5 (+ P6/P7)\n",
    "\n",
    "En sÄ±k kullanÄ±lan set:\n",
    "- **P2**: en yÃ¼ksek Ã§Ã¶zÃ¼nÃ¼rlÃ¼k â†’ kÃ¼Ã§Ã¼k nesneler\n",
    "- **P3**: kÃ¼Ã§Ã¼kâ€‘orta\n",
    "- **P4**: orta\n",
    "- **P5**: bÃ¼yÃ¼k nesneler\n",
    "\n",
    "BazÄ± detectorâ€™lar daha da aÅŸaÄŸÄ± Ã¶lÃ§ek ister:\n",
    "- **P6** genelde P5â€™ten stride=2 conv ile Ã¼retilir\n",
    "- **P7** (RetinaNet) P6â€™dan tekrar stride=2\n",
    "\n",
    "Bu ekstra seviyeler daha bÃ¼yÃ¼k receptive field hedefler.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93d76bd",
   "metadata": {},
   "source": [
    "\n",
    "## 7) AkÄ±ÅŸÄ±n gÃ¶rsel (ASCII) ÅŸemasÄ±\n",
    "\n",
    "```bash\n",
    "Bottom-Up (Backbone):\n",
    "  C2 -----> C3 -----> C4 -----> C5\n",
    "  (1/4)    (1/8)     (1/16)    (1/32)\n",
    "\n",
    "Top-Down + Lateral:\n",
    "              [1x1] C5 ----> P5\n",
    "                         |\n",
    "                        Up\n",
    "                         |\n",
    "              [1x1] C4 --+--> P4 --(3x3 smooth)\n",
    "                         |\n",
    "                        Up\n",
    "                         |\n",
    "              [1x1] C3 --+--> P3 --(3x3 smooth)\n",
    "                         |\n",
    "                        Up\n",
    "                         |\n",
    "              [1x1] C2 --+--> P2 --(3x3 smooth)\n",
    "```\n",
    "\n",
    "- Oklar backboneâ€™un normal akÄ±ÅŸÄ±nÄ± (Câ€™ler)\n",
    "- Up + toplama + 3Ã—3 ile Pâ€™ler Ã¼retilir.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc219c23",
   "metadata": {},
   "source": [
    "\n",
    "## 8) PyTorch ile â€œminimalâ€ FPN implementasyonu\n",
    "\n",
    "AÅŸaÄŸÄ±da basit bir FPN modÃ¼lÃ¼ yazÄ±yoruz.\n",
    "- Girdi: backboneâ€™dan gelen featureâ€™lar `[C2, C3, C4, C5]`\n",
    "- Ã‡Ä±ktÄ±: `[P2, P3, P4, P5]`\n",
    "\n",
    "Not:\n",
    "- Burada backboneâ€™u **hazÄ±r Ã§Ä±ktÄ± veriyor gibi** dÃ¼ÅŸÃ¼n.\n",
    "- GerÃ§ekte backboneâ€™dan bu featureâ€™larÄ± almanÄ±n yolu (torchvision feature extractor vb.) var; onu da Ã¶rnekleyeceÄŸim.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "431d957d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([2, 256, 128, 128]),\n",
       " torch.Size([2, 256, 64, 64]),\n",
       " torch.Size([2, 256, 32, 32]),\n",
       " torch.Size([2, 256, 16, 16])]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FPN(nn.Module):\n",
    "    '''\n",
    "    Minimal FPN:\n",
    "      - lateral 1x1 conv: Ck -> out_channels\n",
    "      - top-down upsample + sum\n",
    "      - smoothing 3x3 conv\n",
    "    '''\n",
    "    def __init__(self, in_channels_list, out_channels=256):\n",
    "        super().__init__()\n",
    "        assert len(in_channels_list) == 4, \"Bu minimal Ã¶rnek C2..C5 (4 seviye) bekliyor.\"\n",
    "\n",
    "        self.lateral_convs = nn.ModuleList([\n",
    "            nn.Conv2d(cin, out_channels, kernel_size=1)\n",
    "            for cin in in_channels_list\n",
    "        ])\n",
    "        self.smooth_convs = nn.ModuleList([\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "            for _ in in_channels_list\n",
    "        ])\n",
    "\n",
    "    def forward(self, feats):\n",
    "        # feats: [C2, C3, C4, C5]\n",
    "        C2, C3, C4, C5 = feats\n",
    "\n",
    "        # 1) Lateral projections\n",
    "        lat2 = self.lateral_convs[0](C2)\n",
    "        lat3 = self.lateral_convs[1](C3)\n",
    "        lat4 = self.lateral_convs[2](C4)\n",
    "        lat5 = self.lateral_convs[3](C5)\n",
    "\n",
    "        # 2) Top-down pathway\n",
    "        P5 = lat5\n",
    "        P4 = lat4 + F.interpolate(P5, size=lat4.shape[-2:], mode=\"nearest\")\n",
    "        P3 = lat3 + F.interpolate(P4, size=lat3.shape[-2:], mode=\"nearest\")\n",
    "        P2 = lat2 + F.interpolate(P3, size=lat2.shape[-2:], mode=\"nearest\")\n",
    "\n",
    "        # 3) Smooth\n",
    "        P2 = self.smooth_convs[0](P2)\n",
    "        P3 = self.smooth_convs[1](P3)\n",
    "        P4 = self.smooth_convs[2](P4)\n",
    "        P5 = self.smooth_convs[3](P5)\n",
    "\n",
    "        return [P2, P3, P4, P5]\n",
    "\n",
    "# HÄ±zlÄ± shape testi\n",
    "B = 2\n",
    "C2 = torch.randn(B, 256, 128, 128)   # 1/4\n",
    "C3 = torch.randn(B, 512, 64, 64)     # 1/8\n",
    "C4 = torch.randn(B, 1024, 32, 32)    # 1/16\n",
    "C5 = torch.randn(B, 2048, 16, 16)    # 1/32\n",
    "\n",
    "fpn = FPN([256, 512, 1024, 2048], out_channels=256)\n",
    "P2, P3, P4, P5 = fpn([C2, C3, C4, C5])\n",
    "[P.shape for P in (P2, P3, P4, P5)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eebdea3",
   "metadata": {},
   "source": [
    "\n",
    "Beklenen:\n",
    "- P2: (B, 256, 128, 128)\n",
    "- P3: (B, 256, 64, 64)\n",
    "- P4: (B, 256, 32, 32)\n",
    "- P5: (B, 256, 16, 16)\n",
    "\n",
    "Kanallar eÅŸitlendi, Ã§Ã¶zÃ¼nÃ¼rlÃ¼k backbone seviyelerini takip etti âœ…\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc63ec26",
   "metadata": {},
   "source": [
    "\n",
    "## 9) Backboneâ€™dan C2..C5 featureâ€™larÄ±nÄ± nasÄ±l alÄ±rsÄ±n? (Torchvision yaklaÅŸÄ±mÄ±)\n",
    "\n",
    "GerÃ§ek projede backbone (ResNet, CSPDarknet, EfficientNet vs.) iÃ§inden ara featureâ€™larÄ± almak gerekir.\n",
    "\n",
    "Torchvisionâ€™da iki yaygÄ±n yol var:\n",
    "- `torchvision.models.feature_extraction.create_feature_extractor`\n",
    "- ya da modelin layerâ€™larÄ±nÄ± manual hookâ€™lamak\n",
    "\n",
    "AÅŸaÄŸÄ±daki kod **Ã¶rnek** amaÃ§lÄ±dÄ±r. Ortamda torchvision yoksa Ã§alÄ±ÅŸmayabilir; problem deÄŸil.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "636b9e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Bu hÃ¼cre Ã¶rnek amaÃ§lÄ±dÄ±r. torchvision ortamÄ±nda Ã§alÄ±ÅŸÄ±r.\n",
    "try:\n",
    "    import torchvision\n",
    "    from torchvision.models.feature_extraction import create_feature_extractor\n",
    "\n",
    "    backbone = torchvision.models.resnet50(weights=None)\n",
    "    backbone.eval()\n",
    "\n",
    "    # ResNet mapping:\n",
    "    # layer1 -> C2 (stride 4), layer2 -> C3 (stride 8), layer3 -> C4 (stride 16), layer4 -> C5 (stride 32)\n",
    "    return_nodes = {\n",
    "        \"layer1\": \"C2\",\n",
    "        \"layer2\": \"C3\",\n",
    "        \"layer3\": \"C4\",\n",
    "        \"layer4\": \"C5\",\n",
    "    }\n",
    "    extractor = create_feature_extractor(backbone, return_nodes=return_nodes)\n",
    "\n",
    "    x = torch.randn(1, 3, 512, 512)\n",
    "    with torch.no_grad():\n",
    "        out = extractor(x)\n",
    "\n",
    "    {k: v.shape for k, v in out.items()}\n",
    "except Exception as e:\n",
    "    print(\"Torchvision Ã¶rneÄŸi bu ortamda Ã§alÄ±ÅŸmadÄ± (problem deÄŸil). Hata:\", type(e).__name__, \"-\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7ed814",
   "metadata": {},
   "source": [
    "\n",
    "Bu Ã§Ä±ktÄ±larla FPNâ€™i ÅŸÃ¶yle beslersin:\n",
    "\n",
    "- C2 = out[\"C2\"]\n",
    "- C3 = out[\"C3\"]\n",
    "- C4 = out[\"C4\"]\n",
    "- C5 = out[\"C5\"]\n",
    "\n",
    "Sonra:\n",
    "- P2..P5 = fpn([C2, C3, C4, C5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61120bae",
   "metadata": {},
   "source": [
    "\n",
    "## 10) Pratik notlar (gerÃ§ek hayatta iÅŸine yarayacak)\n",
    "\n",
    "### 10.1) Upsample modu\n",
    "- `nearest`: hÄ±zlÄ± ve Ã§oÄŸu detector iÃ§in yeterli\n",
    "- `bilinear`: biraz daha yumuÅŸak, ama compute artar\n",
    "\n",
    "### 10.2) Sum vs Concat\n",
    "- **Sum**: FPNâ€™in klasik hali\n",
    "- **Concat**: PANet/BiFPN gibi varyantlarda gÃ¶rÃ¼lÃ¼r (ama genelde ekstra conv gerekir)\n",
    "\n",
    "### 10.3) Hangi seviyede hangi anchor?\n",
    "Anchor-based detectorâ€™larda her P seviyesine farklÄ± anchor scale verilir:\n",
    "- P2 kÃ¼Ã§Ã¼k anchor\n",
    "- P5 bÃ¼yÃ¼k anchor\n",
    "\n",
    "Anchor-free modellerde de (FCOS vb.) seviye atamasÄ± strideâ€™a gÃ¶re yapÄ±lÄ±r.\n",
    "\n",
    "### 10.4) Nerede kullanÄ±lÄ±r?\n",
    "- BackBone ile Head arasÄ±na.\n",
    "- Detection head her Pk Ã¼zerinde aynÄ± kÃ¼Ã§Ã¼k conv stack ile Ã§alÄ±ÅŸÄ±r.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e2eb49",
   "metadata": {},
   "source": [
    "\n",
    "## 11) FPN tÃ¼revleri (kÄ±sa ama net)\n",
    "\n",
    "### PANet (Path Aggregation Network)\n",
    "FPN topâ€‘down semantiÄŸi aÅŸaÄŸÄ± indirir.\n",
    "PANet bunun Ã¼stÃ¼ne bir de **bottomâ€‘up path augmentation** ekler:\n",
    "- Alt seviyeden Ã¼st seviyeye tekrar bilgi taÅŸÄ±r (Ã¶zellikle localization iyileÅŸmesi hedeflenir).\n",
    "\n",
    "### BiFPN (EfficientDet)\n",
    "BiFPN fikri:\n",
    "- Ã‡oklu giriÅŸleri â€œaÄŸÄ±rlÄ±klÄ± birleÅŸtirâ€ (learnable weights)\n",
    "- Gereksiz nodeâ€™larÄ± at, daha verimli grafik kur\n",
    "- Tekrarlanan BiFPN bloklarÄ± ile daha gÃ¼Ã§lÃ¼ multiâ€‘scale fusion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264d6d71",
   "metadata": {},
   "source": [
    "\n",
    "## 12) Tek paragraf Ã¶zet\n",
    "\n",
    "FPN, backboneâ€™un bottomâ€‘up Ã¼rettiÄŸi Ã§ok seviyeli featureâ€™larÄ± alÄ±r (C2..C5), Ã¼stten alta topâ€‘down upsample yaparak semantiÄŸi aÅŸaÄŸÄ± indirir ve her seviyede lateral 1Ã—1 conv ile backbone detayÄ±nÄ± ekleyip (sum) 3Ã—3 ile temizler; sonuÃ§ta P2..P5 gibi Ã§ok Ã¶lÃ§ekli, hem semantik hem konumsal olarak gÃ¼Ã§lÃ¼ feature mapâ€™ler elde eder ve bu sayede Ã¶zellikle kÃ¼Ã§Ã¼k nesnelerde detection performansÄ±nÄ± artÄ±rÄ±r. âœ…\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
